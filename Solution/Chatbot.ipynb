{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "w0eE0rbwiDjt",
        "ezM-Q2FViDjt",
        "kXR8EaiviDju",
        "O2L7iKEH_NaB",
        "uNBwlAD6_U6I",
        "pNcv0g7r-4Mc"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrTtYBHjiDjt"
      },
      "source": [
        "\n",
        "## **Chatbot Assessment**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoPZtkgziDjt"
      },
      "source": [
        "## **Chatbot Setup and Preparations**\n",
        "------------\n",
        "~~~~~~\n",
        "To start, Download the data ZIP file\n",
        "`here <https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`__\n",
        "and put in a ``data/`` directory under the current directory.\n",
        "\n",
        "After that, let’s import some necessities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSuXr1tdILy7"
      },
      "source": [
        "Import necessary libraries and setup the GPU as the hardware accelerator for the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLu4trfBiDjt",
        "outputId": "ed9c0878-4a08-47e1-df72-8004262f6816"
      },
      "source": [
        "from __future__ import absolute_import # Import resources using the full file path from the projects root directory\n",
        "from __future__ import division # Update and change the division operator to true division (floating point numbers as output regardless)\n",
        "from __future__ import print_function # Enable stringigised output for debugging purposes\n",
        "from __future__ import unicode_literals # Enable string literals to be converted into unicode literals (text into number sequences)\n",
        "\n",
        "import torch # Import the Torch library, used for tensor computation and machine learning (neural networks) support\n",
        "from torch.jit import script, trace # Import TorchScript (JIT - just-in-time compilation) function scripting (compile methods and functions as TorchScript code) and tracing (return executable(s) that is optimised using JIT) support\n",
        "import torch.nn as nn # Import neural network creation and training support\n",
        "from torch import optim # Import optimization algorithm support, for the use of adjusting parameters affecting neural network learning processes \n",
        "import torch.nn.functional as F # Import one-dimensional convolution support for input composed of multiple input planes, in neural networks (output tensor)\n",
        "import csv # Import comma seperated value file support, for importing and exporting date to and from spreadsheets and databases\n",
        "import random # Import randomization support\n",
        "import re # Import regular expression support for the purpose of matching character sequences with other character sequences (strings and sets of strings)\n",
        "import os # Import operating system dependant functionality use support\n",
        "import unicodedata # Import unicode database support for quering unicode literals by name (string format)\n",
        "import codecs # Import stream and file interface support, for transcoding program data (unicode encoding)\n",
        "from io import open # Import file input and output streaming support, for opening files external to the program\n",
        "import itertools # Import iterative functionality support\n",
        "import math # Import mathematical functionality support\n",
        "\n",
        "#import sys # Import python runtime environment manipulation functionality\n",
        "#!{sys.executable} -m pip install pyspellchecker # Install the python spell checker library (based upon Peter Norvig's spell checker implementation - manual implementation is shown in the vocabulary class)\n",
        "#from spellchecker import spellchecker # Import the spell checking and correction functionality\n",
        "\n",
        "from random import seed # Import random number generation intialisation support\n",
        "from random import randint # Import random integer generation support\n",
        "\n",
        "import time # Import time-related functionality support\n",
        "\n",
        "from pathlib import Path # Import filesystem functionality support\n",
        "\n",
        "# Produce plots that are inline with the notebooks cell indentation, beneath the code cell producing commanding the plot output, store the plot in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt # Import figure plotting support (similarities to MATLAB)\n",
        "import matplotlib.ticker as ticker # Import figure plotting axes ticking support\n",
        "import numpy as np # Import general-purpose array-processing support\n",
        "import plotly.graph_objects as go # Import graph object functionality support\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction # Import BLEU (Bilingual Evaluation Understudy) score calculation and score smoothing support\n",
        "from difflib import SequenceMatcher # Import sequence comparison functionality support\n",
        "!pip install pip install python-Levenshtein # Install Levenshtein (edit) distance and edit operations, string similarity, approximate median strings and averaging, string sequencing and set similarity support\n",
        "import Levenshtein # Import Levenshtein (edit) distance and edit operations, string similarity, approximate median strings and averaging, string sequencing and set similarity support\n",
        "\n",
        "import nltk # Import natural language toolkit (NLTK) support (natural language processing (NLP))\n",
        "nltk.download('punkt') # Download the punkt sequence tokenizer package (tokenizing support)\n",
        "nltk.download('stopwords') # Download the sentence stop words package \n",
        "from nltk.corpus import stopwords # Import stop word filter and processing support\n",
        "from nltk.tokenize import word_tokenize # Import substring and string tokenizing support (words and punctuation to numerical tokens)\n",
        "\n",
        "CUDA_IS_AVAILABLE = torch.cuda.is_available() # Determine whether a GPU is present for the operating device\n",
        "device = torch.device(\"cuda\" if CUDA_IS_AVAILABLE else \"cpu\") # Determine the hardware accelerator(s) in use (Compute Unified Device Architecture - use GPU and CPU in parallel to perform calculations)\n",
        "print(\"Hardware accelerator in use: {}\".format(device)) # Output the hardware accelerator used to execute the notebook"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.6/dist-packages (1.3.4)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (51.0.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Hardware accelerator in use: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qQzU0aMiDjt"
      },
      "source": [
        "## **Load and Preprocess Data**\n",
        "----------------------\n",
        "~~~~~~\n",
        "The next step is to reformat our data file and load the data into\n",
        "structures that we can work with.\n",
        "\n",
        "\n",
        "The Cornell movie-dialogs corpus\n",
        "Corpus <https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`\n",
        "is a rich dataset of movie character dialog:\n",
        "\n",
        "-  220,579 conversational exchanges between 10,292 pairs of movie\n",
        "   characters\n",
        "-  9,035 characters from 617 movies\n",
        "-  304,713 total utterances\n",
        "\n",
        "This dataset is large and diverse, and there is a great variation of\n",
        "language formality, time periods, sentiment, etc. Our hope is that this\n",
        "diversity makes our model robust to many forms of inputs and queries.\n",
        "\n",
        "\n",
        "The Cornell movie-quotes corpus\n",
        "Corpus <https://www.cs.cornell.edu/~cristian/memorability.html>\n",
        "is a collection of movie lines together with memorability annotations:\n",
        "\n",
        "- 894014 movie script lines\n",
        "- from 1068 movie scripts\n",
        "- 6282 one-line memorable quotes that are automatically matched with the script line which contain them\n",
        "- 2197 one-sentence memorable quotes paired with surrounding non-memorable quotes from the same movie, spoken by the same character and containing the same number of words\n",
        "\n",
        "\n",
        "The WikiQA corpus\n",
        "Corpus <https://www.microsoft.com/en-us/download/details.aspx?id=52419&from=http%3A%2F%2Fresearch.microsoft.com%2Fapps%2Fmobile%2Fdownload.aspx%3Fp%3D4495da01-db8c-4041-a7f6-7984a4f6a905>\n",
        "is a new publicly available set of question and sentence pairs, collected and annotated for research on open-domain question answering. With the help of crowdsourcing, it includes:\n",
        "\n",
        "- 3,047 questions\n",
        "- 29,258 sentences in the dataset\n",
        "- 1,473 sentences were labeled as answer sentences to their corresponding questions.\n",
        "\n",
        "\n",
        "First, we’ll take a look at some lines of our data file to see the\n",
        "original format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9e93IMWIqLh"
      },
      "source": [
        "Link Google Drive with the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAxaK9twvDAQ",
        "outputId": "9f5aabb6-aa86-41ca-d003-ed5266492ae9"
      },
      "source": [
        "from google.colab import drive # Import Google Drive support\n",
        "drive.mount('/content/drive', force_remount = False) # Mount the Google Drive associated with the account operating the notebook"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RzGCi-aIzlR"
      },
      "source": [
        "Access the chosen text corpus from the Google Drive directory configured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCQdguWZiDjt",
        "outputId": "bd4cfc3e-c3a9-4285-f5b2-ba8f1a75f8ee"
      },
      "source": [
        "# Corpora available: cornell movie-dialogs corpus (CMD), cornell movie-quotes corpus (CMQ), the WikiQA corpus (WIKI)\n",
        "corpus_name = {\"CMD\": \"cornell movie-dialogs corpus/movie_lines.txt/movie_conversations.txt\", \n",
        "               \"CMQ\": \"cornell movie-quotes corpus/moviequotes_scripts.txt\",\n",
        "               \"WIKI\": \"WikiQA corpus/WikiQA_train.txt\"} # Initialise a dictionary representing the keyed series of nominated text corpus (language resources)\n",
        "\n",
        "corpus_choice = \"CMQ\" # Initialise the text corpus to be used to train the chatbot model\n",
        "\n",
        "directory_extensions = corpus_name[corpus_choice].split('/') # Split the dictionairy entries by their extensions to the folder in the Google Drive directory mounted\n",
        "\n",
        "corpus_data_directory = \"/content/drive/My Drive/Colab Notebooks/Data\" # Define the absolute directory of the corpus\n",
        "corpus = os.path.join(corpus_data_directory, directory_extensions[0]) # Configure and combine the absolute directory of the corpus and its folders name\n",
        "\n",
        "print(directory_extensions, '\\n') # Output the directory and extensions for the text corpus chosen (check setup correctly)\n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, print the first '10' lines of a parsed text file\n",
        "def printLines(file, number_of_lines = 10):\n",
        "    number_of_lines_file = 0 # Initialise the number of lines of text read in the file\n",
        "\n",
        "    with open(file, 'rb') as data_file: # Open the file parsed\n",
        "        lines = data_file.readlines() # Read and parse the file as lines\n",
        "    \n",
        "    for line in lines[:number_of_lines]: # For each line in the line array, do the following\n",
        "        print(line) # Output each line of text read-in, per line\n",
        "\n",
        "    for line in lines: # For each line in the line array, do the following\n",
        "        number_of_lines_file += 1 # Increment the number of lines of text read in the file\n",
        "      \n",
        "    print(\"\\nNumber of lines in the file:\", number_of_lines_file) # Output the number of lines parsed in the file\n",
        "\n",
        "    return number_of_lines_file # Return the number of lines of text read in the file being parsed\n",
        "\n",
        "# Text files available: movie_lines.txt (CMD), moviequotes_scripts.txt (CMQ), WikiQA_train.txt (WIKI) \n",
        "number_of_lines_file = printLines(os.path.join(corpus, ''.join(directory_extensions[1]))) # Function call, output the lines of text for the file parsed "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cornell movie-quotes corpus', 'moviequotes_scripts.txt'] \n",
            "\n",
            "b'0 +++$+++ \"murderland\" +++$+++ 1 +++$+++ announcer +++$+++  +++$+++ Ladies and gentlemen, the official mascot of Murderland.... Scraps the Dog !\\n'\n",
            "b'1 +++$+++ \"murderland\" +++$+++ 2 +++$+++ announcer +++$+++  +++$+++ Choose the doorway that starts you on your magical journey into  MURDERLAND !\\n'\n",
            "b'2 +++$+++ \"murderland\" +++$+++ 3 +++$+++ johnny +++$+++  +++$+++ I didn\\'t think he\\'d make it past Scraps.\\n'\n",
            "b'3 +++$+++ \"murderland\" +++$+++ 4 +++$+++ bruce +++$+++ 2 +++$+++ Let\\'s just see if he can make it into round two....\\n'\n",
            "b'4 +++$+++ \"murderland\" +++$+++ 5 +++$+++ bruce +++$+++  +++$+++ Don\\'t.\\n'\n",
            "b'5 +++$+++ \"murderland\" +++$+++ 6 +++$+++ johnny +++$+++ 4 +++$+++ What ?\\n'\n",
            "b'6 +++$+++ \"murderland\" +++$+++ 7 +++$+++ bruce +++$+++ 5 +++$+++ Don\\'t eat at the console.\\n'\n",
            "b'7 +++$+++ \"murderland\" +++$+++ 8 +++$+++ johnny +++$+++ 6 +++$+++ What ? Are you my mother ?\\n'\n",
            "b'8 +++$+++ \"murderland\" +++$+++ 9 +++$+++ bruce +++$+++ 7 +++$+++ It\\'s my control board and I don\\'t want it acting squirrelly because you dropped a few crumbs into the keyboard, no put the shit away.\\n'\n",
            "b'9 +++$+++ \"murderland\" +++$+++ 10 +++$+++ johnny +++$+++ 8 +++$+++ Yes, sir Mom.\\n'\n",
            "\n",
            "Number of lines in the file: 894014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0eE0rbwiDjt"
      },
      "source": [
        "## **Create Formatted Data File**\n",
        "---------\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "For convenience, we'll create a nicely formatted data file in which each line\n",
        "contains a tab-separated *query sentence* and a *response sentence* pair.\n",
        "\n",
        "The following functions facilitate the parsing of the raw\n",
        "*movie_lines.txt* data file.\n",
        "\n",
        "-  ``loadLines`` splits each line of the file into a dictionary of\n",
        "   fields (lineID, characterID, movieID, character, text)\n",
        "-  ``loadConversations`` groups fields of lines from ``loadLines`` into\n",
        "   conversations based on *movie_conversations.txt*\n",
        "-  ``extractSentencePairs`` extracts pairs of sentences from\n",
        "   conversations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9c0ncZ9JDII"
      },
      "source": [
        "Create a formatted data file for the purpose of seperating lines of text and for identifying the fields that make up said lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejRhQvROiDjt"
      },
      "source": [
        "# Function declaration, split each line of the file parsed into a dictionary of fields\n",
        "def loadLines(file_name, fields):\n",
        "    lines = {} # Initialise the lines dictionary\n",
        "    \n",
        "    with open(file_name, 'r', encoding = 'iso-8859-1') as file: # Open the file being parsed with Latin alphabet encoding\n",
        "        for line in file: # For each line in the file parsed, do the following\n",
        "            \n",
        "            if corpus_choice == \"CMD\" or corpus_choice == \"CMQ\": # If the corpus chosen is the cornell movie-dialogs or movie-quotes datasets, do the following\n",
        "                field_values = line.split(\" +++$+++ \") # Split the currently iterated line into a list, for the delimiter passed\n",
        "            \n",
        "                line_object = {} # Initialise the line object dictionary, for extracting fields\n",
        "\n",
        "                for i, field in enumerate(fields): # For the number of fields determined, do the following\n",
        "                    line_object[field] = field_values[i] # Store the currentlty iterated element from the line (list) at the currently iterated field (map the string to its field)\n",
        "\n",
        "                lines[line_object[\"lineID\"]] = line_object # Store the current instance of the line object dictionary (all fields), from the first index of the line dictionary onwards\n",
        "\n",
        "            elif corpus_choice == \"WIKI\": # If the corpus chosen is the wikiqa dataset, do the following\n",
        "                field_values = re.split('\\t', line) # Split the currently iterated line into a list, for the delimiter passed\n",
        "                \n",
        "                line_object = {} # Initialise the line object dictionary, for extracting fields\n",
        "\n",
        "                for i, field in enumerate(fields): # For the number of fields determined, do the following\n",
        "                    line_object[field] = field_values[i] # Store the currentlty iterated element from the line (list) at the currently iterated field (map the string to its field)\n",
        "\n",
        "                    lines[line_object[field]] = line_object # Store the current instance of the line object dictionary (all fields), from the first index of the line dictionary onwards\n",
        "\n",
        "    return lines # Return the array of lines populated \n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, group the fields of lines parsed in the 'loadLines' function into conversations based upon the lines they reside in, according to the 'movie_conversations.txt' text file\n",
        "def loadConversations(file_name, lines, fields, corpus_choice):\n",
        "    conversations = [] # Intialise the coversations array\n",
        "    \n",
        "    with open(file_name, 'r', encoding = 'iso-8859-1') as file: # Open the file being parsed with Latin alphabet encoding\n",
        "        for line in file: # For each line in the file parsed, do the following\n",
        "    \n",
        "            if corpus_choice == \"CMD\" or corpus_choice == \"CMQ\": # If the corpus chosen is the cornell movie-dialogs or movie-quotes datasets, do the following\n",
        "                field_values = line.split(\" +++$+++ \") # Split the currently iterated line into a list, for the delimiter passed\n",
        "            \n",
        "            elif corpus_choice == \"WIKI\": # If the corpus chosen is the wikiqa dataset, do the following\n",
        "                field_values = re.split('\\t', line) # Split the currently iterated line into a list, for the delimiter passed\n",
        "            \n",
        "            conversation_object = {} # Initialise the conversation object dictionary, for extracting fields\n",
        "            \n",
        "            # Reassemble the lines\n",
        "            conversation_object[\"lines\"] = [] # Intialise a new field for the conversation object dictionary\n",
        "            \n",
        "            for i, field in enumerate(fields): # For the number of fields determined, do the following\n",
        "                conversation_object[field] = field_values[i] # Store the currentlty iterated element from the line (list) at the currently iterated field (map the string to its field)\n",
        "            \n",
        "            if corpus_choice == \"CMD\": # If the corpus chosen is the cornell movie-dialogs dataset, do the following\n",
        "                # Convert the string of line numbers into a list of line numbers (conversation_object[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
        "                utterance_id_pattern = re.compile('L[0-9]+') # Compile a regular expression pattern into a regular expression pattern object for ordering lines by their number (line id); query and response (ordered)\n",
        "                lineIds = utterance_id_pattern.findall(conversation_object[\"utteranceIDs\"]) # Store the line numbers of where the line of text parsed exists in the file    \n",
        "               \n",
        "                for lineId in lineIds: # For each line ID discovered, do the following\n",
        "                    conversation_object[\"lines\"].append(lines[lineId]) # Append the information populated for the line number of the line array to the current instance of the conversation object dictionary\n",
        "\n",
        "                conversations.append(conversation_object) # Append the current instance of coversation object dictionary (all fields) as a new entry to the conversations array \n",
        "\n",
        "                #print(conversation_object) # Output the contents of the each conversation object instance\n",
        "\n",
        "            elif corpus_choice == \"CMQ\": # If the corpus chosen is the cornell movie-quotes dataset, do the following\n",
        "                lineID = conversation_object[\"lineID\"] # Store the line number of the current line being parsed in the text\n",
        "                responseLineID = conversation_object[\"responseLineID\"] # Store the line number corresponding to the current lines predecessor line (the query before the current response) in the conversation\n",
        "                \n",
        "                if responseLineID is not '': # If the current lines predecessor line forms a conversation with the current line, do the following\n",
        "                    conversation = [lines[responseLineID], lines[lineID]] # Store the information for each of the lines in an array, ordered: query, response\n",
        "\n",
        "                    for i in range(0, 2, 1): # For the range given (start, stop, step), do the following\n",
        "                        conversation_object[\"lines\"].append(conversation[i]) # Append the information returned for each line to the same array in the 'lines' field (where it can be paired using i and i + 1) as a query and response pair \n",
        "\n",
        "                conversations.append(conversation_object) # Append the current instance of coversation object dictionary (all fields) as a new entry to the conversations array \n",
        "                    \n",
        "                #print(conversation_object) # Output the contents of the each conversation object instance\n",
        "\n",
        "            elif corpus_choice == \"WIKI\": # If the corpus chosen is the wikiqa dataset, do the following\n",
        "                query = conversation_object[\"question\"] # Store the query sentence of the current line being parsed in the text\n",
        "                response = conversation_object[\"answer\"] # Store the response sentence of the current line being parsed in the text\n",
        "                \n",
        "                conversation = [lines[query], lines[response]] # Store the information for each of the lines in an array, ordered: query, response\n",
        "\n",
        "                for i in range(0, 2, 1): # For the range given (start, stop, step), do the following\n",
        "                    conversation_object[\"lines\"].append(conversation[i]) # Append the information returned for each line to the same array in the 'lines' field (where it can be paired using i and i + 1) as a query and response pair \n",
        "\n",
        "                conversations.append(conversation_object) # Append the current instance of coversation object dictionary (all fields) as a new entry to the conversations array \n",
        "                    \n",
        "                #print(conversation_object) # Output the contents of the each conversation object instance \n",
        "\n",
        "    return conversations # Return the array of conversations populated\n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, extract pairs of query and response sentences from the conversations parsed\n",
        "def extractSentencePairs(conversations, corpus_choice):\n",
        "    query_response_pairs = [] # Initialise the query and response sentence pairs array\n",
        "    fields = [] # Initialise the fields array for storing the fields of the individual corpuses of where the sentence pairs exist\n",
        "\n",
        "    if corpus_choice == \"CMD\":    fields = [\"text\", \"text\"] # If the corpus chosen is the cornell movie-dialogs dataset, do the following\n",
        "    elif corpus_choice == \"CMQ\":  fields = [\"queryLineText\", \"queryLineText\"] # Else if the corpus chosen is the cornell movie-quotes dataset, do the following\n",
        "    elif corpus_choice == \"WIKI\": fields = [\"question\", \"answer\"] # Else if the corpus chosen is the cornell movie-quotes dataset, do the following\n",
        "\n",
        "    for conversation in conversations: # For each conversation parsed and populated, do the following\n",
        "        # Iterate over all the lines of the conversation\n",
        "        for i in range(len(conversation[\"lines\"]) - 1): # For the length of the conversation currently iterated ('-1' for '0' indexing), do the following\n",
        "            input_line = conversation[\"lines\"][i][fields[0]].strip() # Return a copy of the text of the currently iterated line of the currently iterated conversation in the array (query sentence)\n",
        "            target_line = conversation[\"lines\"][i+1][fields[1]].strip() # Return a copy of the text of the next line of the currently iterated conversation in the array (response sentence)\n",
        "\n",
        "            # Filter wrong samples (if one of the lists is empty)\n",
        "            if input_line and target_line: # If both lines of the conversation have text, do the following\n",
        "                query_response_pairs.append([input_line, target_line]) # Append the lines as a new entry pair to the query response pair array\n",
        "\n",
        "    return query_response_pairs # Return the array of query and response pairs populated"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezM-Q2FViDjt"
      },
      "source": [
        "## **Create the Formatted Data File (continued)**\n",
        "---------\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EaJoD9MJiDd"
      },
      "source": [
        "Create the formatted data file: 'formatted_movie_lines.txt'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy5t2Cd5iDjt",
        "outputId": "f70c52c8-990d-4959-fc33-740cbe5eabf0"
      },
      "source": [
        "data_file = os.path.join(corpus, \"formatted_movie_lines.txt\") # Store the file path to the newly formatted file\n",
        "\n",
        "delimiter = '\\t' # Define the delimiter to be a tab\n",
        "delimiter = str(codecs.decode(delimiter, \"unicode_escape\")) # Unescape the delimiter (hexidecimal escape sequence (characters beyond their literally meaning) is replaced by its unicode representation)\n",
        "\n",
        "lines = {} # Intialise the lines dictionary\n",
        "conversations = [] # Intialise the conversations array (list)\n",
        "MOVIE_DIALOG_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"] # Initialise the array (list) of movie line fields\n",
        "MOVIE_DIALOG_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"] # Initialise the array (list) of movie conversation fields \n",
        "MOVIE_QUOTES_FIELDS = [\"lineID\", \"movieTitle\", \"queryLineID\", \"characterID\", \"responseLineID\", \"queryLineText\"] # Initialise the array (list) of movie quote fields\n",
        "WIKI_QA_FIELDS = [\"question\", \"answer\", \"label\"] # Initialise the array (list) of wiki question and answer fields\n",
        "\n",
        "print(\"\\nProcessing corpus: {}\".format(directory_extensions[0])) # Output that the nominated corpus is being processed\n",
        "\n",
        "if corpus_choice == \"CMD\": # If the corpus chosen is the cornell movie-dialogs dataset, do the following\n",
        "    lines = loadLines(os.path.join(corpus, directory_extensions[1]), MOVIE_DIALOG_LINES_FIELDS) # Function call, load the lines of the active corpus data file file\n",
        "    conversations = loadConversations(os.path.join(corpus, directory_extensions[2]), lines, MOVIE_DIALOG_CONVERSATIONS_FIELDS, corpus_choice) # Function call, load the conversations of the 'movie_conversations.text' file\n",
        "\n",
        "elif corpus_choice == \"CMQ\": # If the corpus chosen is the cornell movie-quotes dataset, do the following\n",
        "    lines = loadLines(os.path.join(corpus, directory_extensions[1]), MOVIE_QUOTES_FIELDS) # Function call, load the lines of the active corpus data file file\n",
        "    conversations = loadConversations(os.path.join(corpus, directory_extensions[1]), lines, MOVIE_QUOTES_FIELDS, corpus_choice) # Function call, load the conversations of the 'movie_conversations.text' file\n",
        "\n",
        "elif corpus_choice == \"WIKI\": # If the corpus chosen is the wikiqa dataset, do the following\n",
        "    lines = loadLines(os.path.join(corpus, directory_extensions[1]), WIKI_QA_FIELDS) # Function call, load the lines of the active corpus data file file\n",
        "    conversations = loadConversations(os.path.join(corpus, directory_extensions[1]), lines, WIKI_QA_FIELDS, corpus_choice) # Function call, load the conversations of the 'movie_conversations.text' file\n",
        "\n",
        "print(\"\\nWriting the newly formatted file...\") # Output that a newly formatted file (CSV) is being written to\n",
        "with open(data_file, 'w', encoding = 'utf-8') as output_file: # Open the file being written-to with Unicode (variable character width) encoding\n",
        "    writer = csv.writer(output_file, delimiter = delimiter, lineterminator = '\\n') # Configure the file, delimiter and line terminator parameters for writing\n",
        "    \n",
        "    for pair in extractSentencePairs(conversations, corpus_choice): # For each pair of query and response sentences populated in the conversations array, do the following\n",
        "        writer.writerow(pair) # Write each sentence pair to a seperate row in the file configured\n",
        "\n",
        "# Print a sample of lines\n",
        "print(\"\\nSample lines from the newly formatted file:\") # Output that a sample of the lines written to the file are to be shown\n",
        "_ = printLines(data_file) # Function call, output the lines of text for the file containing the sentence pairs"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing corpus: cornell movie-quotes corpus\n",
            "\n",
            "Writing the newly formatted file...\n",
            "\n",
            "Sample lines from the newly formatted file:\n",
            "b\"I didn't think he'd make it past Scraps.\\tLet's just see if he can make it into round two....\\n\"\n",
            "b\"Don't.\\tWhat ?\\n\"\n",
            "b\"What ?\\tDon't eat at the console.\\n\"\n",
            "b\"Don't eat at the console.\\tWhat ? Are you my mother ?\\n\"\n",
            "b\"What ? Are you my mother ?\\tIt's my control board and I don't want it acting squirrelly because you dropped a few crumbs into the keyboard, no put the shit away.\\n\"\n",
            "b\"It's my control board and I don't want it acting squirrelly because you dropped a few crumbs into the keyboard, no put the shit away.\\tYes, sir Mom.\\n\"\n",
            "b\"Never underestimate a man who cheats on his taxes. His file says he is an avid jogger.\\tYou've got to be kidding me ! His lazy ass couldn't win the special Olympics.\\n\"\n",
            "b\"He'll never get it right. Try the Log Ride !\\tNot yet.\\n\"\n",
            "b\"Not yet.\\tBut, he's...\\n\"\n",
            "b\"But, he's...\\tI said NO.\\n\"\n",
            "\n",
            "Number of lines in the file: 500105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCqE1NQziDjt"
      },
      "source": [
        "## **Loading and Trimming Words**\n",
        "---------\n",
        "~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "Our next order of business is to create a vocabulary and load\n",
        "query/response sentence pairs into memory.\n",
        "\n",
        "Note that we are dealing with sequences of **words**, which do not have\n",
        "an implicit mapping to a discrete numerical space. Thus, we must create\n",
        "one by mapping each unique word that we encounter in our dataset to an\n",
        "index value.\n",
        "\n",
        "For this we define a ``Vocabulary`` class, which keeps a mapping from words to\n",
        "indexes, a reverse mapping of indexes to words, a count of each word and\n",
        "a total word count. The class provides methods for adding a word to the\n",
        "vocabulary (``addWord``), adding all words in a sentence\n",
        "(``addSentence``) and trimming infrequently seen words (``trim``). More\n",
        "on trimming later.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAQbU2_mLME0"
      },
      "source": [
        "List every word and its total number of occurences in the text corpus, map each word to a unique index and reverse said indexes back to its representing word. Add words to a vocabulary and remove words that are infrequently used (trim rare words)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOslSPPRiDjt"
      },
      "source": [
        "# Default word tokens\n",
        "PAD_token = 0 # Used for padding short sentences\n",
        "SOS_token = 1 # Start-of-sentence token\n",
        "EOS_token = 2 # End-of-sentence token\n",
        "\n",
        "# Class vocabulary\n",
        "class Vocabulary:\n",
        "\n",
        "    # Function declaration, initialise the class (constructor)\n",
        "    def __init__(self, name):\n",
        "        self.name = name # Initialise the name of the vocabulary object\n",
        "        self.trimmed = False # Initialise the vocabulary objects trimmed state\n",
        "        self.word2index = {} # Initialise the word to index dictionary\n",
        "        self.word2count = {} # Intialise the word to count dictionary\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"} # Intialise the index to word dictionary\n",
        "        self.number_of_words = 3 # Count default tokens: PAD = 0, SOS = 1, EOS = 2, first word = 3\n",
        "\n",
        "\n",
        "\n",
        "    # Function declaration, split sentences into words and process them for the vocabulary\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '): # For each word in the sentence passed (split the sentence into a list of words that is split using the ' ' seperator)\n",
        "            self.addWord(word) # Function call, process the word for its frequency and posiiton in the sentence (add to vocabulary)\n",
        "\n",
        "\n",
        "\n",
        "    # Function declaration, process words syntactically to the vocabulary\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index: # For each word that does not have an index specified in the word to index dictionary, do the following\n",
        "            self.word2index[word] = self.number_of_words # Set the words index to the currently unoccupied index in the word to index array (number of words existing in the vocabulary + 1)\n",
        "            self.word2count[word] = 1 # Intialise the words count for its index in the word to count array\n",
        "            self.index2word[self.number_of_words] = word # Store the word corresponding to its index (map), in the index to word dictionary\n",
        "            self.number_of_words += 1 # Incremenet the number of words exisiting in the vocabulary\n",
        "        else: # Else for each word that does have an index specified in the word to index dictionary, do the following\n",
        "            self.word2count[word] += 1 # Increment the frequency of the word passed, for its index in the word to count dictionary\n",
        "\n",
        "\n",
        "\n",
        "    # Function declaration, remove words below a specified count threshold\n",
        "    def trim(self, minimum_count):\n",
        "        if self.trimmed: # If the vocabulary has been trimmed, do the following\n",
        "            return # Return\n",
        "        \n",
        "        self.trimmed = True # The vocabulary has been trimmed\n",
        "\n",
        "        keep_words = [] # Intialise an array for the words to be kept from the vocabulary\n",
        "\n",
        "        for word, count in self.word2count.items(): # For each word and its corresponding frequency in the vocabulary (dictonarys tuple pair - key and value), do the following\n",
        "            if count >= minimum_count: # If the currently iterated words frequency is larger than or equal to the minimum count, do the following\n",
        "                keep_words.append(word) # Add a new entry to the keep words array to store the word currenlty iterated\n",
        "\n",
        "        print('Kept words: was {}, now {} [{:.2f}%] of words removed...'.format(len(self.word2index), len(keep_words), len(keep_words) / len(self.word2index))) # Output the number of words kept compartive to the number of words in the voacabulary orginally and their representative percentage\n",
        "\n",
        "        # Reinitialise the dictionaries\n",
        "        self.word2index = {} # Intialise the word to index dictionary\n",
        "        self.word2count = {} # Intialise the word to count dictionary\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"} # Intialise the index to word dictionary\n",
        "        self.number_of_words = 3 # Count default tokens: PAD = 0, SOS = 1, EOS = 2, first word = 3\n",
        "\n",
        "        for word in keep_words: # For each word in the keep words array, do the following\n",
        "            self.addWord(word) # Re-add the word to the vocabulary (update the vocabulary)\n",
        "\n",
        "    \n",
        "\n",
        "    # The toy-spelling-corrector functionality is based upon Peter Norvig's blog post: https://norvig.com/spell-correct.html\n",
        "    # It uses a Levenshtein Distance algorithm to find permutations (each of several possible ways in which a set or number of things can be ordered or arranged) within an edit distance of '2' from the original word\n",
        "\n",
        "    # Function declaration, determine whether a word has been misspelt in the input sentence (query)\n",
        "    def spellCheckQuery(self, input_sentence):\n",
        "        words = input_sentence.split(' ') # Split the input sentence (query) into a list words using the white space seperator\n",
        "\n",
        "        output_words = '' # Initialise a string representing the output sequence of words (input sentence corrected and recompiled)\n",
        "        word_corrected = False # Initialise a Boolean variable representing whether a word has been corrected from the input sentence, or not\n",
        "\n",
        "        for i, word in enumerate(words): # For each word in the input sentence (query), do the following\n",
        "            if word not in self.word2index: # If the word currently iterated does not exist in the vocabulary populated, do the following\n",
        "                word_originally = word # Store the orignal instance of the word currently iterated for correction\n",
        "                print(\"Checking word '{}' for correction...\".format(word_originally)) # Output that the word is being checked for a correction (replacement word)\n",
        "\n",
        "                word = self.spellCheckWord(word) # Store the correction word for the word mispelt (or unrecognised by the words populated in the vocabulary)\n",
        "\n",
        "                if len(words) == 1 and word == \"\": # If the input sentence only contains '1' word and the word could not be corrected (no known corrections), do the following\n",
        "                    word = word_originally # Set the word to its original word (allow error handling to be executed - unencountered word)\n",
        "                    print(\"'{}' could not be corrected! No replacement words were found...\".format(word_originally)) # Output that the word misspelt (or unrecognised by the words populated in the vocabulary) could not be corrected\n",
        "\n",
        "                elif word == \"\": # Else if the input sentence contains more than one word but the word could not be corrected (no known corrections), do the following \n",
        "                    print(\"'{}' could not be corrected! No replacement words were found...\".format(word_originally)) # Output that the word misspelt (or unrecognised by the words populated in the vocabulary) could not be corrected\n",
        "\n",
        "                else: # Else if the input sentence contains more than one word and the word was corrected, do the following \n",
        "                    if word is not word_originally: # If the currently iterated word has been corrected, do the following \n",
        "                        print(\"'{}' has been corrected to '{}'...\".format(word_originally, word)) # Output that the word misspelt (or unrecognised by the words populated in the vocabulary) has been corrected\n",
        "                        \n",
        "                        if word_corrected is False: # If a word from the passed input sentence has not been corrected, do the following\n",
        "                            word_corrected = True # Set the word corrected Boolean variable to 'true'\n",
        "\n",
        "            output_words += word # Concatenate each word in the input sequence to form a new string representing the sentence in its correct form\n",
        "\n",
        "            if i is not len(words) - 1: # If the currently iterated word is not the last word in the input sentence, do the following \n",
        "                output_words += ' ' # Concatenate the current output sequence with a white space character, to form spacing between words concatenated to the sequence\n",
        "\n",
        "        if word_corrected == True: # If the query sentence has been corrected from the original input, do the following\n",
        "            print(\"Spell check and correction complete. Your query is now: '{}'\".format(output_words)) # Output that the word spell and correction process has completed and the resultant input that is parsed by the chatbot\n",
        "\n",
        "        return output_words # Return the input sequence (query) determined\n",
        "\n",
        "\n",
        "    \n",
        "    # Function declaration, return the probability of the currently passed word being the most suited correction to the misspelt word checked\n",
        "    def spellCheckWordCorrectionProbability(self, word):\n",
        "        correction_probability = self.word2index[word] / sum(self.word2index.values()) # Calculate the passed words probability as the correction for the misspelt word checked\n",
        "\n",
        "        return correction_probability # Return the probability of the word passed being a correction for the misspelt word checked\n",
        "    \n",
        "\n",
        "\n",
        "    # Function declaration, return the word with the highest probability of being the correct correction for the misspelt word\n",
        "    def spellCheckWord(self, word):\n",
        "        output_word = '' # Initialise a string representing the replacement word (correction)\n",
        "        best_word_correction_probability = 0 # Initialise the best probability calculated for all correction words populated\n",
        "        possible_word_corrections = self.spellCheckPossibleCorrectionWord(word) # Store all possible correction words for the misspelt word passed\n",
        "        \n",
        "        for correction_word in possible_word_corrections: # For each correction word in the array of correction words for the missplet word, do the following\n",
        "            current_word_correction_probability = self.spellCheckWordCorrectionProbability(correction_word) # Store the probability of the currently iterated correction word, as being the correct replacement for the misspelt word\n",
        "            \n",
        "            #print(\"Testing correction word '{}' from list of {} correction words...\".format(correction_word, len(possible_word_corrections)))\n",
        "            #print(\"Correction '{}' has a {} probability of being correct...\".format(correction_word, current_word_correction_probability))\n",
        "            \n",
        "            if (current_word_correction_probability > best_word_correction_probability): # If the currenttly iterated correction words probability as the correct replacement for the misseplt word, is larger than the best correction words probability known currently, do the following\n",
        "                best_word_correction_probability = current_word_correction_probability # Set the best correction words probability known currently, to the currenttly iterated correction words probability as the correct replacement for the misseplt word\n",
        "                output_word = correction_word # Set the best suited correction word to the currently iterated correction word\n",
        "        \n",
        "        return output_word # Return the best suited correction word for replacing the misspelt word in the input sentence\n",
        "\n",
        "\n",
        "\n",
        "    # Function declaration, populate an array of possible correction words for the misspelt word in the input sentence\n",
        "    def spellCheckPossibleCorrectionWord(self, word):\n",
        "        word_edits_once = self.editedWordsOneCycle(word) # Return the set of words representing the edits of the misspelt word (logically created variations of the word - used to determine a similar match to a known word)\n",
        "        word_edits_twice = self.editedWordsTwoCycles(word_edits_once) # Return the set of words representing the edits of the edits, of the misspelt word (logically created variations of the word - used to determine a similar match to a known word)\n",
        "        known_words = self.known(word_edits_once) or self.known(word_edits_twice) # Store the words that were generated from both edit cycles, that also exist in the vocabuluary populated for the chatbot\n",
        "        \n",
        "        #print(\"{} known corrections for the word: '{}'\\n Known corrections: {}\".format(len(known_words), word, known_words)) # Output the known correction words for the word misspelt in the input sentence\n",
        "        \n",
        "        return known_words # Return the words known to be recognised corrections for the misspelt word in the input sequence\n",
        "    \n",
        "\n",
        "\n",
        "    # Function declaration, return the subset of the input set of words that appears in the vocab\n",
        "    def known(self, input_word_sequence):\n",
        "        known_words = [] # Initialise the known words of the input sequence of words passed\n",
        "\n",
        "        for word in input_word_sequence: # For each word in the input word sequence, do the following\n",
        "            if word in self.word2index: # If the currently iterated word is recognised in the vocabulary populated, do the following\n",
        "                known_words.append(word) # Append the currently iterated word to the known words array\n",
        "                \n",
        "        return known_words # Return all the words that are recognised in the populated vocabulary and that exist in the input sequence of words passed \n",
        "        #return set(word for word in input_word_sequence if word in self.word2index) # Return all the words that are recognised in the populated vocabulary and that exist in the input sequence of words passed\n",
        "    \n",
        "\n",
        "\n",
        "    # Function declaration, return all the edits (edited words) for the word passed (one edit away from the input word - input word, 'edited input word', edited-edited input word)\n",
        "    def editedWordsOneCycle(self, word):\n",
        "        output = [] # Initialise the output array for storing the edit words populated for finding a correction word for the misspelt word passed\n",
        "        \n",
        "        # Randomise an edit sequence for the characters that compose the misspelt word passed, for generating a series of possible correction words that could be used to replace the misspelt word passed \n",
        "        characters           = 'abcdefghijklmnopqrstuvwxyz' # Initialise a string representing all the possible characters that the misspelt word is composed of (letters)\n",
        "        split_characters     = [(word[:i], word[i:])                                       for i in range(len(word) + 1)] # Leftward shift the misspelt words characters, character-for-character for its length, creating two words per character shifted ( e.g. dog = [('' : dog), (d : og), (do : g), (dog : '')] )\n",
        "        delete_characters    = [left_word + right_word[1:]                                 for left_word, right_word in split_characters if right_word] # Delete a character from the right segmentation of the split word\n",
        "        transpose_characters = [left_word + right_word[1] + right_word[0] + right_word[2:] for left_word, right_word in split_characters if len(right_word) > 1] # Rearrange the characters (transpose) for the right segmentation of the split word\n",
        "        replace_characters   = [left_word + character + right_word[1:]                     for left_word, right_word in split_characters if right_word for character in characters] # Insert a new character from the letters array between the segments of the split word, whilst deleting a character from the right segmentation of the split word\n",
        "        insert_characters    = [left_word + character + right_word                         for left_word, right_word in split_characters for character in characters] # Insert a new character from the letters array between the segments of the split word \n",
        "        \n",
        "        output = (delete_characters + transpose_characters + replace_characters + insert_characters) # Concatenate the numerous character sequeneces populated by the iterative word edit process, to form a series of words (possible correct correction words)   \n",
        "        \n",
        "        return output # Return all the words than have been populated for the first edit cycle, of the misspelt word passed\n",
        "        #return set(deletes + transposes + replaces + inserts) # Return all the words than have been populated for the first edit cycle, of the misspelt word passed\n",
        "        \n",
        "\n",
        "\n",
        "    # Function declaration, return all the edits (edited words) for the word passed (two edits away from the input word - input word, edited input word, 'edited-edited input word')\n",
        "    def editedWordsTwoCycles(self, word_edits_once):\n",
        "        output = [] # Initialise the output for the second word edit cycle\n",
        "\n",
        "        for word_edit_once in word_edits_once: # For each edit word in the array of edit words populated in the first edit cycle, do the following\n",
        "            for word_edit_twice in self.editedWordsOneCycle(word_edit_once): # For each re-edited edit word populated in the first edit cycle, do the following\n",
        "                output.append(word_edit_twice) # Append the re-edited edit words to the output array\n",
        "\n",
        "        return output # Return all words than have been populated for the second edit cycle, from the first edit cycles words\n",
        "        #return set(word_edit_twice for word_edit_once in word_edits_once for word_edit_twice in self.editedWordsOneCycle(word_edit_once)) # Return all words than have been populated for the second edit cycle, from the first edit cycles words"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEhET4BDiDjt"
      },
      "source": [
        "~~~~~\n",
        "Now we can assemble our vocabulary and query/response sentence pairs.\n",
        "Before we are ready to use this data, we must perform some\n",
        "preprocessing.\n",
        "\n",
        "First, we must convert the Unicode strings to ASCII using\n",
        "``unicodeToAscii``. Next, we should convert all letters to lowercase and\n",
        "trim all non-letter characters except for basic punctuation\n",
        "(``normalizeString``). Finally, to aid in training convergence, we will\n",
        "filter out sentences with length greater than the ``MAX_LENGTH``\n",
        "threshold (``filterPairs``).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF8FRd6FL-7K"
      },
      "source": [
        "Data must be peprocessed before being used in the chatbot model. Convert Unicode encoded characters (of strings) to ASCII encoded characters, set all capital letters to lower case and, filter out the long sentences to aid in training covergence (progression towards the chatbot model learning to properly respond to a set of training patterns within some margin of error)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6KWqp4qiDjt",
        "outputId": "596b6b50-abea-49d2-ca3c-cb1139bb3cfe"
      },
      "source": [
        "MAX_LENGTH = 10  # Maximum sentence length (words) to consider in the chatbots training process\n",
        "concatenate_apostrophised_words = True # Determine whether split apostrophised words are concatenated\n",
        "\n",
        "\n",
        "\n",
        "# Turn a Unicode string to a series of plain ASCII characters: https://stackoverflow.com/a/518232/2809427\n",
        "# Function declaration, convert a string of Unicode characters to ASCII characters\n",
        "def unicodeToAscii(string):\n",
        "    \n",
        "    return ''.join(character for character in unicodedata.normalize('NFD', string) if unicodedata.category(character) != 'Mn') # Return the string in ASCII format, for the normal form decomposed method (NFD - combined characters), if the category assigned to any character is not 'Mn'\n",
        "\n",
        "\n",
        "\n",
        "# Function call, normalise strings to be lowercase, trimmed from numerous white spaces and non-letter characters\n",
        "def normalizeString(string):\n",
        "    string = unicodeToAscii(string.lower().strip()) # Convert the Unicode characters to ASCII characters, in lower case format and to a list\n",
        "    string = re.sub(r\"([.!?])\", r\" \\1\", string) # Replace repeated non-letter (punctuation) characters in the string for a white space character\n",
        "    string = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", string) # Replace non-letter characters in the string for a white space character\n",
        "    string = re.sub(r\"\\s+\", r\" \", string).strip() # Replace multiple white space characters for a single white space character\n",
        "    \n",
        "    return string # Return the resultant string (ASCII encoded)\n",
        "\n",
        "\n",
        "\n",
        "# Function call, read query and response pairs and return a vocabulary object\n",
        "def readVocabularies(data_file, corpus_name):\n",
        "    print(\"Reading the lines of the newly formatted data file...\") # Output that the lines of the data file are being read-in\n",
        "    \n",
        "    lines = open(data_file, encoding = 'utf-8').read().strip().split('\\n') # Open the file being read-in with Unicode (variable character width) encoding and split and store the text into a list of lines\n",
        "    pairs = [[normalizeString(string) for string in line.split('\\t')] for line in lines] # Split every line into a pair in the array of pairs composed of query and response sentences and normalise it\n",
        "    vocabulary = Vocabulary(corpus_name) # Create an instance of a vocabulary class object, passing the name of the corpus being used to intialise it \n",
        "    \n",
        "    return vocabulary, pairs # Return a vocabulary object, as well as the array of query and response sentence pairs for the file parsed\n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, returns 'true' if both sentences forming a pair are under the maximum length threshold\n",
        "def filterPair(pair):\n",
        "    return len(pair[0].split(' ')) < MAX_LENGTH and len(pair[1].split(' ')) < MAX_LENGTH # Return the truth for whether the sentence pair(s) when split as words, are shorter than the maximum length of sentences considered (last word of every setence needs to be preseved for the EOS token - hence the smaller than and not the equal to or smaller than operator) \n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, filter the sentence pairs using the 'filterPair' function condition\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)] # Return the sentence pairs that have been validated for the chatbots training process\n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, using the functions defined above, return a populated vocabulary object and list of its corresponding sentence pairs (load and prepare the data)\n",
        "def loadPrepareData(corpus, corpus_name, data_file, save_directory):\n",
        "    reprocessed_pairs = [] # Initialise the reprocessed pairs array\n",
        "    \n",
        "    print(\"Preparing chatbot model training data...\") # Output that the chatbots training data is being prepared\n",
        "    \n",
        "    vocabulary, pairs = readVocabularies(data_file, corpus_name) # Parse a data file to extract query and response sentence pairs from its text, whilst creating a vocabulary object instance\n",
        "    print(\"Read {} sentence pairs...\".format(len(pairs))) # Output the number of sentence pairs that the vocabulary has been configured with intially\n",
        "    \n",
        "    pairs = filterPairs(pairs) # Store the returned validated senetence pairs for the chatbots training process\n",
        "    print(\"Trimmed to {} sentence pairs...\".format(len(pairs))) # Ouput the number of sentence pairs that the vocabulary has been trimmed to\n",
        "    print(\"Counting words...\") # Output that the number of words for all sentence pairs is being counted\n",
        "    \n",
        "    for pair in pairs: # For each pair in the validated pairs list, do the following\n",
        "\n",
        "        if concatenate_apostrophised_words is True: # If the sentence pairs populated are to be screened for concatenating split apostrophised words, do the following\n",
        "            split_sentence = [] # Initialise the split sentence array\n",
        "            sorted_sentence = [] # Initialise the sorted sentence array\n",
        "        \n",
        "            apostrophe_characters = [\"re\", \"t\", \"ve\", \"m\", \"d\", \"ll\", \"s\"] # Initialise the apostrophe characters array\n",
        "            sentences = [pair[0], pair[1]] # Initialise the sentences array\n",
        "        \n",
        "            # Concatenate the split apostrophised words\n",
        "            for j in range(0, 2, 1): # For each type of sentence in the sentence array, do the following\n",
        "                split_sentence = sentences[j].split() # Split each word in the currently iterated sentence into seperate elements in the list\n",
        "            \n",
        "                for k in range(0, len(split_sentence), 1): # For each word in the currently split sentence, do the following\n",
        "                    if len(split_sentence[k]) <= 2: # If the currently iterated word in the currently split sentence is smaller than or equal to '2' characters in length, do the following\n",
        "                        if split_sentence[k] in apostrophe_characters: # If the currently iterated word is an apostrophe character, do the following\n",
        "                            if k > 0 and len(split_sentence[k]) >= 1: # If the current iteration is not first iteration and the currently iterated words length is larger than or equal to '1' character, do the following\n",
        "                                sorted_sentence[k - 1] = '' # Reinitialise the previously iterated index of the sorted sentence array (prepare for new input)\n",
        "                                sorted_sentence.insert(k - 1, split_sentence[k - 1] + split_sentence[k]) # Store the apostrophised word at the previously iterated index (don, t = dont, '')\n",
        "                        \n",
        "                            else: # Else if the current iteration is the first iteration or the currently iterated words length is smaller than '1' character, do the following\n",
        "                                sorted_sentence.append(split_sentence[k]) # Append the currently iterated word in the currently split sentence to the sorted sentence array\n",
        "                \n",
        "                        else: # Else if the currently iterated word is not an apostrophe character, do the following\n",
        "                            sorted_sentence.append(split_sentence[k]) # Append the currently iterated word in the currently split sentence to the sorted sentence array\n",
        "              \n",
        "                    elif len(split_sentence[k]) > 2: # Else if the currently iterated word in the currently split sentence is larger than '2' characters in length, do the following\n",
        "                        sorted_sentence.append(split_sentence[k]) # Append the currently iterated word in the currently split sentence to the sorted sentence array\n",
        "              \n",
        "                if j == 0: # If the query sentence is currently being sorted, do the following\n",
        "                    sentences[j] = sorted_sentence # Set the query sentence to the current iteration of the sorted sentence array\n",
        "                    sorted_sentence = [] # Reinitialise the sorted sentence array (for future iterations)\n",
        "        \n",
        "                elif j == 1: # Else if the target response sentence is currently being sorted, do the following\n",
        "                    sentences[j] = sorted_sentence # Set the target response sentence to the current iteration of the sorted sentence array\n",
        "                    sorted_sentence = [] # Reinitialise the sorted sentence array (for future iterations)\n",
        "\n",
        "            query_sentence = ' '.join(sentences[0]) # Concatenate the elements of the query sentence index, in the sentence array, to a string\n",
        "            response_sentence = ' '.join(sentences[1]) # Concatenate the elements of the response sentence index, in the sentence array, to a string\n",
        "\n",
        "            query_sentence = re.sub(r\"\\s+\", r\" \", query_sentence).strip() # Replace multiple white space characters for a single white space character\n",
        "            response_sentence = re.sub(r\"\\s+\", r\" \", response_sentence).strip() # Replace multiple white space characters for a single white space character\n",
        "\n",
        "            vocabulary.addSentence(query_sentence) # Add a sentence to the vocabulary object, representing the query sentence\n",
        "            vocabulary.addSentence(response_sentence) # Add a sentence to the vocabulary object, representing the response sentence\n",
        "\n",
        "            reprocessed_pairs.append([query_sentence, response_sentence]) # Append the reprocessed sentence pair to the reprocessed sentence pair array\n",
        "    \n",
        "        elif concatenate_apostrophised_words is False: # Else if the sentence pairs populated are not to be screened for concatenating split apostrophised words, do the following\n",
        "            vocabulary.addSentence(pair[0]) # Add a sentence to the vocabulary object, representing the query sentence\n",
        "            vocabulary.addSentence(pair[1]) # Add a sentence to the vocabulary object, representing the response sentence\n",
        "            \n",
        "    print(\"Words counted:\", vocabulary.number_of_words) # Output the nummber of words stored in the vocabulary object instance, that formulate sentences\n",
        "\n",
        "    if concatenate_apostrophised_words is True: # If the sentence pairs populated are to be screened for concatenating split apostrophised words, do the following\n",
        "        return vocabulary, reprocessed_pairs # Return a vocabulary object, as well as the array of query and response sentence pairs (reprocessed) for the file parsed\n",
        "\n",
        "    elif concatenate_apostrophised_words is False: # Else if the sentence pairs populated are not to be screened for concatenating split apostrophised words, do the following\n",
        "        return vocabulary, pairs # Return a vocabulary object, as well as the array of query and response sentence pairs for the file parsed\n",
        "\n",
        "\n",
        "\n",
        "# Load and or assemble a vocabulary object and its correpsonding sentence pairs\n",
        "save_directory = os.path.join(corpus_data_directory, \"save\") # Store the file path to where the vocabulary object instance is being saved \n",
        "vocabulary, pairs = loadPrepareData(corpus, ''.join(directory_extensions[0]), data_file, save_directory) # Load, prepare and store the data of the corpus parsed, as a series of query and response sentence pairs and a vocabulary object instance \n",
        "\n",
        "print(\"\\npairs:\") # Output 'pairs' on a new line\n",
        "\n",
        "for pair in pairs[:10]: # For the first '10' sentence pairs in the vocabulary object created, do the following \n",
        "    print(pair) # Output the contents of each sentence pair iterated"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing chatbot model training data...\n",
            "Reading the lines of the newly formatted data file...\n",
            "Read 500105 sentence pairs...\n",
            "Trimmed to 137326 sentence pairs...\n",
            "Counting words...\n",
            "Words counted: 30519\n",
            "\n",
            "pairs:\n",
            "['dont .', 'what ?']\n",
            "['what ?', 'dont eat at the console .']\n",
            "['dont eat at the console .', 'what ? are you my mother ?']\n",
            "['not yet .', 'but hes . . .']\n",
            "['but hes . . .', 'i said no .']\n",
            "['stop the hydraulics .', 'got it .']\n",
            "['is that it ?', 'yeah id say thats it .']\n",
            "['so have you seen simpson ?', 'no why ?']\n",
            "['good morning .', 'good morning .']\n",
            "['thank you .', 'i meant him .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH8Ema4eiDjt"
      },
      "source": [
        "~~~~~\n",
        "Another tactic that is beneficial to achieving faster convergence during\n",
        "training is trimming rarely used words out of our vocabulary. Decreasing\n",
        "the feature space will also soften the difficulty of the function that\n",
        "the model must learn to approximate. We will do this as a two-step\n",
        "process:\n",
        "\n",
        "1) Trim words used under ``MIN_COUNT`` threshold using the ``vocabulary.trim``\n",
        "   function.\n",
        "\n",
        "2) Filter out pairs with trimmed words.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipQE5TPWMxF_"
      },
      "source": [
        "Increase training convergence further by trimming rarely used words from the vocabulary configured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vREMjqctiDjt",
        "outputId": "2e57c67e-346f-4e8b-930a-9c30753f86b4"
      },
      "source": [
        "MIN_COUNT = 3 # Minimum frequency of word occurence for trimming\n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, trim rare occurences of words from a vocabulary object instance\n",
        "def trimRareWords(vocabulary, pairs, MIN_COUNT):\n",
        "    vocabulary.trim(MIN_COUNT) # Function call, trim words from the vocabulary object instance that occur less than the minimum count\n",
        "    \n",
        "    keep_pairs = [] # Intialise an array for the validated pairs kept in the vocabulary\n",
        "    \n",
        "    for pair in pairs: # For each pair in the array of sentence pairs populated, do the following\n",
        "        query_sentence = pair[0] # Initialise and set the query sentence to the first element in each pair list\n",
        "        response_sentence = pair[1] # Initialise and set the response sentence to the second element in each pair list\n",
        "        keep_query = True # Initialise the keep query sentence determiner (keep by default)\n",
        "        keep_response = True # Initialise the keep response sentence determiner (keep by default)\n",
        "        \n",
        "        for word in query_sentence.split(' '): # For each word in the query sentence currently iterated, do the following\n",
        "            if word not in vocabulary.word2index: # If the currently iterated word in the query sentence does not have an index assigned in the word to index dictionary, do the following\n",
        "                keep_query = False # The query sentence for the pair currently iterated contained words that have been trimmed\n",
        "                break # Break from the iteration\n",
        "      \n",
        "        for word in response_sentence.split(' '): # For each word in the response sentence currently iterated, do the following\n",
        "            if word not in vocabulary.word2index: # If the currently iterated word in the response sentence does not have an index assigned in the word to index dictionary, do the following\n",
        "                keep_response = False # The reponse sentence for the pair currently iterated contained words that have been trimmed\n",
        "                break # Break from the iteration\n",
        "\n",
        "        if keep_query and keep_response: # If both query and response sentences were not trimmed, do the following\n",
        "            keep_pairs.append(pair) # Add a new entry in the keep pairs array, for the currently iterated sentence pair that has not been trimmed (only keep pairs that do not contain trimmed word(s))\n",
        "\n",
        "    print(\"Trimmed from {} sentence pairs, to {} [{:.2f}%] of the total sentence pairs...\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs))) # Output the number of rare words trimmed from the vocabulary and its representation as a difference in percent\n",
        "    \n",
        "    return keep_pairs # Return the pairs validated by the rare word trimming process\n",
        "\n",
        "\n",
        "\n",
        "pairs = trimRareWords(vocabulary, pairs, MIN_COUNT) # Trim the rare words from the vocabulary object instance (query and response sentence pairs it contains)\n",
        "\n",
        "\n",
        "\n",
        "# Inspired by: https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7\n",
        "# Function declaration, seperate the prepared sentence pairs into a series of training and evaluation sentence pairs\n",
        "def trainingEvaluationPairs(sentence_pairs, training_ratio, extraction_mode):\n",
        "    training_pairs = [] # Initialise the training pairs array\n",
        "    evaluation_pairs = sentence_pairs # Initialise the evaluation pairs array\n",
        "    \n",
        "    if training_ratio > 90: # If the training ratio is larger than '90', do the following\n",
        "        training_ratio = 90 # Set the training ratio to '90' (percent of all pairs populated)\n",
        "    \n",
        "    if type(training_ratio) is float: # If the training ratio is a floating point storage type, do the following\n",
        "        training_ratio = int(training_ratio) # Cast the training ratio to an integer format (ensures correct indexing and sentence pairs can be proportioned)\n",
        "\n",
        "    number_of_training_pairs = int(len(sentence_pairs) * (training_ratio / 100)) # Calculate the number of sentence pairs reserved for training the chatbot model, relative to the training ratio passed\n",
        "    #number_of_evaluation_pairs = len(sentence_pairs) - number_of_training_pairs\n",
        "\n",
        "    seed(1) # Initialise the seed for randomly generating integer variables\n",
        "\n",
        "    for i in range(0, number_of_training_pairs, 1): # For the number of training pairs determined, do the following\n",
        "        if extraction_mode is \"random\": # If the sentence pair extraction method is randomised, do the following\n",
        "            sentence_pair_index = randint(0, len(evaluation_pairs) - 1) # Generate a random integer bewteen the first and last index of the evaluation pairs array (representing the adjustment to the original sentence pairs passed)\n",
        "\n",
        "        elif extraction_mode is \"ordered\": # Else if the sentence pair extraction method is ordered, do the following\n",
        "            sentence_pair_index = 0 # Set the sentence pair index to the first element in the evaluation pairs array (representing the adjustment to the original sentence pairs passed)\n",
        "\n",
        "        training_pairs.append(evaluation_pairs[sentence_pair_index]) # Append the sentence pair of the current index generated in the evaluation pairs array, to the training pairs array\n",
        "        evaluation_pairs.pop(sentence_pair_index) # Pop the sentence pair appended to the training pairs array, from the evaluation pairs array (switch ownership)\n",
        "\n",
        "    return training_pairs, evaluation_pairs # Return the training and evaluation sentence pair arrays"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kept words: was 30516, now 13776 [0.45%] of words removed...\n",
            "Trimmed from 137326 sentence pairs, to 118640 [0.86%] of the total sentence pairs...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn1WtEPoiDjt"
      },
      "source": [
        "## Prepare Data for Models\n",
        "-----------------------\n",
        "~~~~~~\n",
        "Although we have put a great deal of effort into preparing and massaging our\n",
        "data into a nice vocabulary object and list of sentence pairs, our models\n",
        "will ultimately expect numerical torch tensors as inputs. One way to\n",
        "prepare the processed data for the models can be found in the `seq2seq\n",
        "translation\n",
        "tutorial <https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html>`.\n",
        "\n",
        "In that tutorial, we use a batch size of 1, meaning that all we have to\n",
        "do is convert the words in our sentence pairs to their corresponding\n",
        "indexes from the vocabulary and feed this to the models.\n",
        "\n",
        "However, if you’re interested in speeding up training and/or would like\n",
        "to leverage GPU parallelization capabilities, you will need to train\n",
        "with mini-batches.\n",
        "\n",
        "Using mini-batches also means that we must be mindful of the variation\n",
        "of sentence length in our batches. To accomodate sentences of different\n",
        "sizes in the same batch, we will make our batched input tensor of shape\n",
        "*(max_length, batch_size)*, where sentences shorter than the\n",
        "*max_length* are zero padded after an *EOS_token*.\n",
        "\n",
        "If we simply convert our English sentences to tensors by converting\n",
        "words to their indexes(\\ ``indexesFromSentence``) and zero-pad, our\n",
        "tensor would have shape *(batch_size, max_length)* and indexing the\n",
        "first dimension would return a full sequence across all time-steps.\n",
        "However, we need to be able to index our batch along time, and across\n",
        "all sequences in the batch. Therefore, we transpose our input batch\n",
        "shape to *(max_length, batch_size)*, so that indexing across the first\n",
        "dimension returns a time step across all sentences in the batch. We\n",
        "handle this transpose implicitly in the ``zeroPadding`` function.\n",
        "\n",
        "The ``inputVariation`` function handles the process of converting sentences to\n",
        "tensor, ultimately creating a correctly shaped zero-padded tensor. It\n",
        "also returns a tensor of ``lengths`` for each of the sequences in the\n",
        "batch which will be passed to our decoder later.\n",
        "\n",
        "The ``outputVariation`` function performs a similar function to ``inputVariation``,\n",
        "but instead of returning a ``lengths`` tensor, it returns a binary mask\n",
        "tensor and a maximum target sentence length. The binary mask tensor has\n",
        "the same shape as the output target tensor, but every element that is a\n",
        "*PAD_token* is 0 and all others are 1.\n",
        "\n",
        "``batch2TrainData`` simply takes a bunch of pairs and returns the input\n",
        "and target tensors using the aforementioned functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynw0jy-FNDbO"
      },
      "source": [
        "Prepare the vocabulary for use with the chatbot model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6N8liG3iDjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6f000b-46eb-4c6b-ee17-1c0dd99c8eea"
      },
      "source": [
        "# Function declaration, return the indexes of words belonging to sentences in the vocabulary passed\n",
        "def indexesFromSentence(vocabulary, sentence):\n",
        "    return [vocabulary.word2index[word] for word in sentence.split(' ')] + [EOS_token] # Return the index of each word belonging in the sentences of the vocabulary (plus the EOS token index of '2' as PAD, SOS and EOS tokens are indexed before any word in a vocabulary object instance) \n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, zero pad the sentences of the input batche passed (indexes of words), so that each sentence of is the same length\n",
        "def zeroPadding(input_batch, fillvalue = PAD_token):\n",
        "    return list(itertools.zip_longest(*input_batch, fillvalue = fillvalue)) # Return the list of input batches that are zero padded for the largest size of batch passed\n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, generate a binary matrix representing the masking for the input batch passed (padded words in the batch sequence)\n",
        "def binaryMatrix(input_batch, value = PAD_token):\n",
        "    padding_mask = [] # Initialise an array for the mask representing padded indexes in the input batch passed\n",
        "    \n",
        "    for i, sequence in enumerate(input_batch): # For each sequence of words in the input batch, do the following\n",
        "        padding_mask.append([]) # Add a new entry in the mask array for the current sequence of words iterated in the input batch\n",
        "        \n",
        "        for token in sequence: # For each words token in the sequence, do the following\n",
        "            if token == PAD_token: # If the words token is '0' (padded/ there is no word), do the following\n",
        "                padding_mask[i].append(0) # Add a new entry of '0' (false) in the mask array for the current word in the currently iterated sequence of the input batch\n",
        "            else: # Else if the words token is not '0' (not padded/ there is a word), do the following\n",
        "                padding_mask[i].append(1) # Add a new entry of '1' (true) in the mask array for the current word in the currently iterated sequence of the input batch\n",
        "    \n",
        "    return padding_mask # Return the padding mask array (boolean)\n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, return a padded input sequence (sentence) tensor and their lengths \n",
        "def inputVariation(input_batch, vocabulary):\n",
        "    indexes_batch = [indexesFromSentence(vocabulary, sentence) for sentence in input_batch] # Store the index of each word in every sentence included in the input batch passed, for the instance of vocabulary object\n",
        "    sentence_lengths = torch.tensor([len(indexes) for indexes in indexes_batch]) # Create a tensor and store the lengths of each sentence (sequence) in the batch of indexes populated\n",
        "    padded_list = zeroPadding(indexes_batch) # Function call, store the returning zero padded index list generated for the input batch passed\n",
        "    padded_tensor = torch.LongTensor(padded_list) # Reformat the padded index list as a long tensor\n",
        "    \n",
        "    return padded_tensor, sentence_lengths # Return the padded long tensor of word indexes populated and the lengths of each sentence that it contains (non-padded)\n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, return a padded output sequence (sentence) tensor, padding mask, and the maximum length of any of its sentence \n",
        "def outputVariation(output_batch, vocabulary):\n",
        "    indexes_batch = [indexesFromSentence(vocabulary, sentence) for sentence in output_batch] # Store the index of each word in every sentence included in the output batch passed, for the instance of vocabulary object\n",
        "    max_target_length = max([len(indexes) for indexes in indexes_batch]) # Store the maximum sentence length identified from the outputting batch passed\n",
        "    padded_list = zeroPadding(indexes_batch) # Function call, store the returning zero padded index list generated for the outputting batch passed\n",
        "    padding_mask = binaryMatrix(padded_list) # Compile the zero padded index list generated for the outputting batch passed as a binary matrix (Boolean)\n",
        "    padding_mask = torch.BoolTensor(padding_mask) # Reformat the binary list as a Boolean based tensor representing padded (true) and non-padded (false) indexes\n",
        "    padded_tensor = torch.LongTensor(padded_list) # Reformat the padded index list as a long tensor\n",
        "    \n",
        "    return padded_tensor, padding_mask, max_target_length # Return the padded long tensor of word indexes populated, its representative padding mask and the maximum length of any of its sentences that it contains \n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, convert an input batch of sentence pairs into a targeted tensor (sorted)\n",
        "def batch2TrainData(vocabulary, pair_batch):\n",
        "    pair_batch.sort(key = lambda x: len(x[0].split(\" \")), reverse = True) # Sort the batch of sentence pairs in an descending to ascending order, for every element in their order contained in the array\n",
        "    input_batch, output_batch = [], [] # Initialise an array for the input and output batches of the sentence pairs populated in the pair batch\n",
        "    \n",
        "    for pair in pair_batch: # For each sentence pair populated in the pair batch, do the following\n",
        "        input_batch.append(pair[0]) # Add a new entry in the input batch array of the currently iterated query sentence from the pair batch\n",
        "        output_batch.append(pair[1]) # Add a new entry in the output batch array of the currently iterated response sentence from the pair batch\n",
        "    \n",
        "    padded_tensor_input, sentence_lengths = inputVariation(input_batch, vocabulary) # Function call, store the query sentences of the input batch as a tensor and store the lengths of each of the sentences it contains\n",
        "    padded_tensor_output, padding_mask, max_target_length = outputVariation(output_batch, vocabulary) # Function call, store the response sentences of the target batch as a tensor, store its padding mask and the maximum length of any of its sentences that it contains \n",
        "    \n",
        "    return padded_tensor_input, sentence_lengths, padded_tensor_output, padding_mask, max_target_length # Return the products of the function calls, for the use of training the chatbot\n",
        "\n",
        "\n",
        "\n",
        "# Example for validation\n",
        "small_batch_size = 5 # Define a batch size that is small for validating the batch generating process\n",
        "batches = batch2TrainData(vocabulary, [random.choice(pairs) for _ in range(small_batch_size)]) # Function call, batch the sentence pairs of the vocabulary object instance passed, as a series of data ready to be used to train the chatbot\n",
        "input_batch, sentence_lengths, target_batch, padding_mask, max_target_length = batches # Store the instance of batch object as seperate fields, for each field it contains\n",
        "\n",
        "print(\"Input query:\\n\", input_batch, '\\n') # Output the padded input batch (tensor) of the vocabularys sentence pairs (indexes of words forming the query sentences of the vocabulary object instance)\n",
        "print(\"Sentence lengths:\", sentence_lengths, '\\n') # Output the lengths of each sentence contained in the tensor\n",
        "print(\"Expected response:\\n\", target_batch, '\\n') # Output the padded target batch (tensor) of the vocabularys sentence pairs (indexes of words forming the response sentences of the vocabulary object instance)\n",
        "print(\"Padded mask:\\n\", padding_mask, '\\n') # Ouput the binary mask of the input batch tensor\n",
        "print(\"Maximum sentence length:\", max_target_length, '\\n') # Output the maximum length of any sentence contained in the tensor"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input query:\n",
            " tensor([[ 228,   21, 2115, 1600, 1003],\n",
            "        [ 576,  125,   17,   93,    4],\n",
            "        [ 364,  500,    4, 1297,    2],\n",
            "        [   4,   47,    4,    4,    0],\n",
            "        [ 228,  188,    4,    2,    0],\n",
            "        [ 576,  108,    2,    0,    0],\n",
            "        [   4,  125,    0,    0,    0],\n",
            "        [   2,    2,    0,    0,    0]]) \n",
            "\n",
            "Sentence lengths: tensor([8, 8, 6, 5, 3]) \n",
            "\n",
            "Expected response:\n",
            " tensor([[   5,  108,   31,   31,   64],\n",
            "        [ 238,   26,  726, 8087,  170],\n",
            "        [   6, 1124,  256,    6,  595],\n",
            "        [   2,  125,  250,    2,    6],\n",
            "        [   0,    2,    9,    0,    2],\n",
            "        [   0,    0, 2552,    0,    0],\n",
            "        [   0,    0,  646,    0,    0],\n",
            "        [   0,    0,    4,    0,    0],\n",
            "        [   0,    0,    2,    0,    0]]) \n",
            "\n",
            "Padded mask:\n",
            " tensor([[ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [False,  True,  True, False,  True],\n",
            "        [False, False,  True, False, False],\n",
            "        [False, False,  True, False, False],\n",
            "        [False, False,  True, False, False],\n",
            "        [False, False,  True, False, False]]) \n",
            "\n",
            "Maximum sentence length: 9 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZJVfGbViDjt"
      },
      "source": [
        "## **Define Models**\n",
        "-------------\n",
        "\n",
        "## Sequence-to-sequence (Seq2Seq) Model\n",
        "~~~~~~~~~~~~~\n",
        "\n",
        "The brains of our chatbot is a sequence-to-sequence (seq2seq) model. The\n",
        "goal of a seq2seq model is to take a variable-length sequence as an\n",
        "input, and return a variable-length sequence as an output using a\n",
        "fixed-sized model.\n",
        "\n",
        "`Sutskever et al.` discovered that by using two separate recurrent neural nets together, we can accomplish this task. One RNN acts as an **encoder**, which encodes a variable length input sequence to a fixed-length context vector. \n",
        "In theory, this context vector (the final hidden layer of the RNN) will \n",
        "contain semantic information about the query sentence that is input to the bot. The second RNN is a **decoder**, which takes an input word and the context vector, and returns a guess for the next word in the sequence and a\n",
        "hidden state to use in the next iteration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4Aw2YSJiDjt"
      },
      "source": [
        "## **Encoder Model (RNN)**\n",
        "---------\n",
        "~~~~~~~\n",
        "The encoder RNN iterates through the input sentence one token\n",
        "(e.g. word) at a time, at each time step outputting an “output” vector\n",
        "and a “hidden state” vector. The hidden state vector is then passed to\n",
        "the next time step, while the output vector is recorded. The encoder\n",
        "transforms the context it saw at each point in the sequence into a set\n",
        "of points in a high-dimensional space, which the decoder will use to\n",
        "generate a meaningful output for the given task.\n",
        "\n",
        "At the heart of our encoder is a multi-layered Gated Recurrent Unit,\n",
        "invented by `Cho et al.` in 2014. We will use a bidirectional variant of the GRU, meaning that there are essentially two independent RNNs: one that is fed the input sequence in normal sequential order, and one that is fed the input sequence in reverse order. The outputs of each network are summed at each time step. Using a bidirectional GRU will give us the advantage of encoding both\n",
        "past and future context.\n",
        "\n",
        "Note that an ``embedding`` layer is used to encode our word indices in\n",
        "an arbitrarily sized feature space. For our models, this layer will map\n",
        "each word to a feature space of size *hidden_size*. When trained, these\n",
        "values should encode semantic similarity between similar meaning words.\n",
        "\n",
        "Finally, if passing a padded batch of sequences to an RNN module, we\n",
        "must pack and unpack padding around the RNN pass using\n",
        "``nn.utils.rnn.pack_padded_sequence`` and\n",
        "``nn.utils.rnn.pad_packed_sequence`` respectively.\n",
        "\n",
        "**Computation Graph:**\n",
        "\n",
        "   1) Convert word indexes to embeddings.\n",
        "   2) Pack padded batch of sequences for RNN module.\n",
        "   3) Forward pass through GRU.\n",
        "   4) Unpack padding.\n",
        "   5) Sum bidirectional GRU outputs.\n",
        "   6) Return output and final hidden state.\n",
        "\n",
        "**Inputs:**\n",
        "\n",
        "-  ``input_sequence``: batch of input sentences; shape=\\ *(max_length,\n",
        "   batch_size)*\n",
        "-  ``input_lengths``: list of sentence lengths corresponding to each\n",
        "   sentence in the batch; shape=\\ *(batch_size)*\n",
        "-  ``hidden``: hidden state; shape=\\ *(n_layers x num_directions,\n",
        "   batch_size, hidden_size)*\n",
        "\n",
        "**Outputs:**\n",
        "\n",
        "-  ``contextual_outputs``: output features from the last hidden layer of the GRU\n",
        "   (sum of bidirectional outputs); shape=\\ *(max_length, batch_size,\n",
        "   hidden_size)*\n",
        "-  ``hidden_state``: updated hidden state from GRU; shape=\\ *(n_layers x\n",
        "   num_directions, batch_size, hidden_size)*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5t70EPRNQ9D"
      },
      "source": [
        "Create the Recurrent Neural Network representing the encoder for the encoder-decoder sequence-to-sequence model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igm2SICRaCYj"
      },
      "source": [
        "rnn_module = \"GRU\" # Initialise the RNN module string, representing the neural network module used by the encoder-decoder RNN model\r\n",
        "mlp_active = {\"encoder\": False, \"decoder\": False} # Initialise the MLP NN Boolean variable, representing whether MLP NN is used on the embedding layer of the encoder and decoder models"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ySIJT9i-qpY"
      },
      "source": [
        "# CNN implementations discovered\r\n",
        "# https://github.com/pyturn/Deep-Learning-Codes/blob/master/Model%20Interpretation/IMDB%20CNN.ipynb\r\n",
        "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\r\n",
        "# https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html?highlight=neural%20networks\r\n",
        "\r\n",
        "# Inspired by: https://gist.github.com/spro/c87cc706625b8a54e604fb1024106556\r\n",
        "# Class convolutional neural network\r\n",
        "class CNN(nn.Module):\r\n",
        "    \r\n",
        "    # Function declaration, initialise the class (constructor)\r\n",
        "    def __init__(self, input_size, hidden_size, output_size, number_of_layers = 1):\r\n",
        "        super(CNN, self).__init__() # Set the 'CNN' class to be a super class (parent class from which other classes inherit from)\r\n",
        "        self.input_size = input_size # Initialise the input size\r\n",
        "        self.hidden_size = hidden_size # Initialise the size of the hidden state of the encoder\r\n",
        "        self.output_size = output_size # intialise the output size of the CNN\r\n",
        "        self.number_of_layers = number_of_layers # Initialise the number of recurrent layers used by the encoder RNN\r\n",
        "\r\n",
        "        self.c1 = nn.Conv1d(in_channels = input_size, out_channels = hidden_size, kernel_size = 2, stride = 1, padding  = 0) # Initialise the first one-dimensional convolution layer\r\n",
        "        self.p1 = nn.AvgPool1d(2) # Initialise the first one-dimensional convolution pooling layer (average operator) (progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the CNN; pooling layer operates on each feature (convolution) map independently)\r\n",
        "        self.c2 = nn.Conv1d(in_channels = hidden_size, output_channels = hidden_size, kernel_size = 1, stride = 1, padding = 0) # Initialise the second one-dimensional convolution layer\r\n",
        "        self.p2 = nn.AvgPool1d(2) # Initialise the second one-dimensional convolution pooling layer (average operator) (progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the CNN; pooling layer operates on each feature (convolution) map independently)\r\n",
        "  \r\n",
        "        self.out = nn.Linear(hidden_size, output_size) # Initialise the output fully-connected linear layer (hidden vector to output vector)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    # Function declaration, propagate through the CNN (forward pass) and produce an output variable (feed-forward layer)\r\n",
        "    def forward(self, input):\r\n",
        "        # (sentence length, batch size, hidden size) --> (batch size, sentence length, hidden size)\r\n",
        "        input = input.transpose(0, 1) # Retranspose the position of the first and second indexed arrays, in the weighting tensor \r\n",
        "\r\n",
        "        # Feed the input sentence through the CNN\r\n",
        "        convolution = self.c1(input) # Convolve the input sentence\r\n",
        "        pool = self.p1(convolution) # Resolve the spatial size of the convolution output\r\n",
        "        convolution = self.c2(pool) # Convolve the pooled output of the original convolution output\r\n",
        "        pool = self.p2(convolution) # Resolve the spatial size of the convolution output\r\n",
        "\r\n",
        "        # (batch size, sentence length, hidden size) --> (sentence length, batch size, hidden size)\r\n",
        "        pool = pool.transpose(0, 1) # Retranspose the position of the first and second indexed arrays, in the weighting tensor \r\n",
        "        \r\n",
        "        self.out(pool) # Linearly transform the convolution output (from one vector space to another that respects the underlying (linear) structure of each vector space)\r\n",
        "\r\n",
        "        return output # Return the output"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXThEnvYSvrG"
      },
      "source": [
        "# Multilayer perceptron implementation\r\n",
        "# https://towardsdatascience.com/a-simple-starter-guide-to-build-a-neural-network-3c2cf07b8d7c\r\n",
        "# https://towardsdatascience.com/multi-layer-perceptron-usingfastai-and-pytorch-9e401dd288b8\r\n",
        "# https://medium.com/biaslyai/pytorch-introduction-to-neural-network-feedforward-neural-network-model-e7231cff47cb\r\n",
        "# https://towardsdatascience.com/a-simple-starter-guide-to-build-a-neural-network-3c2cf07b8d7c\r\n",
        "\r\n",
        "# Class multilayer perceptron neural network (deep/ multilayer feed-forward model)\r\n",
        "class MultilayerPerceptronNN(nn.Module):\r\n",
        "    \r\n",
        "    # Function declaration, initialise the class (constructor)\r\n",
        "    def __init__(self, input_size, hidden_size):\r\n",
        "        super(MultilayerPerceptronNN, self).__init__() # Set the 'MultilayerPerceptronNN' class to be a super class (parent class from which other classes inherit from)\r\n",
        "        \r\n",
        "        # ReLu the best activation function: https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\r\n",
        "        # The rectified linear activation function or ReLU for short, is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero \r\n",
        "        # It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance\r\n",
        "        self.relu = nn.ReLU() # Initialise a non-linear ReLu layer (allows backpropagation through the network (weighting parameter adjustment) and  allows stacking of multiple layers of neurons to create a deep neural network)\r\n",
        "        \r\n",
        "        # Inputs -> [input layer] -> outputs -> [hidden layer] -> outputs -> [output layer] -> final outputs (MLP)\r\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) # Initialise the first fully-connected linear layer (input vector to hidden vector)\r\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size) # Initialise the second fully-connected linear layer (hidden vector to output vector)\r\n",
        "        #self.fc3 = nn.Linear(hidden_size, input_size) # Initialise the third fully-connected linear layer (hidden vector to input vector)\r\n",
        "        \r\n",
        "        \r\n",
        "\r\n",
        "    # Function declaration, propagate through the MLP model (forward pass) and produce an output variable (feed-forward layer)\r\n",
        "    # A node, also called a neuron or perceptron, is a computational unit that has one or more weighted input connections, a transfer function that combines the inputs in some way, and an output connection\r\n",
        "    # Nodes are then organized into layers to comprise a network\r\n",
        "    # A single-layer artificial neural network, also called a single-layer, has a single layer of nodes, as its name suggests\r\n",
        "    # Each node in the single layer connects directly to an input variable and contributes to an output variable\r\n",
        "    #\r\n",
        "    # A single-layer network can be extended to a multiple-layer network, referred to as a Multilayer perceptron\r\n",
        "    # A MLP is an artificial neural network with more than a single layer\r\n",
        "    # It has an input layer that connects to the input variables, one or more hidden layers, and an output layer that produces the output variables\r\n",
        "    def forward(self, input_data, apply_softmax = False, dropout = 0.1):\r\n",
        "        output = self.fc1(input_data) # Linearly transform the input data (from one vector space to another that respects the underlying (linear) structure of each vector space)\r\n",
        "        output = self.relu(output) # Apply the rectified linear unit (ReLu) function element-wise (activation function - transform the summed weighted input from the node into the activation of the node or output for that input)\r\n",
        "        output = self.fc2(F.dropout(output, p = dropout)) # Linearly transform the ReLu output (from one vector space to another that respects the underlying (linear) structure of each vector space)\r\n",
        "        #output = self.relu(output) # Apply the rectified linear unit (ReLu) function element-wise (activation function - transform the summed weighted input from the node into the activation of the node or output for that input)\r\n",
        "        #output = self.fc3(F.dropout(output, p = dropout)) # Linearly transform the ReLu output (from one vector space to another that respects the underlying (linear) structure of each vector space)\r\n",
        "        \r\n",
        "        if apply_softmax == True: # If the output is set to be softmaxed (normalized probability - converts a vector of numbers into a vector of probabilities, where the probabilities of each value are proportional to the relative scale of each value in the vector) scores (with added dimension)\r\n",
        "            output = F.softmax(output, dim = 1) # Softmax the output (produce a probability)\r\n",
        "\r\n",
        "        return output # Return the output"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wF8cbnGiDjt"
      },
      "source": [
        "# Class encoder recurrent neural network\n",
        "class EncoderRNN(nn.Module):\n",
        "\n",
        "    # Function declaration, initialise the class (constructor)\n",
        "    def __init__(self, hidden_size, embedding, number_of_layers = 1, dropout = 0, rnn_module = \"GRU\", mlp_active = False):\n",
        "        super(EncoderRNN, self).__init__() # Set the 'EncoderRNN' class to be a super class (parent class from which other classes inherit from)\n",
        "        self.number_of_layers = number_of_layers # Initialise the number of recurrent layers used by the encoder RNN\n",
        "        self.hidden_size = hidden_size # Initialise the size of the hidden state of the encoder\n",
        "        self.embedding = embedding # Initialise the embedding layer of the encoder\n",
        "        self.contextual_outputs = None # Initialise the RNN contextual outputs\n",
        "        self.hidden_state = None # Initialise the RNN hidden state\n",
        "\n",
        "        self.rnn_module = rnn_module # Initialise the RNN module string representing the active RNN module\n",
        "        self.mlp_active = mlp_active[\"encoder\"] # Initialise the MLP active Boolean variable, representing whether MLP NN is used on the embedding layer of the encoder model\n",
        "        self.gru = nn.GRU # Initialise the GRU RNN module for the encoder model\n",
        "        self.lstm = nn.LSTM # Initialise the LSTM RNN module for the encoder model\n",
        "        self.mlp = MultilayerPerceptronNN(hidden_size, hidden_size) # Initialise the MLP NN for the encoder model\n",
        "        self.rnn = nn.RNN # Initialise the Elman RNN for the decoder model\n",
        "        self.cnn = None # Initialise the CNN for the encoder model\n",
        "\n",
        "        if self.rnn_module is \"GRU\": # If the RNN module being used is GRU, do the following\n",
        "            # Initialize a gated recurrent unit (GRU) RNN for an input sequence; the input size and hidden size parameters are both set to 'hidden_size' as our input size is a word embedding with the number of features equal to the 'hidden_size'\n",
        "            self.gru = nn.GRU(hidden_size, hidden_size, number_of_layers, dropout = (0 if number_of_layers == 1 else dropout), bidirectional = True, batch_first = True)\n",
        "            # bidirectional GRU RNN (true) - enables previous time steps and later time steps to make predictions about the current state (output vector appropriated to the input passed)\n",
        "            # dropout - if non-zero, introduces a dropout layer (randomly sets input units to '0' with a frequency of rate at each step during training time, which helps prevent data overfitting) on the outputs of each GRU layer except the last layer, with dropout probability equal to the dropout configured\n",
        "            # hidden size - the number of elements in the hidden state (representation of previous inputs which helps to retain information on what the model saw in the previous time step when processing the current time steps information, for potentialising a different output for the same input, depending on previous inputs in the series.\n",
        "            #\n",
        "            # GRU RNN's are able to solve the vanishing gradient problem by using an update gate and a reset gate. The update gate controls information that flows into memory, and the reset gate controls the information that flows out of memory.\n",
        "            # The update gate and reset gate are two vectors that decide which information will get passed on to the output. They can be trained to keep information from the past or remove information that is irrelevant to the prediction. \n",
        "        \n",
        "        # https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
        "        # https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/\n",
        "        # https://www.youtube.com/watch?v=0_PgWWmauHk\n",
        "        elif self.rnn_module is \"LSTM\": # Else if the RNN module being used is LSTM, do the following\n",
        "            # Initialize a long short-term memory (LSTM) RNN for an input sequence; the input size and hidden size parameters are both set to 'hidden_size' as our input size is a word embedding with the number of features equal to the 'hidden_size'\n",
        "            self.lstm = nn.LSTM(hidden_size, hidden_size, number_of_layers, dropout = (0 if number_of_layers == 1 else dropout), bidirectional = True)\n",
        "\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
        "        # http://mnemstudio.org/neural-networks-elman.htm\n",
        "        # https://www.hindawi.com/journals/cin/2014/724317/\n",
        "        # https://www.data-blogger.com/2017/05/17/elman-rnn-implementation-in-tensorflow/\n",
        "        elif self.rnn_module is \"RNN\": # Else if the RNN module being used is Elman RNN, do the following\n",
        "            # Initialize an Elman RNN for an input sequence; the input size and hidden size parameters are both set to 'hidden_size' as our input size is a word embedding with the number of features equal to the 'hidden_size'\n",
        "            self.rnn = nn.RNN(hidden_size, hidden_size, number_of_layers, dropout = (0 if number_of_layers == 1 else dropout), bidirectional = True, nonlinearity = \"tanh\")\n",
        "            \n",
        "\n",
        "\n",
        "    # Function declaration, propagate through the RNN (forward pass) and produce a context (output) and a hidden state vector (feed-forward layer)\n",
        "    def forward(self, input_sequence, input_lengths, hidden_state = None):\n",
        "        # Convert word indexes to embeddings (low-dimensional, learned continuous vector representation of discrete (indexes) variables into which you can translate high-dimensional vectors)\n",
        "        embedded = self.embedding(input_sequence)\n",
        "\n",
        "        # Inspired by: https://machinelearningmastery.com/what-are-word-embeddings/\n",
        "        # Multilayer perceptron NN\n",
        "        if self.mlp_active is True: # If the MLP NN is set to be used, do the following\n",
        "            embedded = self.mlp(embedded, False, 0.0) # Feed the word embeddings through the MLP NN\n",
        "\n",
        "        # Inspired by: https://gist.github.com/spro/c87cc706625b8a54e604fb1024106556\n",
        "        # Convolutional neural network\n",
        "        #self.cnn = CNN(len(input_lengths), self.hidden_size, len(input_lengths)) # Initialise the CNN for the encoder model\n",
        "        #embedded = self.cnn(embedded) # Feed the input sentence through the CNN\n",
        "        \n",
        "        # Pack padded batch of sequences (sentences) for the RNN module\n",
        "        packedPaddedSequence = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        \n",
        "        if self.rnn_module is \"LSTM\": # If the RNN module being used is LSTM, do the following\n",
        "            h0 = torch.zeros(len(packedPaddedSequence), len(input_lengths), self.hidden_size).to(device) # Initialise the intial hidden state of the LSTM RNN\n",
        "            c0 = torch.zeros(len(packedPaddedSequence), len(input_lengths), self.hidden_size).to(device) # Initialise the initial cell state of the LSTM RNN\n",
        "\n",
        "            # Forward pass through the LSTM RNN for the input sequence passed\n",
        "            self.contextual_outputs, self.hidden_state = self.lstm(packedPaddedSequence, (h0, c0))\n",
        "\n",
        "        elif self.rnn_module is \"GRU\": # Else if the RNN module being used is GRU, do the following\n",
        "            # Forward pass through the GRU RNN for the input sequence passed\n",
        "            self.contextual_outputs, self.hidden_state = self.gru(packedPaddedSequence, hidden_state)\n",
        "        \n",
        "        elif self.rnn_module is \"RNN\": # Else if the RNN module being used is Elman RNN, do the following\n",
        "            h0 = torch.zeros(self.number_of_layers * 2, len(input_lengths), self.hidden_size).to(device) # Initialise the intial hidden state of the Elman RNN\n",
        "            \n",
        "            # Forward pass through the Elman RNN for the input sequence passed\n",
        "            self.contextual_outputs, self.hidden_state = self.rnn(packedPaddedSequence, h0)\n",
        "        \n",
        "        # Unpack the padded batch of sequences (sentences) for the RNN module\n",
        "        self.contextual_outputs, _ = nn.utils.rnn.pad_packed_sequence(self.contextual_outputs)\n",
        "        # Sum the bidirectional GRU RNN outputs (past and future GRU outputs summed to represent the semantic information of the input sequence passed)\n",
        "        self.contextual_outputs = self.contextual_outputs[:, :, :self.hidden_size] + self.contextual_outputs[:, :, self.hidden_size:]\n",
        "\n",
        "        return self.contextual_outputs, self.hidden_state # Return the semantic information of the words passed (context) and the hidden state vector (information retained for the models previously handled words, for their context in the input sequence passed) "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS78y5hyiDjt"
      },
      "source": [
        "## **Decoder Model (RNN)**\n",
        "---------\n",
        "~~~~~~~~\n",
        "The decoder RNN generates the response sentence in a token-by-token\n",
        "fashion. It uses the encoder’s context vectors, and internal hidden\n",
        "states to generate the next word in the sequence. It continues\n",
        "generating words until it outputs an *EOS_token*, representing the end\n",
        "of the sentence. A common problem with a vanilla seq2seq decoder is that\n",
        "if we rely soley on the context vector to encode the entire input\n",
        "sequence’s meaning, it is likely that we will have information loss.\n",
        "This is especially the case when dealing with long input sequences,\n",
        "greatly limiting the capability of our decoder.\n",
        "\n",
        "To combat this, `Bahdanau et al.' created an “attention mechanism” that allows the decoder to pay attention to certain parts of the input sequence, rather than using the entire fixed context at every step.\n",
        "\n",
        "At a high level, attention is calculated using the decoder’s current\n",
        "hidden state and the encoder’s outputs. The output attention weights\n",
        "have the same shape as the input sequence, allowing us to multiply them\n",
        "by the encoder outputs, giving us a weighted sum which indicates the\n",
        "parts of encoder output to pay attention to. \n",
        "\n",
        "`Luong et al.` improved upon Bahdanau et al.’s groundwork by creating “Global attention”. The key difference is that with “Global attention”, we consider all of the encoder’s hidden states, as opposed to Bahdanau et al.’s “Local\n",
        "attention”, which only considers the encoder’s hidden state from the\n",
        "current time step. Another difference is that with “Global attention”,\n",
        "we calculate attention weights, or energies, using the hidden state of\n",
        "the decoder from the current time step only. Bahdanau et al.’s attention\n",
        "calculation requires knowledge of the decoder’s state from the previous\n",
        "time step. Also, Luong et al. provides various methods to calculate the\n",
        "attention energies between the encoder output and decoder output which\n",
        "are called “score functions”.\n",
        "\n",
        "Overall, the Global attention mechanism can be summarized by the\n",
        "following figure. Note that we will implement the “Attention Layer” as a\n",
        "separate ``nn.Module`` called ``Attn``. The output of this module is a\n",
        "softmax normalized weights tensor of shape *(batch_size, 1,\n",
        "max_length)*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQwk85KzNpiL"
      },
      "source": [
        "Create the Thang Luong attention mechanism layer for the Recurrent Neural Network representing the decoder for the encoder-decoder sequence-to-sequence model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b14X2EUZiDjt"
      },
      "source": [
        "# Class attention (Loung attention layer (decoding) - attention allows the decoder network to focus on different parts of the encoders outputs for every step of the decoders own outputs)\n",
        "class Attention(nn.Module):\n",
        "  \n",
        "    # Function declaration, initialise the class (constructor)\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attention, self).__init__() # Set the 'Attention' class to be a super class (parent class from which other classes inherit from)\n",
        "        self.method = method # Initialise the methods for calculating attention weights\n",
        "        self.relu = nn.ReLU() # Initialise a non-linear ReLu layer (allows backpropagation through the network (weighting parameter adjustment) and  allows stacking of multiple layers of neurons to create a deep neural network)\n",
        "\n",
        "        if self.method not in ['dot', 'general', 'concat', 'mlp', 'cnn']: # If the method passed is not a recgonised method for calculating attention weights, do the following\n",
        "            raise ValueError(self.method, \"is not an appropriate attention weight calculation method.\") # Throw an error, acknowledging that the method passed is an inappropriate attention weight calculation method\n",
        "        \n",
        "        self.hidden_size = hidden_size # Initialise the size of the hidden state of the decoder\n",
        "        \n",
        "        if self.method == 'general': # If the method passed is recognised as the 'general' weighted combination scoring method, do the following\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size) # Initialise the tensor representing the linear transformation of the decoder hidden state vector size (from one vector space to another that respects the underlying (linear) structure of each vector space)\n",
        "        \n",
        "        elif self.method == 'concat': # If the method passed is recognised as the 'concat' weighted combination scoring method, do the following\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size) # Initialise the tensor representing the linear transformation of the decoder hidden state vector size (from one vector space to another that respects the underlying (linear) structure of each vector space) \n",
        "            self.weight = nn.Parameter(torch.FloatTensor(hidden_size)) # Intialise the tensor representing the weighting used by the concatenation weighted combination scoring method\n",
        "\n",
        "        elif self.method == 'mlp': # If the method passed is recognised as the 'mlp' weighted combination scoring method, do the following\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size) # Initialise the tensor representing the linear transformation of the decoder hidden state vector size (from one vector space to another that respects the underlying (linear) structure of each vector space)\n",
        "\n",
        "        elif self.method == 'cnn': # If the method passed is recognised as the 'cnn' weighted combination scoring method, do the following\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size) # Initialise the tensor representing the linear transformation of the decoder hidden state vector size (from one vector space to another that respects the underlying (linear) structure of each vector space)\n",
        "            self.conv1 = nn.Conv1d(in_channels = 10, out_channels = 10, kernel_size = 1, stride = 1, padding = 0) # Initialise a one-dimensional convolutional neural network layer\n",
        "\n",
        "    # Function declaration, dot-product scoring method for calculating attention weights\n",
        "    def dotScore(self, hidden_state, encoder_output): \n",
        "        # For the dot-product scoring method, no weights or linear layers are involved\n",
        "        \n",
        "        return torch.sum(hidden_state * encoder_output, dim = 2) # Return the sum of all elements in the decoder hidden state vector mulitplied by the encoder output (input sequence - sentences) passed\n",
        "\n",
        "\n",
        "\n",
        "    # Function declaration, general scoring method for calculating attention weights \n",
        "    def generalScore(self, hidden_state, encoder_output): \n",
        "        # For general scoring, the decoder hidden state is passed through linear layers to introduce a weight matrix\n",
        "        energy = self.attn(encoder_output) \n",
        "         \n",
        "        return torch.sum(hidden_state * energy, dim = 2) # Return the sum of all elements in the decoder hidden state vector multiplied by their weightings\n",
        "\n",
        "\n",
        "\n",
        "    # Function declaration, concatenation scoring method for calculating attention weights\n",
        "    def concatScore(self, hidden_state, encoder_output): \n",
        "        # For concatenation scoring, the decoder hidden state and encoder outputs are concatenated first\n",
        "        energy = self.attn(torch.cat((hidden_state.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        \n",
        "        return torch.sum(self.weight * energy, dim = 2) # Return the sum of the decoder hidden state and encoder output concatenation multiplied by their weightings\n",
        "\n",
        "\n",
        "\n",
        "    # Function declaration, multilayer perceptron method for calculating attention weights \n",
        "    def mlpScore(self, hidden_state, encoder_output): \n",
        "        # For the multilayer perceptron scoring method, a series of linear and non-linear layers are involved\n",
        "        energy = self.attn(encoder_output) # Linearly transform the input data (from one vector space to another that respects the underlying (linear) structure of each vector space)\n",
        "        energy = self.relu(energy) # Apply the rectified linear unit (ReLu) function element-wise (activation function - transform the summed weighted input from the node into the activation of the node or output for that input)\n",
        "        energy = self.attn(energy) # Linearly transform the ReLu output (from one vector space to another that respects the underlying (linear) structure of each vector space)\n",
        "        \n",
        "        return torch.sum(hidden_state * energy, dim = 2) # Return the sum of all elements in the decoder hidden state vector multiplied by their weightings\n",
        "        \n",
        "    \n",
        "\n",
        "    # Function declaration, convolutional neural network method for calculating attention weights \n",
        "    def cnnScore(self, hidden_state, encoder_output): \n",
        "        # For the convolutional neural network scoring method, a series of linear and non-linear layers are involved\n",
        "  \n",
        "        #10, 64, 500 (sentence length, batch size, hidden size) --> 64, 10, 500 (batch size, sentence length, hidden size)\n",
        "        #encoder_output = encoder_output.transpose(0, 1) # Retranspose the position of the first and second indexed arrays, in the weighting tensor \n",
        "        #print(encoder_output.shape) # Output the shape of the weighting tensor\n",
        "        \n",
        "        #energy = self.conv1(encoder_output) # Feed the input sentence through the CNN\n",
        "        #print(energy.shape) # Output the shape of the weighting tensor\n",
        "        \n",
        "        # Next steps: \n",
        "        # Apply zero-padding to the convolution layer, to fit the output shape of the convolution to the shape expected by the decoder model; \n",
        "        # Retranspose the weighting tensor to its original shape, for the weighted sum to be accepted by the decoder model\n",
        "        # Apply linear transformation to the weighting tensor, to rescale the size of the weighting tensor\n",
        "\n",
        "        #64, 10, 500 (batch size, sentence length, hidden size) --> 64, 1, 499 (batch size, output channel, hidden size)\n",
        "        #energy = energy.transpose(0, 1) # Retranspose the position of the first and second indexed arrays, in the weighting tensor \n",
        "        #print(energy.shape) # Output the shape of the weighting tensor\n",
        "\n",
        "        energy = self.attn(energy) # Linearly transform the convolution output (from one vector space to another that respects the underlying (linear) structure of each vector space)\n",
        "        #print(energy.shape) # Output the shape of the weighting tensor\n",
        "\n",
        "        return torch.sum(hidden_state * energy, dim = 2) # Return the sum of all elements in the decoder hidden state vector multiplied by their weightings\n",
        "\n",
        "\n",
        "\n",
        "    # Function declaration, calculate the attention weights for the encoder RNN outputs (context vector) to create weighted combinations of words chosen by the decoder as the words output by the chatbot (feed-forward layer)\n",
        "    def forward(self, hidden_state, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the method passed\n",
        "        if self.method == 'general': # If the method passed is recognised as the 'general' weighted combination scoring method, do the following\n",
        "            attn_energies = self.generalScore(hidden_state, encoder_outputs) # Function call, calculate weighted combination scores using the general scoring method\n",
        "\n",
        "        elif self.method == 'concat': # Else if the method passed is recognised as the 'concat' weighted combination scoring method, do the following\n",
        "            attn_energies = self.concatScore(hidden_state, encoder_outputs) # Function call, calculate weighted combination scores using the concatenation scoring method\n",
        "\n",
        "        elif self.method == 'dot': # Else if the method passed is recognised as the 'dot' weighted combination scoring method, do the following\n",
        "            attn_energies = self.dotScore(hidden_state, encoder_outputs) # Function call, calculate weighted combination scores using the dot-product scoring method\n",
        "\n",
        "        elif self.method == 'mlp': # Else if the method passed is recognised as the 'mlp' weighted combination scoring method, do the following\n",
        "            attn_energies = self.mlpScore(hidden_state, encoder_outputs) # Function call, calculate weighted combination scores using the multilayer perceptron scoring method\n",
        "\n",
        "        elif self.method == 'cnn': # Else if the method passed is recognised as the 'cnn' weighted combination scoring method, do the following\n",
        "            attn_energies = self.cnnScore(hidden_state, encoder_outputs) # Function call, calculate weighted combination scores using the convolutional neural network scoring method\n",
        "\n",
        "        attn_energies = attn_energies.t() # Transpose the 'max_length' and 'batch_size' dimensions\n",
        "\n",
        "        return F.softmax(attn_energies, dim = 1).unsqueeze(1) # Return the softmax normalized probability (converts a vector of numbers into a vector of probabilities, where the probabilities of each value are proportional to the relative scale of each value in the vector) scores (with added dimension)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-g4OUWliDjt"
      },
      "source": [
        "~~~~~~~\n",
        "\n",
        "Now that we have defined our attention submodule, we can implement the\n",
        "actual decoder model. For the decoder, we will manually feed our batch\n",
        "one time step at a time. This means that our embedded word tensor and\n",
        "GRU output will both have shape *(1, batch_size, hidden_size)*.\n",
        "\n",
        "**Computation Graph:**\n",
        "\n",
        "   1) Get embedding of current input word.\n",
        "   2) Forward through unidirectional GRU.\n",
        "   3) Calculate attention weights from the current GRU output from (2).\n",
        "   4) Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector.\n",
        "   5) Concatenate weighted context vector and GRU output using Luong eq. 5.\n",
        "   6) Predict next word using Luong eq. 6 (without softmax).\n",
        "   7) Return output and final hidden state.\n",
        "\n",
        "**Inputs:**\n",
        "\n",
        "-  ``input_step``: one time step (one word) of input sequence batch;\n",
        "   shape=\\ *(1, batch_size)*\n",
        "-  ``last_hidden``: final hidden layer of GRU; shape=\\ *(n_layers x\n",
        "   num_directions, batch_size, hidden_size)*\n",
        "-  ``encoder_outputs``: encoder model’s output; shape=\\ *(max_length,\n",
        "   batch_size, hidden_size)*\n",
        "\n",
        "**Outputs:**\n",
        "\n",
        "-  ``output``: softmax normalized tensor giving probabilities of each\n",
        "   word being the correct next word in the decoded sequence;\n",
        "   shape=\\ *(batch_size, vocabulary.num_words)*\n",
        "-  ``hidden``: final hidden state of GRU; shape=\\ *(n_layers x\n",
        "   num_directions, batch_size, hidden_size)*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC_fp5ZzN81O"
      },
      "source": [
        "Create the Recurrent Neural Network representing the decoder for the encoder-decoder sequence-to-sequence model, which equips the Thang Luong attention mechanism layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNC18ZuFiDjt"
      },
      "source": [
        "## **Define Training Procedure**\n",
        "-------------------------\n",
        "\n",
        "## Masked loss\n",
        "~~~~~~~~~~~\n",
        "Since we are dealing with batches of padded sequences, we cannot simply\n",
        "consider all elements of the tensor when calculating loss. We define\n",
        "``maskedNLLLoss`` to calculate our loss based on our decoder’s output\n",
        "tensor, the target tensor, and a binary mask tensor describing the\n",
        "padding of the target tensor. This loss function calculates the average\n",
        "negative log likelihood of the elements that correspond to a *1* in the\n",
        "mask tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGdB7striDjt"
      },
      "source": [
        "# Class Luong attention decoder RNN - attention allows the decoder network to focus on different parts of the encoders outputs for every step of the decoders own outputs)\n",
        "class LuongAttentionDecoderRNN(nn.Module):\n",
        "    \n",
        "    # Function declaration, initialise the class (constructor)\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, number_of_layers = 1, dropout = 0.1, rnn_module = \"GRU\"):\n",
        "        super(LuongAttentionDecoderRNN, self).__init__() # Set the 'LuongAttentionDecoderRNN' class to be a super class (parent class from which other classes inherit from)\n",
        "        self.attn_model = attn_model # Initialise the attention decoder model\n",
        "        self.hidden_size = hidden_size # Initialise the size of the hidden state of the decoder\n",
        "        self.output_size = output_size # Initialise the size of the attention decoder output (softmaxed normalised tensor - softmax the concetenation of the hidden state and context vectors produced by the decoder)\n",
        "        self.number_of_layers = number_of_layers # Initialise the number of recurrent layers used by the decoder RNN \n",
        "        self.dropout = dropout # Initialise the dropout layer (randomly zero parts of the input sequences passed with a given probability (here 0.1) for fuzzing inputs to prevent overfitting; used towards the end of the network to purposely increase sampling variety for training the chatbot model)\n",
        "        self.rnn_output = None # Initialise the RNN output\n",
        "        self.hidden_state = None # Initialise the RNN hidden state\n",
        "        self.rnn_module = rnn_module # Initialise the RNN module string representing the active RNN module\n",
        "        \n",
        "        self.mlp_active = mlp_active[\"decoder\"] # Initialise the MLP active Boolean variable, representing whether MLP NN is used on the embedding layer of the decoder model\n",
        "        self.gru = nn.GRU # Initialise the GRU RNN module for the decoder model\n",
        "        self.lstm = nn.LSTM # Initialise the LSTM RNN module for the decoder model\n",
        "        self.mlp = MultilayerPerceptronNN(hidden_size, hidden_size) # Initialise the MLP NN for the decoder model\n",
        "        self.rnn = nn.RNN # Initialise the Elman RNN for the decoder model\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding # Initialise the embedding layer of the decoder (representing words using a dense vector representation; easier for machine learning on large inputs like sparse vectors (removes the many zeros from padding - unwanted space) representing words)\n",
        "        self.embedding_dropout = nn.Dropout(dropout)# Initialise the dropout of the embedding layer to the dropout of the droupout layer configured \n",
        "        \n",
        "        if self.rnn_module is \"GRU\": # If the RNN module being used is GRU, do the following\n",
        "            # GRU RNN's are able to solve the vanishing gradient problem by using an update gate and a reset gate. The update gate controls information that flows into memory, and the reset gate controls the information that flows out of memory.\n",
        "            # The update gate and reset gate are two vectors that decide which information will get passed on to the output. They can be trained to keep information from the past or remove information that is irrelevant to the prediction. \n",
        "            self.gru = nn.GRU(hidden_size, hidden_size, number_of_layers, dropout = (0 if number_of_layers == 1 else dropout)) # Initialize a gated recurrent unit (GRU) RNN for an input sequence; the input size and hidden size parameters are both set to 'hidden_size' as our input size is a word embedding with the number of features equal to the 'hidden_size'\n",
        "        \n",
        "        elif self.rnn_module is \"LSTM\": # Else if the RNN module being used is LSTM, do the following\n",
        "            self.lstm = nn.LSTM(hidden_size, hidden_size, number_of_layers * 2, dropout = (0 if number_of_layers == 1 else dropout)) # Initialize a long short-term memory (LSTM) RNN for an input sequence; the input size and hidden size parameters are both set to 'hidden_size' as our input size is a word embedding with the number of features equal to the 'hidden_size'\n",
        "                \n",
        "        elif self.rnn_module is \"RNN\": # Else if the RNN module being used is Elman RNN, do the following\n",
        "            self.rnn = nn.RNN(hidden_size, hidden_size, number_of_layers, dropout = (0 if number_of_layers == 1 else dropout), nonlinearity = \"tanh\") # Initialize a Elman RNN for an input sequence; the input size and hidden size parameters are both set to 'hidden_size' as our input size is a word embedding with the number of features equal to the 'hidden_size'\n",
        "            \n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size) # Initialise the tensor representing the linear transformation of the decoder hidden state vector size (from one vector space to another that respects the underlying (linear) structure of each vector space)  \n",
        "        self.output = nn.Linear(hidden_size, output_size) # Initialise the tensor representing the linear transformation of the decoder hidden state vector size and the attention decoder output tensor (from one vector space to another that respects the underlying (linear) structure of each vector space)  \n",
        "        self.attn = Attention(attn_model, hidden_size) # Create and initialise an 'Attention' super class object instance\n",
        "\n",
        "\n",
        "\n",
        "    # Function declaration, compile the tensor that holds the probability of each word being the next word in the decoded sequence (feed-forward layer)\n",
        "    def forward(self, input_word, last_hidden_state, encoder_outputs):\n",
        "        # Note: this is executed one step (word) at a time\n",
        "        # Get the embedding of current word input from the decoded target word \n",
        "        embedded = self.embedding(input_word) # Store the embedding of the word input from the decoded sequence (aims to quantify and categorize semantic similarities between words based on their distributional properties in large samples of vocabulary)\n",
        "        embedded = self.embedding_dropout(embedded) # Apply the embedding dropout on the word embedded (increase the variety of the words semantic information for reducing overfitting - arbitarily amplify its probability as the correct next word in the response sequence)\n",
        "\n",
        "        # Inspired by: https://machinelearningmastery.com/what-are-word-embeddings/\n",
        "        # Multilayer perceptron NN\n",
        "        if self.mlp_active is True: # If the MLP NN is set to be used, do the following\n",
        "            embedded = self.mlp(embedded, False, 0.0) # Feed the word embeddings through the MLP NN\n",
        "\n",
        "        if self.rnn_module is \"GRU\": # If the RNN module being used is GRU, do the following\n",
        "            self.rnn_output, self.hidden_state = self.gru(embedded, last_hidden_state) # Forward through the unidirectional GRU RNN, returning the next hidden state vector and output (semantic similarities between words based on their distributional properties)\n",
        "        \n",
        "        elif self.rnn_module is \"LSTM\": # Else if the RNN module being used is LSTM, do the following\n",
        "            self.rnn_output, self.hidden_state = self.lstm(embedded, last_hidden_state) # Forward pass through the unidirectional LSTM RNN, returning the next hidden state vector and output (semantic similarities between words based on their distributional properties)\n",
        "        \n",
        "        elif self.rnn_module is \"RNN\": # Else if the RNN module being used is Elman RNN, do the following\n",
        "            self.rnn_output, self.hidden_state = self.rnn(embedded, last_hidden_state) # Forward pass through the unidirectional Elman RNN, returning the next hidden state vector and output (semantic similarities between words based on their distributional properties) \n",
        "  \n",
        "        attn_weights = self.attn(self.rnn_output, encoder_outputs) # Calculate attention weights from the current GRU output\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # Multiply the attention weights to the encoder outputs to get new weighted sum context vector (batch matrix-matrix product of matrices; each matrix must be 3D tensors containing the same number of matrices)\n",
        "        \n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        self.rnn_output = self.rnn_output.squeeze(0) # Store the compact version of the GRU output (the output array, but with all or a subset of the dimensions of length '1' removed - remove unused subsequent arrays within the array)\n",
        "        context = context.squeeze(1) # Store the compact version of the context vector (the context vector, but with all or a subset of the dimensions of length '1' removed - remove unused subsequent arrays within the array)\n",
        "        concatenate_input = torch.cat((self.rnn_output, context), 1) # Concatenate the GRU output and context vector \n",
        "        concatenate_output = torch.tanh(self.concat(concatenate_input)) # Remap the tensors values representing the concatenation of the GRU output and context vector\n",
        "        # The hyperbolic tangent function outputs in the range (-1, 1), thus mapping strongly negative inputs to negative values. Unlike the sigmoid function, only near-zero values are mapped to near-zero outputs, and this solves the vanishing gradients problem to some extent \n",
        "        # The hyperbolic tangent function is differentiable at every point and its derivative comes out to be 1 - tanh^2(x) \n",
        "        # Since the expression involves the tanh function, its value can be reused to make the backward propagation faster\n",
        "      \n",
        "        # Predict the next word using Luong eq. 6\n",
        "        output = self.output(concatenate_output) # Calculate the linear combination of the tensor that represents the concatenation of the GRU output and context vector (multiplying each term by a constant and adding the results (e.g. a linear combination of x and y would be any expression of the form ax + by, where a and b are constants))\n",
        "        output = F.softmax(output, dim = 1) # Calculate the softmax normalized probability (converts a vector of numbers into a vector of probabilities, where the probabilities of each value are proportional to the relative scale of each value in the vector) scores (with added dimension)\n",
        "        \n",
        "        return output, self.hidden_state # Return the output and final hidden state of the decoder RNN"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS25OnIXOWtO"
      },
      "source": [
        "Calculate the loss in accuracy between the predicted and expected responses of the chatbot model, for batches of sentence pairs exisiting in training data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjIcd6xFiDju"
      },
      "source": [
        "# Function declaration, evaluate and optimise the attention weights configured to minimize the error in predicting accurate responses for the given data model (negative log likelihood loss (NLLLoss))\n",
        "def maskedNLLLoss(decoder_outputs, target_outputs, target_outputs_padding_mask):\n",
        "    masked_target_outputs_total = target_outputs_padding_mask.sum() # Store the sum of all the target outputs that are masked (zero padded)\n",
        "    crossEntropy = -torch.log(torch.gather(decoder_outputs, 1, target_outputs.view(-1, 1)).squeeze(1)) # Calculate the raw cross entropy loss (performance of the algorithm modelling the data output - predicted output vs actual output in the training data set)\n",
        "    # Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1\n",
        "    # Cross-entropy loss increases as the predicted probability diverges from the actual label\n",
        "    # So predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high loss value (perfect model would have a logarithmic loss of 0)\n",
        "    # \n",
        "    # Each predicted probability is compared to the actual class output value (0 or 1) and a score is calculated that penalizes the probability based on the distance from the expected value \n",
        "    # The penalty is logarithmic, offering a small score for small differences (0.1 or 0.2) and enormous score for a large difference (0.9 or 1.0)\n",
        "\n",
        "    masked_loss = crossEntropy.masked_select(target_outputs_padding_mask).mean() # Calculate the final cross entropy loss (averaging the tensor representing the cross entropy loss of the target outputs, for the target outputs that are not zero padded (true or '1') using the mask generated for the training batch of sentences)\n",
        "    masked_loss = masked_loss.to(device) # Set the masked NLL loss model to be executed using the active hardware accelerator (device options CUDA (GPU and CPU) or CPU)\n",
        "    \n",
        "    return masked_loss, masked_target_outputs_total.item() # Return the calculated loss of the data model and the number of target outputs that are masked (zero padded)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wucay8qCiDju"
      },
      "source": [
        "## **Single Training Iteration**\n",
        "---------\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "The ``train`` function contains the algorithm for a single training\n",
        "iteration (a single batch of inputs).\n",
        "\n",
        "We will use a couple of clever tricks to aid in convergence:\n",
        "\n",
        "-  The first trick is using **teacher forcing**. This means that at some\n",
        "   probability, set by ``teacher_forcing_ratio``, we use the current\n",
        "   target word as the decoder’s next input rather than using the\n",
        "   decoder’s current guess. This technique acts as training wheels for\n",
        "   the decoder, aiding in more efficient training. However, teacher\n",
        "   forcing can lead to model instability during inference, as the\n",
        "   decoder may not have a sufficient chance to truly craft its own\n",
        "   output sequences during training. Thus, we must be mindful of how we\n",
        "   are setting the ``teacher_forcing_ratio``, and not be fooled by fast\n",
        "   convergence.\n",
        "\n",
        "-  The second trick that we implement is **gradient clipping**. This is\n",
        "   a commonly used technique for countering the “exploding gradient”\n",
        "   problem. In essence, by clipping or thresholding gradients to a\n",
        "   maximum value, we prevent the gradients from growing exponentially\n",
        "   and either overflow (NaN), or overshoot steep cliffs in the cost\n",
        "   function.\n",
        "\n",
        "**Sequence of Operations:**\n",
        "\n",
        "   1) Forward pass entire input batch through encoder.\n",
        "   2) Initialize decoder inputs as SOS_token, and hidden state as the encoder's final hidden state.\n",
        "   3) Forward input batch sequence through decoder one time step at a time.\n",
        "   4) If teacher forcing: set next decoder input as the current target; else: set next decoder input as current decoder output.\n",
        "   5) Calculate and accumulate loss.\n",
        "   6) Perform backpropagation.\n",
        "   7) Clip gradients.\n",
        "   8) Update encoder and decoder model parameters.\n",
        "\n",
        "\n",
        ".. Note ::\n",
        "\n",
        "  PyTorch’s RNN modules (``RNN``, ``LSTM``, ``GRU``) can be used like any\n",
        "  other non-recurrent layers by simply passing them the entire input\n",
        "  sequence (or batch of sequences). We use the ``GRU`` layer like this in\n",
        "  the ``encoder``. The reality is that under the hood, there is an\n",
        "  iterative process looping over each time step calculating hidden states.\n",
        "  Alternatively, you ran run these modules one time-step at a time. In\n",
        "  this case, we manually loop over the sequences during the training\n",
        "  process like we must do for the ``decoder`` model. As long as you\n",
        "  maintain the correct conceptual model of these modules, implementing\n",
        "  sequential models can be very straightforward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C7JDkIyO1V4"
      },
      "source": [
        "Train the chatbot model for one iteration, using a single batch of inputs (a query sentence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6HE3688iDju"
      },
      "source": [
        "# Function declaration, train the chatbot model with a single batch of input sentences (one iteration for one batch) for updating (reevaluating and optimizing) the attention weights configured to minimize the error in predicting accurate responses for the given data model\n",
        "def train(input_batch, sentence_lengths, target_batch, padding_mask, max_target_length, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, gradient_clip, max_length = MAX_LENGTH):\n",
        "\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad() # Initialise the gradient of descent for the encoder RNN\n",
        "    decoder_optimizer.zero_grad() # Initialise the gradient of descent for the decoder RNN\n",
        "\n",
        "    input_batch = input_batch.to(device) # Set the input batch to be handled using the active hardware accelerator (device options CUDA (GPU and CPU) or CPU)\n",
        "    target_batch = target_batch.to(device) # Set the target batch to be handled using the active hardware accelerator (device options CUDA (GPU and CPU) or CPU)\n",
        "    padding_mask = padding_mask.to(device) # Set the padding mask of the input batch to be handled using the active hardware accelerator (device options CUDA (GPU and CPU) or CPU)\n",
        "\n",
        "    sentence_lengths = sentence_lengths.to(\"cpu\") # Set the sentence packing processes of the RNN's when training the algorithm, to be executed using the CPU hardware accelerator (mandatory)\n",
        "    # When training RNN's (GRU), it is difficult to batch the variable length sequences\n",
        "    # For example: if the length of sequences in a size 8 batch is [4,6,8,5,4,3,7,8], you will pad all the sequences and that will result in 8 sequences of length 8\n",
        "    # You would end up doing 64 computations (8x8), but you needed to do only 45 computations\n",
        "    # Moreover, if you wanted to applicate something advanced like a bidirectional-RNN, it would be harder to do batch computations just by padding and you might end up doing more computations than required\n",
        "    #\n",
        "    # Instead, PyTorch allows us to pack the sequence, internally packed sequence is a tuple of two lists\n",
        "    # One contains the elements of sequences (sentences) and the other contains the batch size at each step (iteration)\n",
        "    # This is helpful in recovering the actual sequences as well as telling the RNN's what the batch size at each time step is; this can then be passed to the RNN's, where they will internally optimize the computations\n",
        "\n",
        "    accumulated_loss = 0 # Initialise the accumulated loss for the input batch passed\n",
        "    masked_losses = [] # Initialise the masked losses array for the input batch passed\n",
        "    masked_target_output_loss_total = 0 # Initialise the total number of losses totalled for the masked target outputs\n",
        "    \n",
        "    # Forward pass the entire input batch of sentences through the encoder RNN\n",
        "    encoder_outputs, encoder_hidden = encoder(input_batch, sentence_lengths)\n",
        "    \n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]]) # Create initial decoder input (start with SOS tokens for each sentence in the input batch passed)\n",
        "    decoder_input = decoder_input.to(device) # Set the decoder input to be handled using the active hardware accelerator (device options CUDA (GPU and CPU) or CPU)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoders final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.number_of_layers] \n",
        "\n",
        "    using_teacher_forcing = True if random.random() < teacher_forcing_ratio else False # Determine if teacher forcing is being used for the current training iteration\n",
        "    # Teacher forcing is a strategy for training recurrent neural networks that uses model output from a prior time step as an input\n",
        "    # Functions by using the actual or expected output from the training dataset at the current time step, as input in the next time step, rather than the output generated by the network\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step (one of multiple repetitions of the RNN) at a time\n",
        "    for timestep in range(max_target_length): # For each word (timestep) in the maximum length of any sequence (zero padded sentence) in the input batch passed, do the following\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs) # Calculate the output and hidden state of the decoder RNN \n",
        "            \n",
        "        if using_teacher_forcing: # If teacher forcing is being used (use actual or expected output from the training dataset as opposed to output generated by the encoder RNN), do the following\n",
        "            # Teacher forcing: next decoder input is the decoders current target output (expected word of the current target batch)\n",
        "            decoder_input = target_batch[timestep].view(1, -1) \n",
        "            \n",
        "        else: # If teacher forcing is not being used (use output generated by the encoder RNN as opposed to the actual or expected output from the training dataset), do the following\n",
        "            # No teacher forcing: next input is decoders own current output (largest element)\n",
        "            _, topi = decoder_output.topk(1) # Return the word with the highest probability as the correct next word in the response sequence, from the output generated by the decoder\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]]) # Set the decoders input to the decoders current output, word-for-word (token-by-token)\n",
        "            decoder_input = decoder_input.to(device) # Set the decoder input to be handled using the active hardware accelerator (device options CUDA (GPU and CPU) or CPU)\n",
        "            \n",
        "        # Calculate and accumulate loss\n",
        "        masked_loss, masked_target_outputs_total = maskedNLLLoss(decoder_output, target_batch[timestep], padding_mask[timestep]) # Calculate the masked loss and the total number of masked target outputs considered in the loss, for the current timestep (word)\n",
        "        accumulated_loss += masked_loss # Accumulate the masked loss for predicting the next word in the iterated sequence of the input batch passed\n",
        "        masked_losses.append(masked_loss.item() * masked_target_outputs_total) # Add a new entry into the masked losses array for the masked loss calculated for the current timestep (word) \n",
        "        masked_target_output_loss_total += masked_target_outputs_total # Accumulate the total number of losses generated for the masked target outputs of the decoder RNN\n",
        "\n",
        "    # Perform backpropagation\n",
        "    accumulated_loss.backward() # Compute the gradient of loss, for all losses calculated and accumulated\n",
        "    # Propagate the accumulated loss back into the neural network to know how much of the loss every node is responsible for, \n",
        "    # and subsequently updating the weights in such a way that minimizes the loss by giving the nodes with higher error rates lower weights (vice versa)\n",
        "\n",
        "    # Clip gradients: gradients of descent are modified to remain in-place (clipped)\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), gradient_clip) \n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), gradient_clip) \n",
        "    # Gradient clipping is a technique to prevent exploding gradients (gradient becomes too large and error gradients accumulate, resulting in an unstable network) in RNNs\n",
        "    # With gradient clipping, a pre-determined gradient threshold is introduced, and then gradients normals that exceed this threshold are scaled down to match the normal \n",
        "    # This prevents any gradient to have normal greater than the threshold and thus the gradients are clipped\n",
        "\n",
        "    # Adjust encoder-decoder model (RNNs) weighting parameters\n",
        "    encoder_optimizer.step() # Apply (update) the gradients of descent to the encoder RNN's weighting parameters (optimise for minimizing loss - descending gradient) \n",
        "    decoder_optimizer.step() # Apply (update) the gradients of descent to the decoder RNN's weighting parameters (optimise for minimizing loss - descending gradient)\n",
        "\n",
        "    return sum(masked_losses) / masked_target_output_loss_total # Return the average loss of information for the data model configured"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbWXFimKiDju"
      },
      "source": [
        "## **Training Iterations**\n",
        "---------\n",
        "~~~~~~~~~~~~~~~~~~~\n",
        "It is finally time to tie the full training procedure together with the\n",
        "data. The ``trainingIterations`` function is responsible for running\n",
        "``number_of_iterations`` of training given the passed models, optimizers, data,\n",
        "etc. This function is quite self explanatory, as we have done the heavy\n",
        "lifting with the ``train`` function.\n",
        "\n",
        "One thing to note is that when we save our model, we save a tarball\n",
        "containing the encoder and decoder state_dicts (parameters), the\n",
        "optimizers’ state_dicts, the loss, the iteration, etc. Saving the model\n",
        "in this way will give us the ultimate flexibility with the checkpoint.\n",
        "After loading a checkpoint, we will be able to use the model parameters\n",
        "to run inference, or we can continue training right where we left off.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEFMZQitPJnH"
      },
      "source": [
        "Execute the training function performing a single interation of training for the chatbot model, iteratively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wHfFk_sjPyU"
      },
      "source": [
        "# Function declaration, calculate the time elapsed since a given instance of time was initially recorded\n",
        "def timeElapsed(time_start):\n",
        "    time_now = time.time() # Store the time since the system-defined Epoch (timed event) was established\n",
        "    seconds_passed = time_now - time_start # Calculate the difference between the current and previously stored time points (seconds)\n",
        "    minutes_passed = math.floor(seconds_passed / 60) # Reformat the difference in time to be factored by minutes \n",
        "    seconds_passed -= minutes_passed * 60 # Calculate the difference between the time points in seconds, for accumulating the next minute passed  \n",
        "    \n",
        "    return '%d(m) %d(s)' % (minutes_passed, seconds_passed) # Return the minutes and seconds elapsed,  since the "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRyH4HGoiDju"
      },
      "source": [
        "# Function declaration, train the model configured for appropriating its configuration for bettering the response accuracy of the live state of the chatbot\n",
        "def trainingIterations(model_name, vocabulary, sentence_pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_number_of_layers, decoder_number_of_layers, save_directory, \n",
        "                       number_of_training_iterations, batch_size, print_every, save_every, gradient_clip, corpus_name, load_filename, all_losses, plot_every):\n",
        "\n",
        "    # Load batches of query and response sequences (sentences) for each iteration of the training process, from the vocabulary populated\n",
        "    training_batches = [batch2TrainData(vocabulary, [random.choice(sentence_pairs) for _ in range(batch_size)]) for _ in range(number_of_training_iterations)]\n",
        "\n",
        "    # Initialization\n",
        "    print('Initializing...') # Output that the training process is in the initialization state\n",
        "    start_iteration = 1 # Initialise the starting iteration of the chatbot models training process\n",
        "    print_loss = 0 # Initialise the accumulated loss for the input batch passed, to be output\n",
        "    plot_loss = 0 # Initialise the accumulated loss for the input batch passed, to be plotted\n",
        "    \n",
        "    if load_filename: # If the chatbot models training process is being resumed from a loaded checkpoint, do the following\n",
        "        start_iteration = checkpoint['iteration'] + 1 # Set the starting iteration of the chatbot models training process to be the iteration proceeding the checkpoint (iteration) loaded\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Training...\") # Output that the chatbot model is being trained\n",
        "    \n",
        "    start_time = time.time() # Store the time since the system-defined Epoch (timed event) was established\n",
        "\n",
        "    for iteration in range(start_iteration, number_of_training_iterations + 1): # For the current iteration of the chatbot models training process, do the following\n",
        "        training_batch = training_batches[iteration - 1] # Manage the batch of training sequences being used to train the chatbot model (start iteration = 1, training batch starting index = 0)\n",
        "        \n",
        "        # Extract the fields from the training batch of query and response sentences\n",
        "        input_batch, sentence_lengths, target_batch, padding_mask, max_target_length = training_batch\n",
        "\n",
        "        # Execute an iteration of training with a batch of query and response sentences\n",
        "        loss = train(input_batch, sentence_lengths, target_batch, padding_mask, max_target_length, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, gradient_clip) # Function call, train the chatbot model with a single batch of input sentences and return the masked loss calculated\n",
        "        print_loss += loss # Accumulate the loss of accuracy generated for the word predicted next in the response sequence (predicted vs actual/ expected), for output\n",
        "        plot_loss += loss # Accumulate the loss of accuracy generated for the word predicted next in the response sequence (predicted vs actual/ expected), for plot figures\n",
        "\n",
        "        # Output the training processes progress\n",
        "        if iteration % print_every == 0: # For each training iteration corresponding to the output frequency, do the following\n",
        "            print_loss_average = print_loss / print_every # Calculate the average loss to be output for the current batch\n",
        "            print(\"Iteration: {}   Percent complete: {:.1f}%   Average loss: {:.4f}   Time elapsed: {}\".format(iteration, iteration / number_of_training_iterations * 100, print_loss_average, timeElapsed(start_time))) # Output the completion and average loss calculated for the current iteration of the models (seq2seq) training process\n",
        "            print_loss = 0 # Reset the accumulated loss of information being output\n",
        "\n",
        "        # Save a restorable checkpoint for every save frequency succeeded\n",
        "        if (iteration % save_every == 0): # For each training iteration corresponding to the save frequency, do the following\n",
        "            directory = os.path.join(save_directory, model_name, corpus_name, '{}-{}_{}'.format(encoder_number_of_layers, decoder_number_of_layers, hidden_size)) # Define a file directory for saving the current state of the chatbot models training process\n",
        "            \n",
        "            if not os.path.exists(directory): # If the file directory defined does not exist, do the following\n",
        "                os.makedirs(directory) # Create a file directory for the filepath passed\n",
        "            \n",
        "            # Export the current state of the chatbot models training process\n",
        "            #torch.save({\n",
        "                #'iteration': iteration, # Output the current iteration of the training process\n",
        "                #'encoder_state': encoder.state_dict(), # Output the current state of the encoder RNN\n",
        "                #'decoder_state': decoder.state_dict(), # Output the current state of the decoder RNN\n",
        "                #'encoder_optimizer': encoder_optimizer.state_dict(), # Output the current state of the encoder RNNs gradient descent configuration\n",
        "                #'decoder_optimizer': decoder_optimizer.state_dict(), # Output the current state of the decoder RNNs gradient descent configuration\n",
        "                #'loss': loss, # Output the current masked loss calculated for the word predicted as the correct next word in the sequence\n",
        "                #'vocabulary_dictionary': vocabulary.__dict__, # Output the current state of the vocabuluary configured for the chatbot model\n",
        "                #'embedding': embedding.state_dict() # Output the current word embedding of the sentence pairs representing the training batch\n",
        "            #}, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint'))) # Export the configuration to the directory passed and for the name of the training iteration succeeded\n",
        "\n",
        "        # Plot the loss calculated, for the duration of the chatbot models training process\n",
        "        if iteration % plot_every == 0: # For each training iteration corresponding to the plot frequency, do the following\n",
        "            all_losses.append(plot_loss / plot_every) # Store the average loss, for every iteration passed (considering the plot frequency) whilst training the model \n",
        "            plot_loss = 0 # Reset the accumulated loss of information being plot"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqQ3QqXoiDju"
      },
      "source": [
        "## **Define Decoding Evaluation**\n",
        "-----------------\n",
        "\n",
        "### Greedy decoding\n",
        "~~~~~~~~~~~~~~~\n",
        "Greedy decoding is the decoding method that we use during training when\n",
        "we are **NOT** using teacher forcing. In other words, for each timestep, \n",
        "we simply choose the word from ``decoder_output`` with the highest\n",
        "softmax value. This decoding method is optimal on a single timestep\n",
        "level.\n",
        "\n",
        "To facilite the greedy decoding operation, we define a\n",
        "``GreedySearchDecoder`` class. When run, an object of this class takes\n",
        "an input sequence (``input_sequence``) of shape *(input_sequence length, 1)*, a\n",
        "scalar input length (``input_length``) tensor, and a ``max_response_length`` to\n",
        "bound the response sentence length. The input sentence is evaluated\n",
        "using the following:\n",
        "\n",
        "   1) Forward input through encoder model.\n",
        "   2) Prepare encoder's final hidden layer to be first hidden input to the decoder.\n",
        "   3) Initialize decoder's first input as SOS_token.\n",
        "   4) Initialize tensors to append decoded words to.\n",
        "   5) Iteratively decode one word token at a time:\n",
        "       a) Forward pass through decoder.\n",
        "       b) Obtain most likely word token and its softmax score.\n",
        "       c) Record token and score.\n",
        "       d) Prepare current token to be next decoder input.\n",
        "   6) Return collections of word tokens and scores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3SkWNbOSbsN"
      },
      "source": [
        "Define how the chatbot model decodes the encoded input (when teacher forcing is not being used - use output generated by the encoder RNN as opposed to the actual or expected output from the training dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNnvfDi6iDju"
      },
      "source": [
        "# Class greedy search decoder, select the most probable word (highest softmax value) from the chatbot models vocabulary, at each decoding timestep (output) as the candidate to the output sequence (response sentence)\n",
        "class GreedySearchDecoder(nn.Module):\n",
        "    \n",
        "  # Function declaration, initialise the class (constructor)\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__() # Set the 'GreedySearchDecoder' class to be a super class (parent class from which other classes inherit from)\n",
        "        self.encoder = encoder # Initialise an encoder model (RNN) object instance\n",
        "        self.decoder = decoder # Initialise a decoder model (RNN) object instance \n",
        "\n",
        "\n",
        "\n",
        "  # Function declaration, determine the decoded response sentence, appropriated to the input sequence passed (feed-forward layer)\n",
        "    def forward(self, input_sequence, input_sentence_length, max_response_sentence_length):\n",
        "        # Forward the input sequence (sentence) passed, through the encoder model (RNN) to return the semantic information of the words (context vector) and hidden state (information retained for the models previously handled words, for their context in the input sequence passed)\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_sequence, input_sentence_length)\n",
        "\n",
        "        # Prepare encoders final hidden layer to be first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:decoder.number_of_layers] \n",
        "        # Hidden layer is located between the input and output of the algorithm, in which the function applies weights to the inputs and directs them through an activation function as the output\n",
        "\n",
        "        decoder_input = torch.ones(1, 1, device = device, dtype = torch.long) * SOS_token # Initialise the decoder input with a 'SOS_token' (start-of-sequence - start of the response sentence)\n",
        "        \n",
        "        all_tokens = torch.zeros([0], device = device, dtype = torch.long) # Initialise a tensor to append the decoded words to (words calculated with the highest probability for being the next correct word in the response sequence)\n",
        "        all_scores = torch.zeros([0], device = device) # Initialise a tensor representing the score of each word decoded\n",
        "        \n",
        "        # Iteratively decode one word (token) for each timestep and generate a series of appropriate words, collectively forming the response sentence for its maximum length passed\n",
        "        for _ in range(max_response_sentence_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs) # Forward pass through the decoder model (RNN), producing the output (word) and current hidden state for the words already decoded \n",
        "            decoder_score, decoder_input = torch.max(decoder_output, dim = 1) # Obtain most likely word (token) and its softmax score (probability of being the correct next word in the response sequence)\n",
        "            \n",
        "            # Store the word (token) and its probability (score)\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim = 0) # Concatenate the current word decoded with all the words decoded\n",
        "            all_scores = torch.cat((all_scores, decoder_score), dim = 0) # Concatenate the score of the word decoded with all the scores of words decoded\n",
        "            \n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0) # Set the current word (token) to be the next decoder input (add a dimension)\n",
        "        \n",
        "        return all_tokens, all_scores # Return the series of most appropriate words (tokens of words - a string of contiguous characters between two spaces) and their correpsonding scores"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXR8EaiviDju"
      },
      "source": [
        "## **Evaluate Input Text**\n",
        "---------\n",
        "~~~~~~~~~~~~~~~~\n",
        "Now that we have our decoding method defined, we can write functions for\n",
        "evaluating a string input sentence. The ``evaluate`` function manages\n",
        "the low-level process of handling the input sentence. We first format\n",
        "the sentence as an input batch of word indexes with *batch_size == 1*. We\n",
        "do this by converting the words of the sentence to their corresponding\n",
        "indexes, and transposing the dimensions to prepare the tensor for our\n",
        "models. We also create a ``lengths`` tensor which contains the length of\n",
        "our input sentence. In this case, ``lengths`` is scalar because we are\n",
        "only evaluating one sentence at a time (batch_size == 1). Next, we obtain\n",
        "the decoded response sentence tensor using our ``GreedySearchDecoder``\n",
        "object (``searcher``). Finally, we convert the response’s indexes to\n",
        "words and return the list of decoded words.\n",
        "\n",
        "``evaluateInput`` acts as the user interface for our chatbot. When\n",
        "called, an input text field will spawn in which we can enter our query\n",
        "sentence. After typing our input sentence and pressing *Enter*, our text\n",
        "is normalized in the same way as our training data, and is ultimately\n",
        "fed to the ``evaluate`` function to obtain a decoded output sentence. We\n",
        "loop this process, so we can keep chatting with our bot until we enter\n",
        "either “exit” or “quit” or \"bye\" and confirm this choice.\n",
        "\n",
        "Finally, if a sentence is entered that contains a word that is not in\n",
        "the vocabulary, we handle this gracefully by printing an error message\n",
        "and prompting the user to enter another sentence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhznn4TBPoU-"
      },
      "source": [
        "Evaluate the input sequence (sentence) before feeding it into the chatbot model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahz3NAUSiDju"
      },
      "source": [
        "# Function declaration, evaluate the input sequence (query sentence)\n",
        "def evaluate(encoder, decoder, searcher, vocabulary, input_sentence, max_sentence_length = MAX_LENGTH):\n",
        "    # Format the input sentence as a batch of indexes representing representing their containing words\n",
        "    indexes_batch = [indexesFromSentence(vocabulary, input_sentence)] # Convert each word in the input sequence to its correpsonding index, according to the vocabulary (if stored)\n",
        "    \n",
        "    input_sentence_length = torch.tensor([len(indexes) for indexes in indexes_batch]) # Create a tensor representing the length of the input sequence (sentence)\n",
        "    \n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1) # Transpose the dimensions of the input batch to match the chatbot models configuration\n",
        "   \n",
        "    input_batch = input_batch.to(device) # Set the input batch (batch of word indexes composing the sentence) to be handled using the active hardware accelerator (device options CUDA (GPU and CPU) or CPU)\n",
        "    input_sentence_length = input_sentence_length.to(\"cpu\") # Set the length of the input sentence to be handled using the CPU hardware accelerator\n",
        "    \n",
        "    # Decode the input sentence with the greedy search decoder (searcher)\n",
        "    tokens, scores = searcher(input_batch, input_sentence_length, max_sentence_length) # Decode the input sentence using the greedy search decoder, returning the response sequence as a series of tokens and their softmax scores\n",
        "    decoded_words = [vocabulary.index2word[token.item()] for token in tokens] # Convert each index in the output sequence to its correpsonding word (or token explicity), according to the vocabulary (if stored)\n",
        "    \n",
        "    return decoded_words # Return the array of tokens (words and punctuation) forming the response sentence of the chatbot model, for the input sentence passed \n",
        "\n",
        "\n",
        "\n",
        "# Function declaration, evaluate the input sequence (query sentence) and generate an appropriate response to output (response sentence); also handle the termination of the chatbot model evaluation process\n",
        "def evaluateInput(encoder, decoder, searcher, vocabulary, scripted_input):\n",
        "    \n",
        "    if scripted_input == False: # If the chatbot model is being evalauted using live input, do the following\n",
        "        input_sentence = '' # Initialise the string representing the input sentence passed to the chatbot model for processing\n",
        "        name = '' # Initialise the string representing the name of the user\n",
        "        input_choice = '' # Initialise the string representing the choice of termination for the chatbot model evaluation\n",
        "        evaluate_input = True # Initialise the variable (Boolean) representing the evaluation state of the chatbot model (evaluate input by default)\n",
        "        terminate_chat_words = \"exit bye quit\" # Intialise the terminate chat words string\n",
        "\n",
        "        print('Bot: What would you like me to refer to you as?') # Output that the chatbot expects the user to provide a name for it to refer to\n",
        "        name = input('> ') # Handle the input of the user, representing the users name\n",
        "        print('Bot: Hello', ''.join((name, '!')), 'What can I help you with?') # Output that the chatbot is ready to handle input (queries) for providing responses to\n",
        "\n",
        "        while(evaluate_input): # While loop (execute the chatbot model evaluation until the loop is broken from)\n",
        "            try: # Execute the following functionality, cautious of error callbacks being issued\n",
        "                input_sentence = input('> ') # Input a query sentence for the chatbot to produce a response for\n",
        "                \n",
        "                if terminate_chat_words.find(input_sentence.lower()) != -1: # If the input sequence is a terminate chat word, regardless of its case, do the following \n",
        "                    print('Bot: Are you sure you want to terminate me?') # Output that the chatbot model evaluation is being terminated\n",
        "                  \n",
        "                    while(True): # While loop (execute the choice of termination fucntionlaity until the loop is broken from)\n",
        "                        input_choice = input('> ') # Input a choice for determining whether the chatbots evaluation is terminated or not\n",
        "\n",
        "                        if 'n' in input_choice.lower(): # If the input choice contains the character 'n', regardless of its case, do the following\n",
        "                            print('Bot: I see you have changed course... What else can I help you with then?') # Output that the chatbot model is available to handle additional input\n",
        "                      \n",
        "                            break # Break from the loop\n",
        "                        elif 'y' in input_choice.lower(): # Else if the input choice contains the character 'y', regardless of its case, do the following\n",
        "                            evaluate_input = False # Terminate the chatbot models evaluation process (stop loop)\n",
        "\n",
        "                            break # Break from the loop\n",
        "                    \n",
        "                        else: # Else if the input choice does not contain the characters 'n' or 'y', regardless of its case, do the following\n",
        "                            print('Bot: That is not an option! Try again', ''.join((name, '.'))) # Output that the chatbot model is available to handle additional input\n",
        "\n",
        "                else: # Else if the input sequence is not 'exit' or 'quit' or 'bye', regardless of its case, do the following \n",
        "                    # Normalise the input sentence (Unicode to ASCII encoding for the chatbot model to handle)\n",
        "                    input_sentence = normalizeString(input_sentence)\n",
        "                    \n",
        "                    # Function call, spell check and correct the input sentence (query)\n",
        "                    input_sentence = vocabulary.spellCheckQuery(input_sentence)\n",
        "                    \n",
        "                    # Evaluate the input sentence, to produce a response sentence that has been approproated to the input (query) sentence \n",
        "                    output_words = evaluate(encoder, decoder, searcher, vocabulary, input_sentence)\n",
        "                    \n",
        "                    # Format and print the response sequence generated by the chatbot model\n",
        "                    output_words[:] = [word_token for word_token in output_words if not (word_token == 'EOS' or word_token == 'PAD')] # Compile the sequence of words in the order compiled, discarding the end-of-sentence and padding (zeros) tokens \n",
        "                    print('Bot:', ' '.join(output_words)) # Output the response sentence generated by the chatbot model\n",
        "\n",
        "            except KeyError as error: # Handle errors for words that are not recognised by the chatbot model (do not exist in the vocabulary configured)\n",
        "                  print(\"Error: Encountered unknown word: {}\".format(error)) # Output the word that was input and identified as being unrecognised, for the vocabulary configured for the chatbot model\n",
        "\n",
        "        print('Bot: You chose to terminate me! Goodbye', ''.join((name, '.'))) # Output that the chatbot model evaluation is being terminated\n",
        "    \n",
        "    else: # Else if the chatbot model is being evalauted using predetermined input (scripted), do the following\n",
        "        scripted_sentences = [\"Hello\", \"What's up?\", \"Who are you?\", \"Where am I?\", \"Where are you from?\"] # Initialise the series of scripted sentences for the chatbot to respond to\n",
        "    \n",
        "        for index in range(len(scripted_sentences)): # For each scripted sentence passed to the chatbot model to produce a response to, do the following\n",
        "            # Normalise the input sentence (Unicode to ASCII encoding for the chatbot model to handle)\n",
        "            sentence = normalizeString(scripted_sentences[index])\n",
        "            # Evaluate the input sentence, to produce a response sentence that has been approproated to the input (query) sentence \n",
        "            output_words = evaluate(encoder, decoder, searcher, vocabulary, sentence)\n",
        "                    \n",
        "            # Format and print the response sequence generated by the chatbot model\n",
        "            output_words[:] = [word_token for word_token in output_words if not (word_token == 'EOS' or word_token == 'PAD')] # Compile the sequence of words in the order compiled, discarding the end-of-sentence and padding (zeros) tokens \n",
        "            print('Script:', ''.join(scripted_sentences[index])) # Output the query sentence being responsed to\n",
        "            print('Bot:', ' '.join(output_words)) # Output the response sentence generated by the chatbot model\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BarbKdrkiDju"
      },
      "source": [
        "## **Execute Chatbot Model**\n",
        "---------\n",
        "~~~~~~\n",
        "Finally, it is time to run our model!\n",
        "\n",
        "Regardless of whether we want to train or test the chatbot model, we\n",
        "must initialize the individual encoder and decoder models. In the\n",
        "following block, we set our desired configurations, choose to start from\n",
        "scratch or set a checkpoint to load from, and build and initialize the\n",
        "models. Feel free to play with different model configurations to\n",
        "optimize performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfADbM3_Pw4w"
      },
      "source": [
        "Execute the chatbot model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSXlSx_biDju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1227b3f5-db94-4a5a-8973-48febb2975ad"
      },
      "source": [
        "# Configure the encoder, decoder and attention models\n",
        "model_name = 'chatbot_model' # Initialise the name of the chatbot model being used \n",
        "attn_model = 'dot' # Initialise the scoring method used to calculate attention weights, for the Thang Luong attention mechanism of the decoder model (RNN) configured, as the dot-product scoring method\n",
        "#attn_model = 'general' # Initialise the scoring method used to calculate attention weights, for the Thang Luong attention mechanism of the decoder model (RNN) configured, as the general scoring method\n",
        "#attn_model = 'mlp' # Initialise the scoring method used to calculate attention weights, for the Thang Luong attention mechanism of the decoder model (RNN) configured, as the multilayer perceptron scoring method\n",
        "#attn_model = 'cnn' # Initialise the scoring method used to calculate attention weights, for the Thang Luong attention mechanism of the decoder model (RNN) configured, as the convolutional neural network scoring method\n",
        "\n",
        "# Scoring method is dysfucntional: https://stackoverflow.com/questions/55958876/mistake-in-pytorch-attention-seq2seq-tutorial\n",
        "#attn_model = 'concat' # Initialise the scoring method used to calculate attention weights, for the Thang Luong attention mechanism of the decoder model (RNN) configured, as the concatenation scoring method\n",
        "\n",
        "hidden_size = 660 # Initialise the size of the hidden state vectors, in both encoder and decoder models (RNNs)\n",
        "encoder_number_of_layers = 2 # Initialise the number of layers used in the encoder RNN\n",
        "decoder_number_of_layers = 2 # Initialise the number of layers used in the decoder RNN\n",
        "dropout = 0.12 # Initialise the dropout probability for fuzzing input sequences (words in sentences) to prevent overfitting (used for increasing sampling variety for training the chatbot model) \n",
        "batch_size = 64 # Initialise the size of the input sequence batches (mini-batches used for gradient descent - model error is calculated and used to update model weighting parameters) handled by the encoder and decoder models (RNNs)\n",
        "\n",
        "# Set a checkpoint to load from; set to 'none' if starting a new training sequence\n",
        "load_filename = None # Initialise the name of the file representing where the training data is stored, for loading checkpoints of the training process (start a new training sequence by default) \n",
        "checkpoint_iterations = 100 # Initialise the number of checkpoint iterations to load training data from\n",
        "#load_filename = os.path.join(save_directory, model_name, ''.join(directory_extensions[0]),\n",
        "#                            '{}-{}_{}'.format(encoder_number_of_layers, decoder_number_of_layers, hidden_size),\n",
        "#                            '{}_checkpoint.tar'.format(checkpoint_iterations))\n",
        "\n",
        "\n",
        "# Load the configurations of the chatbot RNN models (encoder/ decoder) if a file name is provided\n",
        "if load_filename: # If the chatbot models training process is being resumed from a loaded checkpoint, do the following\n",
        "    # Load the checkpoint, only if the checkpoint being loaded is being loaded to the same device that the model was trained on\n",
        "    checkpoint = torch.load(load_filename)\n",
        "    \n",
        "    # If the configuration of the chatbot model being loaded, was trained on the GPU (CUDA) orginally but is now being trained using the CPU, do the following\n",
        "    #checkpoint = torch.load(load_filename, map_location = torch.device('cpu')) # Retarget the checkpoint for use with the CPU hardware accelerator\n",
        "    \n",
        "    encoder_state_saved_data = checkpoint['encoder_state'] # Store the state of the encoder for the checkpoint loaded\n",
        "    decoder_state_saved_data = checkpoint['decoder_state'] # Store the state of the decoder for the checkpoint loaded\n",
        "    encoder_optimizer_saved_data = checkpoint['encoder_optimizer'] # Store the configuration of the encoder optimizer for the checkpoint loaded\n",
        "    decoder_optimizer_saved_data = checkpoint['decoder_optimizer'] # Store the configuration of the decoder optimizer for the checkpoint loaded\n",
        "    embedding_saved_data = checkpoint['embedding'] # Store the word embedding of the vocabuluary configured for the checkpoint loaded\n",
        "    vocabulary.__dict__ = checkpoint['vocabulary_dictionary'] # Store the vocabuluary configured for the checkpoint loaded\n",
        "\n",
        "print('Building encoder and decoder models...') # Output that the encoder and decoder models (RNNs) are being built (compiled)\n",
        "\n",
        "embedding = nn.Embedding(vocabulary.number_of_words, hidden_size) # Initialize the word embeddings for the vocabulary configured (aims to quantify and categorize semantic similarities between words based on their distributional properties in large samples of vocabulary)\n",
        "\n",
        "if load_filename: # If the chatbot models training process is being resumed from a loaded checkpoint, do the following\n",
        "    embedding.load_state_dict(embedding_saved_data) # Load the word embedding state for the checkpoint loaded\n",
        "\n",
        "# Initialize encoder and decoder model instances (RNNs)\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_number_of_layers, dropout, rnn_module, mlp_active) # Initialise an encoder model (RNN) instance\n",
        "decoder = LuongAttentionDecoderRNN(attn_model, embedding, hidden_size, vocabulary.number_of_words, decoder_number_of_layers, dropout, rnn_module) # Initialise an decoder model (RNN) instance\n",
        "\n",
        "if load_filename: # If the chatbot models training process is being resumed from a loaded checkpoint, do the following\n",
        "    encoder.load_state_dict(encoder_state_saved_data) # Load the encoder model (RNN) state for the checkpoint loaded\n",
        "    decoder.load_state_dict(decoder_state_saved_data) # Load the decoder model (RNN) state for the checkpoint loaded\n",
        "\n",
        "encoder = encoder.to(device) # Set the encoder model (RNN) instance to be handled using the active hardware accelerator (device options CUDA (GPU and CPU) or CPU)\n",
        "decoder = decoder.to(device) # Set the decoder model (RNN) instance to be handled using the active hardware accelerator (device options CUDA (GPU and CPU) or CPU)\n",
        "\n",
        "print('Encoder-decoder model has been built and is ready for execution!') # Output that the chatbot model has been built (compiled)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building encoder and decoder models...\n",
            "Encoder-decoder model has been built and is ready for execution!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnLw9_e_iDju"
      },
      "source": [
        "## **Execute Chatbot Model Training**\n",
        "---------\n",
        "~~~~~~~~~~~~\n",
        "First we set training parameters, then we initialize our optimizers, and\n",
        "finally we call the ``trainingIterations`` function to run our training\n",
        "iterations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0jpMpVnP0TC"
      },
      "source": [
        "Execute the training process of the chatbot model (configure and optimise)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTZHTaKeiDju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25e5c6d-f024-4ee3-adba-a495c5101e4c"
      },
      "source": [
        "gradient_clip = 145.0 # Initialise the clipping for the gradients of descent used to modify the weighting parameters of the encoder-decoder models (RNNs); gradient clipping is a technique to prevent exploding gradients (gradient becomes too large and error gradients accumulate, resulting in an unstable network) in RNNs\n",
        "teacher_forcing_ratio = 1.0 # Initialise the teacher forcing ratio (10%); the probability that the decoder model (RNN) uses the current target word as its next input rather than using its predicted word\n",
        "learning_rate = 0.0001 # Initialise the learning rate of the encoder-decoder models (RNNs) for the chatbot (rate of optimization), when training\n",
        "decoder_learning_ratio = 4.0 # Initialise the learning rate multiplier of the decoder model (RNN) for the chatbot, when training\n",
        "number_of_training_iterations = 10000 # Initialise the number of training iterations to be performed on the chatbots model\n",
        "print_every = 1 # Initialise the frequency (number of iterations) of which loss is calculated and output\n",
        "save_every = 500 # Initialise the frequency (number of iterations) of which restoreable checkpoints are saved; the current configuration of the chatbot model (its parameters) are written to an external file\n",
        "\n",
        "all_losses = [] # Initialise an array for all the losses calculated for a given number of training iterations performed, where loss is calculated (refer to its calculation and ouput frequency)\n",
        "plot_every = 1 # Initialise the frequency (number of iterations) of which loss is plot to the plot figure configured, for evaluating the chatbot models performance, when training\n",
        "\n",
        "retrain_model = True # Determine whether the chatbot model is retrained, or not\n",
        "\n",
        "if retrain_model is True: # If the chatbot model is set to be retrained, do the following\n",
        "    # Ensure dropout layers are in train mode\n",
        "    encoder.train() # Train the chatbots encoder model (RNN)\n",
        "    decoder.train() # Train the chatbots decoder model input_lengths(RNN)\n",
        "\n",
        "    # Initialize the optimizers\n",
        "    print('Building optimizers...') # Output that the weighting parameter optimizers for the encoder-decoder RNNs are being built for the learning rates configured (optimise for minimizing loss - descending gradients) \n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr = learning_rate) # Initialise the encoder model (RNN) optimizer \n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr = learning_rate * decoder_learning_ratio) # Initialise the decoder model (RNN) optimizer\n",
        "\n",
        "    if load_filename: # If the chatbot models training process is being resumed from a loaded checkpoint, do the following\n",
        "        encoder_optimizer.load_state_dict(encoder_optimizer_saved_data) # Load the encoder model (RNN) weighting parameter optimizer state for the checkpoint loaded\n",
        "        decoder_optimizer.load_state_dict(decoder_optimizer_saved_data) # Load the decoder model (RNN) weighting parameter optimizer state for the checkpoint loaded\n",
        "\n",
        "    # If you have cuda, configure cuda to call\n",
        "    for state in encoder_optimizer.state.values(): # For each optimizer state (combination of weighting (learnable) parameter and its value - e.g. learning rate (lr) : 0.0001) configured for the encoder model (RNN), do the following (learnable parameters in its networks layers (convolutional layers, linear layers, etc.))\n",
        "        for parameter, value in state.items(): # For each optimizer states weighting parameter and corresponding value, do the following\n",
        "            if isinstance(value, torch.Tensor): # If the weighting parameters value is a tensor, do the following\n",
        "                state[parameter] = value.cuda() # Set the tensor to be created and handled using the GPU hardware accelerator (if available and in use)\n",
        "\n",
        "    for state in decoder_optimizer.state.values(): # For each optimizer state (combination of weighting (learnable) parameter and its value - e.g. learning rate (lr) : 0.0001) configured for the decoder model (RNN), do the following (learnable parameters in its networks layers (convolutional layers, linear layers, etc.))\n",
        "        for parameter, value in state.items(): # For each optimizer states weighting parameter and corresponding value, do the following\n",
        "            if isinstance(value, torch.Tensor): # If the weighting parameters value is a tensor, do the following\n",
        "                state[parameter] = value.cuda() # Set the tensor to be created and handled using the GPU hardware accelerator (if available and in use)\n",
        "    \n",
        "    print(\"Initiating the chatbot models training process!\") # Output that the chatbot models traning process is initiating \n",
        "\n",
        "    # Inspired by: https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7\n",
        "    training_pairs, evaluation_pairs = trainingEvaluationPairs(pairs, 80, \"ordered\") # Function call, partition the sentence pairs populated in the chatbots vocabulary, for training and evaluating the performance of the chatbot model effectively\n",
        "    print(\"Training pairs: [{}]   Evaluation pairs: [{}]   Total pairs: [{}]\".format(len(training_pairs), len(evaluation_pairs), len(training_pairs) + len(evaluation_pairs))) # Output the number of sentence pairs in each dataset, used to train and evaluate the chatbot model\n",
        "\n",
        "    trainingIterations(model_name, vocabulary, training_pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "                       embedding, encoder_number_of_layers, decoder_number_of_layers, save_directory, number_of_training_iterations, batch_size,\n",
        "                       print_every, save_every, gradient_clip, ''.join(directory_extensions[0]), load_filename, all_losses, plot_every) # Function call, iterate the training process for the chatbot model, for the number of iterations passed\n",
        "\n",
        "else: # If the chatbots model is not being retrained, do the following\n",
        "   print(\"The chatbots model was previously trained!\") # Output that the chatbot model was trained previously "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building optimizers...\n",
            "Initiating the chatbot models training process!\n",
            "Training pairs: [94912]   Evaluation pairs: [23728]   Total pairs: [118640]\n",
            "Initializing...\n",
            "Training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3wFc5k7z1dt"
      },
      "source": [
        "## **Training Evaluation**\n",
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P75NayIFP-ro"
      },
      "source": [
        "Evaluate the training performance of the chatbot model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2L7iKEH_NaB"
      },
      "source": [
        "### **Data Update**\r\n",
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn7qzHLYUSn2"
      },
      "source": [
        "Update chatbot model training and evaluation data, for displaying the most-current data of each corpus supported by the chatbot model, in a series of graph plots and summary tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBa7z5V3pJmw"
      },
      "source": [
        "corpora = [] # Initialise the corpora array\r\n",
        "\r\n",
        "for i, corpus in enumerate(corpus_name): # For each corpus recognised in the corpora dictionary, do the following\r\n",
        "    corpora.append(corpus) # Append the name (key) of the currently iterated corpus to the corpora array\r\n",
        "\r\n",
        "# Function declaration, update the training data used to represent the performace of the corpora supported by the chatbot model\r\n",
        "def updateData(corpus_name, corpus_choice, data_file_path, data_file, read_data, new_data, mode):\r\n",
        "    if mode == \"train\": # If the data update mode is for chatbot model training data, do the following\r\n",
        "        for i, corpus in enumerate(corpus_name): # For each corpus recognised in the corpora dictionary, do the following\r\n",
        "            if data_file_path[corpus].is_file() is False: # If the data file does not exist, do the following\r\n",
        "                with open(data_file[i], 'w') as output_file: # Open the file being written-to (created)\r\n",
        "                    output_file.writelines(read_data[i]) # Write the chatbot models training performance data to the file, for the currently iterated corpus\r\n",
        "\r\n",
        "            if retrain_model == True: # If the chatbot model is set to be retrained, do the following   \r\n",
        "                if corpus is not corpus_choice: # If the currently iterated corpus (key) is not the nominated corpus used to train the chatbot model currently, do the following\r\n",
        "                    with open(data_file[i], 'r') as output_file: # Open the file being read-in\r\n",
        "                          for line in output_file: # For each line in the output file, do the following\r\n",
        "                              if len(line) > 1: # If the length of the line is larger than '1' (not just an single character - need multiple points to plot), do the following\r\n",
        "                                  data = line.split(\" \") # Split the line using white spaces as the delimiter (create a list of the corpus losses - each list element is a loss)\r\n",
        "                                  read_data[i] = data # Store the corpus losses into the index of the read data array, corresponding to the currently iterated corpus\r\n",
        "                      \r\n",
        "                              else: # If the length of the line is not larger than '1' (a single or no characters), do the following\r\n",
        "                                  read_data[i] = 0.0 # Set the index of the read data array that corresponds to the currently iterated corpus, to '0'\r\n",
        "\r\n",
        "                else: # Else if the currently iterated corpus (key) is the nominated corpus used to train the chatbot model currently, do the following\r\n",
        "                    read_data[i] = new_data # Store the corpus losses into the index of the read data array, corresponding to the currently iterated corpus (losses just calculated for the recent training process)\r\n",
        "        \r\n",
        "            else: # If the chatbot model is not set to be retrained, do the following\r\n",
        "                with open(data_file[i], 'r') as output_file: # Open the file being read-in\r\n",
        "                    for line in output_file: # For each line in the output file, do the following\r\n",
        "                        if len(line) > 1: # If the length of the line is larger than '1' (not just an single character - need multiple points to plot), do the following\r\n",
        "                            data = line.split(\" \") # Split the line using white spaces as the delimiter (create a list of the corpus losses - each list element is a loss)\r\n",
        "                            read_data[i] = data # Store the corpus losses into the index of the read data array, corresponding to the currently iterated corpus\r\n",
        "                      \r\n",
        "                        else: # If the length of the line is not larger than '1' (a single or no characters), do the following\r\n",
        "                            read_data[i] = 0.0 # Set the index of the read data array that corresponds to the currently iterated corpus, to '0'\r\n",
        "                  \r\n",
        "            with open(data_file[i], 'w') as output_file: # Open the file being written-to\r\n",
        "                read_data_string = str(read_data[i]) # Cast the loss data for the currently iterated corpus, to a string\r\n",
        "\r\n",
        "                characters_to_replace = \"[,']\" # Initialise the characters to replace string\r\n",
        "                    \r\n",
        "                for character in characters_to_replace: # For each character in the characters to replace string, do the following\r\n",
        "                    read_data_string = read_data_string.replace(character, \"\") # Replace the currently iterated character in the losses string, to an empty character (remove)\r\n",
        "                    \r\n",
        "                output_file.writelines(read_data_string) # Write the chatbot models training performance data to the file, for the currently iterated corpus\r\n",
        "                #print(\"Read string:\", read_data_string) # Output the chatbot models training performance data, for the currently iterated corpus\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    elif mode == \"evaluate\": # Else if the data update mode is for chatbot model evaluation data, do the following\r\n",
        "        if data_file_path.is_file() is False: # If the data file does not exist, do the following\r\n",
        "            with open(data_file, 'w') as output_file: # Open the file being written-to (created)\r\n",
        "                for i, corpus in enumerate(corpus_name): # For each corpus recognised in the corpora dictionary, do the following \r\n",
        "                    if i < len(corpus_name): # If the currently iterated corpus is not the last corpus in the corpora supported by the chatbot model, do the following\r\n",
        "                        output_file.writelines(read_data[i] + \"\\n\") # Write the chatbot models evaluation data to a new line in the file (line proceeding on new line as well), for the currently iterated corpus\r\n",
        "                      \r\n",
        "                    else: # Else if the currently iterated corpus is the last corpus in the corpora supported by the chatbot model, do the following\r\n",
        "                        output_file.writelines(read_data[i]) # Write the chatbot models evaluation data to a new line in the file (no line proceeding), for the currently iterated corpus\r\n",
        "\r\n",
        "        if retrain_model == True: # If the chatbot model is set to be retrained, do the following  \r\n",
        "            with open(data_file, 'r') as output_file: # Open the file being read-in\r\n",
        "                  for i, line in enumerate(output_file): # For each line in the output file, do the following\r\n",
        "                      if corpora[i] is not corpus_choice: # If the currently iterated corpus (key) is not the nominated corpus used to train the chatbot model currently, do the following\r\n",
        "                          data = line.replace(\"\\n\", \"\") # Replace the new character in the currently iterated line in the file, with an empty character (remove)\r\n",
        "                          data = data.split(\" \") # Split the line using white spaces as the delimiter (create a list of the corpus losses - each list element is a loss)\r\n",
        "                      \r\n",
        "                          if len(data) == 1: # If the line is composed up of '1' element (corpus name - no data for corpus), do the following\r\n",
        "                              padded_data = [] # Initialise the padded data array\r\n",
        "\r\n",
        "                              for j in range(0, len(new_data), 1): # For the number of elements in the accuracy data array passed, do the following\r\n",
        "                                  if j == 0: # If the first element in the accuracy data array is currently iterated, do the following\r\n",
        "                                      padded_data.append(data[0]) # Append the corpus name to the padded data array, as the first element ( ['CMQ'] )\r\n",
        "\r\n",
        "                                  else: # Else if other elements in the accuracy data array are currently iterated, do the following\r\n",
        "                                      padded_data.append(\"0\") # Append '0' to the padded data array, as the next element ( ['CMQ', '0', '0', '0', '0', '0', '0', '0', '0', '0'] )\r\n",
        "\r\n",
        "                              read_data[i] = padded_data # Store the corpus accuracy data (padded - no data) into the index of the read data array, corresponding to the currently iterated corpus\r\n",
        "\r\n",
        "                          else: # Else if the line is composed up of more than '1' element (previously recorded accuracy data for the corpus), do the following\r\n",
        "                              read_data[i] = data # Store the corpus accuracy data into the index of the read data array, corresponding to the currently iterated corpus\r\n",
        "                        \r\n",
        "                      else: # Else if the currently iterated corpus (key) is the nominated corpus used to train the chatbot model currently, do the following\r\n",
        "                          read_data[i] = new_data # Store the corpus accuracy data into the index of the read data array, corresponding to the currently iterated corpus (accuracies just calculated for the recent evaluation process)\r\n",
        "              \r\n",
        "                  #for data in read_data: # For each corpus accuracies in the read data array, do the following\r\n",
        "                      #print(\"Read data:\", data) # Output the chatbot models evaluation data, for the currently iterated corpus\r\n",
        "\r\n",
        "        else: # If the chatbot model is not set to be retrained, do the following\r\n",
        "             with open(data_file, 'r') as output_file: # Open the file being read-in\r\n",
        "                  for i, line in enumerate(output_file): # For each line in the output file, do the following\r\n",
        "                      data = line.replace(\"\\n\", \"\") # Replace the new character in the currently iterated line in the file, with an empty character (remove)\r\n",
        "                      data = data.split(\" \") # Split the line using white spaces as the delimiter (create a list of the corpus losses - each list element is a loss)\r\n",
        "                      \r\n",
        "                      if len(data) == 1: # If the line is composed up of '1' element (corpus name - no data for corpus), do the following\r\n",
        "                          padded_data = [] # Initialise the padded data array\r\n",
        "\r\n",
        "                          for j in range(0, len(new_data), 1): # For the number of elements in the accuracy data array passed, do the following\r\n",
        "                              if j == 0: # If the first element in the accuracy data array is currently iterated, do the following\r\n",
        "                                  padded_data.append(data[0]) # Append the corpus name to the padded data array, as the first element ( ['CMQ'] )\r\n",
        "\r\n",
        "                              else: # Else if other elements in the accuracy data array are currently iterated, do the following\r\n",
        "                                  padded_data.append(\"0\") # Append '0' to the padded data array, as the next element ( ['CMQ', '0', '0', '0', '0', '0', '0', '0', '0', '0'] )\r\n",
        "\r\n",
        "                          read_data[i] = padded_data # Store the corpus accuracy data (padded - no data) into the index of the read data array, corresponding to the currently iterated corpus\r\n",
        "\r\n",
        "                      else: # Else if the line is composed up of more than '1' element (previously recorded accuracy data for the corpus), do the following\r\n",
        "                          read_data[i] = data # Store the corpus accuracy data into the index of the read data array, corresponding to the currently iterated corpus\r\n",
        "                        \r\n",
        "                  #for data in read_data: # For each corpus accuracies in the read data array, do the following\r\n",
        "                      #print(\"Read data:\", data) # Output the chatbot models evaluation data, for the currently iterated corpus\r\n",
        "\r\n",
        "        with open(data_file, 'w') as output_file: # Open the file being written-to\r\n",
        "            for i, corpus in enumerate(corpus_name): # For each corpus recognised in the corpora dictionary, do the following\r\n",
        "                read_data_string = ' '.join(read_data[i]) # Concatenate the accuracy data for the currently iterated corpus, to a string\r\n",
        "               \r\n",
        "                characters_to_replace = \"[,']\" # Initialise the characters to replace string\r\n",
        "                    \r\n",
        "                for character in characters_to_replace: # For each character in the characters to replace string, do the following\r\n",
        "                    read_data_string = read_data_string.replace(character, \"\") # Replace the currently iterated character in the losses string, to an empty character (remove)\r\n",
        "                    \r\n",
        "                output_file.writelines(read_data_string + \"\\n\") # Write the chatbot models evaluation data to a new line in the file, for the currently iterated corpus\r\n",
        "                #print(\"Read string:\", read_data_string) # Output the chatbot models evaluation data, for the currently iterated corpus\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    #for data in read_data: # For each corpus data in the read data array, do the following\r\n",
        "        #print(\"Read data:\", data) # Output the chatbot models mode of data, for the currently iterated corpus\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Function declaration, normalise the data populated from the file\r\n",
        "def normaliseData(read_data, mode):\r\n",
        "    data_raw = [] # Initialise the data raw array\r\n",
        "    data_parsed = [] # Initialise the data parsed array\r\n",
        "\r\n",
        "    for i, dataset in enumerate(read_data): # For each corpus dataset, do the following\r\n",
        "        if mode == \"train\": # If the data update mode is for chatbot model training data, do the following \r\n",
        "            if corpora[i] is corpus_choice: # If the currently iterated corpus (key) is the nominated corpus used to train the chatbot model currently, do the following\r\n",
        "                if retrain_model == True: # If the chatbot model is set to be retrained, do the following   \r\n",
        "                    data_parsed.append(dataset) # Append the dataset calculated for the currently nominated corpus, to the data parsed array\r\n",
        "                    #print(\"Data:\", read_data) # Output the currently iterated corpus data\r\n",
        "                \r\n",
        "                else: # Else if the chatbot model is not set to be retrained, do the following   \r\n",
        "                    for data in dataset: # For each data in the currenlty iterated corpus dataset, do the following\r\n",
        "                        #print(\"Data: {} Type: {}\".format(data, type(data))) # Output the currently iterated data and its stoarge type, for the currently iterated corpus dataset\r\n",
        "               \r\n",
        "                        if type(data) is str: # If the storage type of the currently iterated data in the currently iterated corpus dataset, is a string, do the following\r\n",
        "                           #print(\"Data before:\", data) # Output the current state of the data currently iterated\r\n",
        "                            count = len(data) # Initialise the character count as the length of the currently iterated data\r\n",
        "          \r\n",
        "                            integer_decimal = data.split(\".\") # Split the currently iterated data into its integer and decimal components\r\n",
        "                            count = count - (len(integer_decimal[0]) + 1) # Calculate the power of '10' required for the data to be recompiled to its original state, when divided from an integer to become a float variable (minus the integer and decimal point characters)\r\n",
        "                \r\n",
        "                            data = data.replace(\".\", \"\") # Replace the period decimal point (period) character with no character (allow the stringized data to be casted to a float variable)\r\n",
        "                            data = float(data) / 10 ** count # Reformat the data (integer form) to its original magnitude (recompile to its float (decimal) format)\r\n",
        "                            #print(\"Data after:\", data) # Output the current state of the data currently iterated\r\n",
        "\r\n",
        "                        data_raw.append(data) # Append the data (float) to the data raw array\r\n",
        "                        #for data in data_raw: # For each data in the data raw array, do the following\r\n",
        "                            #print(\"Data: {} Type: {}\".format(data, type(data))) # Output the currently iterated data and its storage type (verify the format of each data)\r\n",
        "\r\n",
        "                    data_parsed.append(data_raw) # Append the dataset calculated for the currently nominated corpus, to the data parsed array\r\n",
        "                    #print(\"Dataset:\", dataset) # Output the currently iterated corpus dataset\r\n",
        "\r\n",
        "            else: # If the currently iterated corpus (key) is not the nominated corpus used to train the chatbot model currently, do the following\r\n",
        "                for data in dataset: # For each data in the currenlty iterated corpus dataset, do the following\r\n",
        "                    #print(\"Data: {} Type: {}\".format(data, type(data))) # Output the currently iterated data and its stoarge type, for the currently iterated corpus dataset\r\n",
        "               \r\n",
        "                     if type(data) is str: # If the storage type of the currently iterated data in the currently iterated corpus dataset, is a string, do the following\r\n",
        "                        #print(\"Data before:\", data) # Output the current state of the data currently iterated\r\n",
        "                        count = len(data) # Initialise the character count as the length of the currently iterated data\r\n",
        "          \r\n",
        "                        integer_decimal = data.split(\".\") # Split the currently iterated data into its integer and decimal components\r\n",
        "                        count = count - (len(integer_decimal[0]) + 1) # Calculate the power of '10' required for the data to be recompiled to its original state, when divided from an integer to become a float variable (minus the integer and decimal point characters)\r\n",
        "                \r\n",
        "                        data = data.replace(\".\", \"\") # Replace the period decimal point (period) character with no character (allow the stringized data to be casted to a float variable)\r\n",
        "                        data = float(data) / 10 ** count # Reformat the data (integer form) to its original magnitude (recompile to its float (decimal) format)\r\n",
        "                        #print(\"Data after:\", data) # Output the current state of the data currently iterated\r\n",
        "\r\n",
        "                     data_raw.append(data) # Append the data (float) to the data raw array\r\n",
        "                     #for data in data_raw: # For each data in the data raw array, do the following\r\n",
        "                        #print(\"Data: {} Type: {}\".format(data, type(data))) # Output the currently iterated data and its storage type (verify the format of each data)\r\n",
        "\r\n",
        "                data_parsed.append(data_raw) # Append the dataset calculated for the currently nominated corpus, to the data parsed array\r\n",
        "                #print(\"Dataset:\", dataset) # Output the currently iterated corpus dataset \r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "        elif mode == \"evaluate\": # Else if the data update mode is for chatbot model evaluation data, do the following\r\n",
        "                removed_corpus_name = [] # Initialise the removed corpus name array\r\n",
        "\r\n",
        "                for j in range (1, len(dataset), 1): # For the length of the corpus dataset currently iterated (staring at index '1' - skip corpus name), do the following\r\n",
        "                    removed_corpus_name.append(dataset[j]) # Append each element after the first element in the dataset, to the removed corpus name array (corpus name cannot be converted to an integer or float)\r\n",
        "                    \r\n",
        "                for data in removed_corpus_name: # For each element in the removed corpus name array, do the following\r\n",
        "                #print(\"Data: {} Type: {}\".format(data, type(data))) # Output the currently iterated data and its stoarge type, for the currently iterated corpus dataset\r\n",
        "               \r\n",
        "                    #print(\"Data before:\", data) # Output the current state of the data currently iterated\r\n",
        "                    count = len(data) # Initialise the character count as the length of the currently iterated data\r\n",
        "                  \r\n",
        "                    if data.find(\".\") != -1: # If the currently iterated element in the dataset contains a decimal point character (float), do the following\r\n",
        "                        integer_decimal = data.split(\".\") # Split the currently iterated data into its integer and decimal components\r\n",
        "                        count = count - (len(integer_decimal[0]) + 1) # Calculate the power of '10' required for the data to be recompiled to its original state, when divided from an integer to become a float variable (minus the integer and decimal point characters)\r\n",
        "                \r\n",
        "                        data = data.replace(\".\", \"\") # Replace the period decimal point (period) character with no character (allow the stringized data to be casted to a float variable)\r\n",
        "                        data = float(data) / 10 ** count # Reformat the data (integer form) to its original magnitude (recompile to its float (decimal) format)\r\n",
        "                        #print(\"Data after:\", data) # Output the current state of the data currently iterated\r\n",
        "                        \r\n",
        "                    else: # Else if the currently iterated element in the dataset does not contain a decimal point character (integer), do the following\r\n",
        "                        data = int(data) # Cast the data into its orignal integer storage type\r\n",
        "\r\n",
        "                    data_raw.append(data)\r\n",
        "                    #for data in data_raw: # For each data in the data raw array, do the following\r\n",
        "                        #print(\"Data: {} Type: {}\".format(data, type(data))) # Output the currently iterated data and its storage type (verify the format of each data)\r\n",
        "\r\n",
        "                data_parsed.append(data_raw) # Append the dataset calculated for the currently nominated corpus, to the data parsed array\r\n",
        "                #print(\"Dataset:\", dataset) # Output the currently iterated corpus dataset \r\n",
        "            \r\n",
        "        data_raw = [] # Reinitialise the data raw array (for future iterations)\r\n",
        "\r\n",
        "    #for i in range(0, len(data_parsed), 1): # For each corpus data in the data parsed array, do the following\r\n",
        "        #print(\"Data:\", data_parsed[i]) # Output the dataset for the corpus currently iterated\r\n",
        "\r\n",
        "    return data_parsed # Return the data parsed array"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNBwlAD6_U6I"
      },
      "source": [
        "### **Training Loss Data Graph Plots**\r\n",
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzAuLI7cVNVK"
      },
      "source": [
        "Plot the training loss data compiled for each of the corpuses supported by the chatbot model, in a series of colour-coded graph plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfX7o4X2Jm2W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3341369b-997e-434a-d066-ef0c01d10ad6"
      },
      "source": [
        "data_files = [] # Initialise the performance data files array\n",
        "data_file_paths = {} # Initialise the performance data file paths array\n",
        "\n",
        "read_loss_data = [] # Initialise the read data array (the loss data of corpuses already populated by previous training processes)\n",
        "\n",
        "for i, corpus in enumerate(corpus_name): # For each corpus recognised in the corpora dictionary, do the following\n",
        "    file_name = corpus + \"_loss_data.txt\" # Store the concatenation between the currently iterated corpus name and its trailing extension (the files name)\n",
        "    data_files.append(os.path.join(corpus_data_directory, file_name)) # Configure and combine the absolute directory of the notebook and the files name\n",
        "    data_file_paths[corpus] = Path(data_files[i]) # Append the path variable to the data file paths array\n",
        "    read_loss_data.append('') # Initialise the current index of the read loss data array ( ['', '', ''] )\n",
        "    \n",
        "updateData(corpus_name, corpus_choice, data_file_paths, data_files, read_loss_data, all_losses, \"train\") # Function call, update the loss data for each corpus enrolled by the chatbot model\n",
        "\n",
        "performance_data_parsed = [] # Initialise the performance data parsed array\n",
        "\n",
        "performance_data_parsed = normaliseData(read_loss_data, \"train\") # Function call, normalise the loss data for each corpus enrolled by the chatbot model\n",
        "\n",
        "subplots = [] # Initialise the subplots array, representing the loss of information during the training process of the chatbot model, for each corpus that the chatbot model supports\n",
        "subplot_colours = [['r', 'red'], ['c', 'cyan'], ['m', 'magenta']] # Initialise the colour codes used to illustrate each subplot\n",
        "\n",
        "average_losses = [] # Initialise the average losses array\n",
        "\n",
        "for i in range(0, len(corpora), 1): # For each corpus in the chatbot models supported corpora, do the following\n",
        "    subplots.append(corpora[i]) # Add a new entry to the subplot set, for the currently iterated corpus\n",
        "    \n",
        "    if len(performance_data_parsed[i]) == 0: # If there is no performance data populated for the corpus currently iterated, do the following\n",
        "        average_losses.append(0.00) # Append an average loss of '0' to the average losses array, for the corpus currently iterated\n",
        "\n",
        "    else: # Else if there is performance data populated for the corpus currently iterated, do the following\n",
        "        average_losses.append(round(sum(performance_data_parsed[i]) / len(performance_data_parsed[i]), 2))\n",
        "        \n",
        "subplots.append(\"Corpora\") # Add a new entry to the subplot set, for the corpora (comparison purposes)\n",
        "\n",
        "figure, subplots = plt.subplots(len(corpora) + 1, sharex = False, sharey = False) # Initialise the subplots for the number of corpuses ('+1' for comparative subplot of all corpuses) supported by the chatbot model\n",
        "\n",
        "for i in range(0, len(corpora), 1): # For each corpus in the chatbot models supported corpora, do the following\n",
        "    x_coordinates = np.linspace(0, len(performance_data_parsed[i]) - 1, len(performance_data_parsed[i]))\n",
        "    loss = np.array(performance_data_parsed[i]) # Create a numerical python array instance of the performance parsed array, for the currently iterated corpus\n",
        "    average_loss = np.array(average_losses[i]) # Create a numerical python array instance of the average losses array, for the currently iterated corpus\n",
        "\n",
        "    subplots[i].set_title(corpora[i] + ' training information loss (the difference between two probability distributions - predicted word vs expected word)', color = subplot_colours[i][1], fontsize = 14, fontweight = 'bold', pad = 20) # Configure the title for the subplot currently iterated\n",
        "    subplots[i].set_xlabel('Training Iteration', color = subplot_colours[i][1], fontsize = 10, fontweight = 'bold') # Configure the 'X' axis label for the subplot currently iterated\n",
        "    subplots[i].set_ylabel('Loss', color = subplot_colours[i][1], fontsize = 10, fontweight = 'bold') # Configure the 'Y' axis label for the subplot currently iterated\n",
        "    subplots[i].tick_params(axis = 'x', labelsize = 8, colors = subplot_colours[i][1], gridOn = True, grid_alpha = 0.2, grid_linestyle = \"-.\", grid_color = 'b', tick1On = True, tick2On = True) # Configure the 'X' axis tick parameters for the subplot currently iterated\n",
        "    subplots[i].tick_params(axis = 'y', labelsize = 8, colors = subplot_colours[i][1], gridOn = True, grid_alpha = 0.2, grid_linestyle = \"-.\", grid_color = 'b', tick1On = True, tick2On = True) # Configure the 'Y' axis tick parameters for the subplot currently iterated\n",
        "        \n",
        "    if len(performance_data_parsed[i]) != 0: # If there is performance data populated for the corpus currently iterated, do the following\n",
        "        subplots[i].plot(performance_data_parsed[i], subplot_colours[i][0] + '-') # Plot the array of losses calculated and accumulated for the chatbot models training process, for the subplot currently iterated\n",
        "        subplots[i].text(0, performance_data_parsed[i][0], \"Initial loss: {}\".format(round(performance_data_parsed[i][0], 2)), style = 'italic', \n",
        "                     bbox = {'facecolor': subplot_colours[i][1], 'edgecolor': 'black', 'alpha': 0.7, 'pad': 5}) # Configure a text label representing the intial loss of the currently iterated corpus\n",
        "        subplots[i].text(len(performance_data_parsed[i]) - 1, performance_data_parsed[i][len(performance_data_parsed[i]) - 1], \"Final loss: {}\".format(round(performance_data_parsed[i][len(performance_data_parsed[i]) - 1], 2)), style = 'italic', \n",
        "                     bbox = {'facecolor': subplot_colours[i][1], 'edgecolor': 'black', 'alpha': 0.7, 'pad': 5}) # Configure a text label representing the final loss of the currently iterated corpus\n",
        "        subplots[i].text(len(performance_data_parsed[i]) / 2, average_losses[i], \"Average loss: {}\".format(average_losses[i]), style = 'italic', \n",
        "                     bbox = {'facecolor': subplot_colours[i][1], 'edgecolor': 'black', 'alpha': 0.7, 'pad': 5}) # Configure a text label representing the intial loss of the currently iterated corpus\n",
        "        subplots[i].axhline(y = average_losses[i], color = 'black', linewidth = 3, linestyle = \"--\") # Draw a line parallel to the 'X' axis, for the 'Y' axis representing the currently iterated corpuses average loss of information\n",
        "        subplots[i].fill_between(x_coordinates, loss, 0, facecolor = subplot_colours[i][0], alpha = 0.3, interpolate = True) # Fill the graph space between the plot lines and the 'X' axis\n",
        "\n",
        "subplots[len(corpora)].set_title(\"Corpora\" + ' training information loss (the difference between two probability distributions - predicted word vs expected word)', color = 'lime', fontsize = 14, fontweight = 'bold', pad = 20) # Configure the title for the corpora subplot\n",
        "subplots[len(corpora)].set_xlabel('Training Iteration', color = 'lime', fontsize = 10, fontweight = 'bold') # Configure the 'X' axis label for the corpora subplot\n",
        "subplots[len(corpora)].set_ylabel('Loss', color = 'lime', fontsize = 10, fontweight = 'bold') # Configure the 'Y' axis label for the corpora\n",
        "subplots[len(corpora)].tick_params(axis = 'x', labelsize = 8, colors = 'lime', gridOn = True, grid_alpha = 0.2, grid_linestyle = \"-.\", grid_color = 'b', tick1On = True, tick2On = True) # Configure the 'X' axis tick parameters for the corpora subplot\n",
        "subplots[len(corpora)].tick_params(axis = 'y', labelsize = 8, colors = 'lime', gridOn = True, grid_alpha = 0.2, grid_linestyle = \"-.\", grid_color = 'b', tick1On = True, tick2On = True) # Configure the 'Y' axis tick parameters for the corpora subplot\n",
        "\n",
        "for i in range(0, len(corpora) + 1, 1): # For each corpus in the chatbot models supported corpora ('+1' for averaged subplot), do the following\n",
        "    if i != len(corpora): # If the currently iterated corpus is not the last corpus in the corpora, do the following\n",
        "        subplots[len(corpora)].plot(performance_data_parsed[i], subplot_colours[i][0] + '-') # Plot the array of losses calculated and accumulated for the chatbot models training process, for the corpora subplot\n",
        "    else: # Else if the currently iterated corpus is the last corpus in the corpora, do the following\n",
        "        same_length = 1 # Initialise the count of the number of corpuses that were trained for the same number of iterations\n",
        "        length = 0 # Initialise the number of training iterations performed for the first corpus iterated in the corpora\n",
        "\n",
        "        for j in range(0, len(corpora), 1): # For each corpus in the chatbot models supported corpora, do the following\n",
        "            if j == 0: # If the currently iterated corpus is the first corpus in the corpora, do the following\n",
        "                length = len(performance_data_parsed[j]) # Set the number of training iterations performed for the first corpus iterated in the corpora, to the number of indexes that the performance data parsed array contains for it\n",
        "            else: # Else if the currently iterated corpus is not the first corpus in the corpora, do the following\n",
        "                if len(performance_data_parsed[j]) == length: # If the currenlty itearted corpus was trained for the same number of iterations as the first corpus in the corpora, do the following\n",
        "                    same_length += 1 # Increment the number of corpuses containing performance data for the same number of training iterations\n",
        "        \n",
        "        averaged_performance_data = [] # Initialise the averaged performance data array\n",
        "\n",
        "        if same_length == len(performance_data_parsed): # If all corpuses were trained for the same number of iterations, do the following\n",
        "            for k in range(0, len(corpora), 1): # For each corpus in the corpora array, do the following\n",
        "                for l in range(0, length, 1): # For the number of training iterations performed for each corpus in the corpora, do the following\n",
        "                    if len(averaged_performance_data) != length: # If the average performance data array has not been populated to the number of training iterations performed by each corpus in the corpora, do the following\n",
        "                        averaged_performance_data.append(performance_data_parsed[k][l]) # Append the performance data for the currently iterated corpus, for the currently iterated training iteration, to the averaged performance data array\n",
        "                    \n",
        "                    else: # Else if the average performance data array has been populated to the number of training iterations performed by each corpus in the corpora, do the following\n",
        "                        averaged_performance_data[l] = averaged_performance_data[l] + performance_data_parsed[k][l] # Add the performance data for the currently iterated corpus, for the currently iterated training iteration, to the averaged performance data array (accumulate corpus performance data)\n",
        "\n",
        "            for m in range(0, length, 1): # For the number of training iterations performed for each corpus in the corpora, do the following \n",
        "                averaged_performance_data[m] = averaged_performance_data[m] / len(corpora) # Store the averaged performance data, for the accumulated performance data of each corpus in the corpora, for every training iteration performed\n",
        "\n",
        "            average_losses.append(round((sum(averaged_performance_data) / len(averaged_performance_data)), 2)) # Append the average loss for the averaged performance data, compiled for the currently iterated corpus\n",
        "\n",
        "            subplots[len(corpora)].plot(averaged_performance_data, 'g-') # Plot the array of losses calculated and accumulated for the chatbot models training process, for the corpora subplot (average for all corpuses)\n",
        "            subplots[len(corpora)].text(0, averaged_performance_data[0], \"Initial loss (average): {}\".format(round(averaged_performance_data[0], 2)), style = 'italic', \n",
        "                     bbox = {'facecolor': 'lime', 'edgecolor': 'black', 'alpha': 0.7, 'pad': 5}) # Configure a text label representing the intial loss of the currently iterated corpus\n",
        "            subplots[len(corpora)].text(len(averaged_performance_data) - 1, averaged_performance_data[len(averaged_performance_data) - 1], \"Final loss (average): {}\".format(round(averaged_performance_data[len(averaged_performance_data) - 1], 2)), style = 'italic', \n",
        "                     bbox = {'facecolor': 'lime', 'edgecolor': 'black', 'alpha': 0.7, 'pad': 5}) # Configure a text label representing the final loss of the currently iterated corpus\n",
        "            subplots[i].text(len(averaged_performance_data) / 2, sum(averaged_performance_data) / len(averaged_performance_data), \"Average loss (average): {}\".format(average_losses[len(average_losses) - 1]), style = 'italic', \n",
        "                     bbox = {'facecolor': 'lime', 'edgecolor': 'black', 'alpha': 0.7, 'pad': 5}) # Configure a text label representing the intial loss of the currently iterated corpus\n",
        "            subplots[i].axhline(y = average_losses[len(average_losses) - 1], color = 'black', linewidth = 3, linestyle = \"--\") # Draw a line parallel to the 'X' axis, for the 'Y' axis representing the currently iterated corpuses average loss of information\n",
        "\n",
        "figure.set_figheight(10) # Set the height of the figure in each subplot instance\n",
        "figure.set_figwidth(10) # Set the width of the figure in each subplot instance\n",
        "figure.tight_layout() # Set the format of the subplot layout to be tightly arranged\n",
        "figure.subplots_adjust(left = 0, bottom = 0, right = 2.35, top = 1.1, wspace = None, hspace = None) # Set the alignment of the subplots"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNcv0g7r-4Mc"
      },
      "source": [
        "### **Training Loss Data Summary Table**\r\n",
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRB7xLSiVdk0"
      },
      "source": [
        "Present the training loss data compiled for each of the corpuses supported by the chatbot model, in a summary table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk_pWyytrPQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "08fa4936-22ca-4c28-dc69-c9c6b1f5cbd3"
      },
      "source": [
        "summary_table_corpus = [] # Initialise the summary table corpus array (store corpus names)\r\n",
        "summary_table_fields = ['Corpus', 'Initial Loss', 'Final Loss', 'Loss Range', 'Average Loss'] # Initialise the summary table fields array (store table headers)\r\n",
        "summary_table_values = [] # Initialise the summary table value array (store the values for the corresponding table header fields)\r\n",
        "\r\n",
        "corpus_names = [] # Initialise the corpus names array\r\n",
        "intial_losses = [] # Initialise the initial losses array\r\n",
        "final_losses = [] # Initialise the final losses array\r\n",
        "loss_ranges = [] # Initialise the loss ranges array\r\n",
        "losses_average = [] # Initialise the losses average array\r\n",
        "\r\n",
        "for i in range(0, len(corpora), 1): # For each corpus in the chatbot models supported corpora, do the following\r\n",
        "    if len(performance_data_parsed[i]) != 0: # If there is performance data populated for the corpus currently iterated, do the following\r\n",
        "        initial_loss = performance_data_parsed[i][0] # Store the initial loss calculated at the start of the training process for the chatbot model\r\n",
        "        final_loss = performance_data_parsed[i][len(performance_data_parsed[i]) - 1] # Store the final calculated loss of the training process for the chatbot model\r\n",
        "    \r\n",
        "    else: # Else if there is no performance data populated for the corpus currently iterated, do the following\r\n",
        "        initial_loss = 0.00 # Set the initial loss calculated at the start of the training process for the chatbot model to '0'\r\n",
        "        final_loss = 0.00 # Set the final loss calculated at the start of the training process for the chatbot model to '0'\r\n",
        "\r\n",
        "    corpus_names.append(corpora[i]) # Append the name of the currently iterated corpus to the corpus names array\r\n",
        "    intial_losses.append(str(round(initial_loss, 2))) # Append the initial loss of information for the currently iterated corpus, to the initial losses array\r\n",
        "    final_losses.append(str(round(final_loss, 2))) # Append the final loss of information for the currently iterated corpus, to the final losses array\r\n",
        "    loss_ranges.append(str(abs(round(initial_loss - final_loss, 2)))) # Append the range of information loss for the currently iterated corpus, to the loss ranges array\r\n",
        "    losses_average.append(str(round(average_losses[i], 2))) # Append the average loss of informtaion for the currently iterated corpus, to the losses average array\r\n",
        "\r\n",
        "summary_table_values = [corpus_names, intial_losses, final_losses, loss_ranges, losses_average] # Store each array as a seperate field in the summary table values array (columnised)\r\n",
        "\r\n",
        "summary_table = go.Figure(data = [go.Table(\r\n",
        "     header = dict(values = summary_table_fields,\r\n",
        "               line_color = 'black',\r\n",
        "               fill_color = 'black',\r\n",
        "                    align = 'center',\r\n",
        "        font = dict(color = 'white', size = 12)),\r\n",
        "      cells = dict(values = summary_table_values,\r\n",
        "               line_color = 'black',\r\n",
        "               fill_color = [['lightgrey', 'white'] * len(corpora)],\r\n",
        "                    align = 'center',\r\n",
        "        font = dict(color = 'black', size = 12)))\r\n",
        "]) # Create a summary table object instance, passing the performance data compiled and calculated for each corpus supported by the chatbot model\r\n",
        "\r\n",
        "summary_table.update_layout(width = None, height = None) # Update the layout of the summary table instance\r\n",
        "summary_table.show() # Generate and display the summary table object instance (after updating its layout) "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"4766e23c-4552-4a31-a2f9-98e46f34dd08\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"4766e23c-4552-4a31-a2f9-98e46f34dd08\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '4766e23c-4552-4a31-a2f9-98e46f34dd08',\n",
              "                        [{\"cells\": {\"align\": \"center\", \"fill\": {\"color\": [[\"lightgrey\", \"white\", \"lightgrey\", \"white\", \"lightgrey\", \"white\"]]}, \"font\": {\"color\": \"black\", \"size\": 12}, \"line\": {\"color\": \"black\"}, \"values\": [[\"CMD\", \"CMQ\", \"WIKI\"], [\"8.98\", \"9.52\", \"6.99\"], [\"3.98\", \"2.29\", \"0.08\"], [\"5.01\", \"7.24\", \"6.91\"], [\"4.12\", \"2.99\", \"0.45\"]]}, \"header\": {\"align\": \"center\", \"fill\": {\"color\": \"black\"}, \"font\": {\"color\": \"white\", \"size\": 12}, \"line\": {\"color\": \"black\"}, \"values\": [\"Corpus\", \"Initial Loss\", \"Final Loss\", \"Loss Range\", \"Average Loss\"]}, \"type\": \"table\"}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4766e23c-4552-4a31-a2f9-98e46f34dd08');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jID67UHdnDGo"
      },
      "source": [
        "### **Model Evaluation Accuracy**\r\n",
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLcobHYPWSuE"
      },
      "source": [
        "Evaluate the accuracy of the current chatbot model configuration, using a series of sequence matching techniques to accumulate individual scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8IRCZEc8jWW"
      },
      "source": [
        "# Function declaration, concatenate split apostrophised words\r\n",
        "def concatenateApostrophisedWords(query_sentence, target_response_sentence, response_sentence):\r\n",
        "    split_sentence = [] # Initialise the split sentence array\r\n",
        "    sorted_sentence = [] # Initialise the sorted sentence array\r\n",
        "        \r\n",
        "    apostrophe_characters = [\"re\", \"t\", \"ve\", \"m\", \"d\", \"ll\", \"s\"] # Initialise the apostrophe characters array\r\n",
        "    sentences = [query_sentence, target_response_sentence, response_sentence] # Initialise the sentences array\r\n",
        "        \r\n",
        "    # Concatenate the split apostrophised words\r\n",
        "    for j in range(0, 3, 1): # For each type of sentence in the sentence array, do the following\r\n",
        "        split_sentence = sentences[j].split() # Split each word in the currently iterated sentence into seperate elements in the list\r\n",
        "            \r\n",
        "        for k in range(0, len(split_sentence), 1): # For each word in the currently split sentence, do the following\r\n",
        "            if len(split_sentence[k]) <= 2: # If the currently iterated word in the currently split sentence is smaller than or equal to '2' characters in length, do the following\r\n",
        "                if split_sentence[k] in apostrophe_characters: # If the currently iterated word is an apostrophe character, do the following\r\n",
        "                    if k > 0 and len(split_sentence[k]) >= 1: # If the current iteration is not first iteration and the currently iterated words length is larger than or equal to '1' character, do the following\r\n",
        "                        sorted_sentence[k - 1] = '' # Reinitialise the previously iterated index of the sorted sentence array (prepare for new input)\r\n",
        "                        sorted_sentence.insert(k - 1, split_sentence[k - 1] + split_sentence[k]) # Store the apostrophised word at the previously iterated index (dont, t = dont, '')\r\n",
        "                        \r\n",
        "                    else: # Else if the current iteration is the first iteration or the currently iterated words length is smaller than '1' character, do the following\r\n",
        "                        sorted_sentence.append(split_sentence[k]) # Append the currently iterated word in the currently split sentence to the sorted sentence array\r\n",
        "                \r\n",
        "                else: # Else if the currently iterated word is not an apostrophe character, do the following\r\n",
        "                    sorted_sentence.append(split_sentence[k]) # Append the currently iterated word in the currently split sentence to the sorted sentence array\r\n",
        "              \r\n",
        "            elif len(split_sentence[k]) > 2: # Else if the currently iterated word in the currently split sentence is larger than '2' characters in length, do the following\r\n",
        "                sorted_sentence.append(split_sentence[k]) # Append the currently iterated word in the currently split sentence to the sorted sentence array\r\n",
        "              \r\n",
        "        if j == 0: # If the query sentence is currently being sorted, do the following\r\n",
        "            sentences[j] = sorted_sentence # Set the query sentence to the current iteration of the sorted sentence array\r\n",
        "            sorted_sentence = [] # Reinitialise the sorted sentence array (for future iterations)\r\n",
        "        \r\n",
        "        elif j == 1: # Else if the target response sentence is currently being sorted, do the following\r\n",
        "            sentences[j] = sorted_sentence # Set the target response sentence to the current iteration of the sorted sentence array\r\n",
        "            sorted_sentence = [] # Reinitialise the sorted sentence array (for future iterations)\r\n",
        "\r\n",
        "        elif j == 2: # Else if the response sentence is currently being sorted, do the following\r\n",
        "            sentences[j] = sorted_sentence # Set the response sentence to the current iteration of the sorted sentence array\r\n",
        "            sorted_sentence = [] # Reinitialise the sorted sentence array (for future iterations)\r\n",
        "\r\n",
        "    query_sentence = ' '.join(sentences[0]) # Concatenate the elements of the query sentence index, in the sentence array, to a string\r\n",
        "    target_response_sentence = ' '.join(sentences[1]) # Concatenate the elements of the target response sentence index, in the sentence array, to a string\r\n",
        "    response_sentence = ' '.join(sentences[2]) # Concatenate the elements of the response sentence index, in the sentence array, to a string\r\n",
        "\r\n",
        "    query_sentence = re.sub(r\"\\s+\", r\" \", query_sentence).strip() # Replace multiple white space characters for a single white space character\r\n",
        "    target_response_sentence = re.sub(r\"\\s+\", r\" \", target_response_sentence).strip() # Replace multiple white space characters for a single white space character\r\n",
        "    response_sentence = re.sub(r\"\\s+\", r\" \", response_sentence).strip() # Replace multiple white space characters for a single white space character\r\n",
        "\r\n",
        "    return query_sentence, target_response_sentence, response_sentence # Return the query, target response and reponse sentences"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rooj0yr87Yh5"
      },
      "source": [
        "# Function declaration, calculate the cosine similarity between the target and generated response sentences\r\n",
        "def cosineSimilarity(target_response_sentence, response_sentence):\r\n",
        "    cosine = 0 # Initialise the cosine ratio\r\n",
        "    cosine_similarity = 0 # Initialise the cosine similarity\r\n",
        "    \r\n",
        "    target_response_sentence = target_response_sentence.lower() # Reformat the target response sentence to be in the lower case format (if capital)\r\n",
        "    response_sentence = response_sentence.lower() # Reformat the response sentence to be in the lower case format (if capital)\r\n",
        "   \r\n",
        "    target_response_sentence = word_tokenize(target_response_sentence) # Store the target response sentence, tokenized  \r\n",
        "    response_sentence = word_tokenize(response_sentence) # Store the response sentence, tokenized\r\n",
        "  \r\n",
        "    stop_words = stopwords.words('english') # Store the sentence stop words for the English language\r\n",
        "\r\n",
        "    word_in_target = [] # Initialise the word in target array\r\n",
        "    word_in_response = [] # Initiailise the word in response array\r\n",
        "  \r\n",
        "    target_response_trimmed = {word for word in target_response_sentence if not word in stop_words} # Store the target response sentence, filtered from the stop words of the language passed\r\n",
        "    response_trimmed = {word for word in response_sentence if not word in stop_words} # Store the response sentence, filtered from the stop words of the language passed\r\n",
        "\r\n",
        "    all_words = target_response_trimmed.union(response_trimmed) # Store the set of words that exist in the target response and reponse sentences (duplicates excluded) \r\n",
        "    \r\n",
        "    for word in all_words: # For each word in all the words existing in the target response and reponse sentences (excluding stop words), do the following\r\n",
        "        if word in target_response_trimmed: # If the currently iterated word exists in the target response sentence, do the following\r\n",
        "            word_in_target.append(1) # Append '1' to the word in target array, representing that the currently iterated word exists in the sentence\r\n",
        "        \r\n",
        "        else: # Else if the currently iterated word does not exist in the target response sentence, do the following\r\n",
        "            word_in_target.append(0) # Append '0' to the word in target array, representing that the currently iterated word does not exist in the sentence\r\n",
        "        \r\n",
        "        \r\n",
        "        if word in response_trimmed: # If the currently iterated word exists in the response sentence, do the following\r\n",
        "            word_in_response.append(1) # Append '1' to the word in response array, representing that the currently iterated word exists in the sentence\r\n",
        "        \r\n",
        "        else: # Else if the currently iterated word does not exist in the response sentence, do the following\r\n",
        "            word_in_response.append(0) # Append '0' to the word in response array, representing that the currently iterated word does not exist in the sentence\r\n",
        "  \r\n",
        "    # Cosine function  \r\n",
        "    for i in range(len(all_words)): # For the number of words existing in the target response and response sentences (excluding stop words), do the following\r\n",
        "        cosine += word_in_target[i] * word_in_response[i] # Set the cosine ratio to accumulate the values in the word in target and response arrays, for the currently iterated word (ratio of word containing in both)\r\n",
        "    \r\n",
        "    if sum(word_in_target) > 0 and sum(word_in_response) > 0: # If the target response and response sentences share at least one word (irrespective of order), do the following\r\n",
        "        cosine_similarity = cosine / float((sum(word_in_target) * sum(word_in_response)) ** 0.5) # Calculate the cosine similarity of the sentences (words in the sentences)\r\n",
        "    \r\n",
        "    return cosine_similarity # Return the calculated cosine similarity"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUPxC-29cqxP"
      },
      "source": [
        "# Function declaration, calculate the response accuracy for the chatbot model configuration compiled\r\n",
        "def ResponseAccuracy(vocabulary, sentence_pairs, encoder, decoder, searcher, number_of_iterations):\r\n",
        "    model_accuracy_sentences = [] # Initialise the model accuracy sentences array (accuracy of total sentence predictions)\r\n",
        "    model_accuracy_words = [] # Initialise the model accuracy words array (accuracy of total word predictions)\r\n",
        "    bleu_score_total = [] # Initialise the total BLEU score array (accuracy of words predicted for all sentences)\r\n",
        "    bleu_score = 0 # Initialise the BLEU score for the response sentence being evaluated (accuracy of words predicted for the current sentence) \r\n",
        "    levenshtein_accuracy_total = [] # Initialise the total Levenshtein accuracy \r\n",
        "    sequence_matcher_accuracy_total = [] # Initialise the total sequence matcher accuracy\r\n",
        "    cosine_accuracy_total = [] # Initialise the total cosine accuracy\r\n",
        "     \r\n",
        "    words_correct_total = 0 # Initialise the total correctly predicted word count\r\n",
        "    words_evaluated_total = 0 # Initialise the total number of words evaluated\r\n",
        "    words_correct = 0 # Initialise the correctly predicted word count\r\n",
        "    words_evaluated = 0 # Initialise the number of words evaluated\r\n",
        "\r\n",
        "    if number_of_iterations > len(sentence_pairs): # If the number of evaluation iterations is larger than the number of sentence pairs populated for the chatbot model, do the following\r\n",
        "        print(\"The number of evaluation iterations [{}] exceeds the number of sentence pairs [{}] populated!\".format(number_of_iterations, len(sentence_pairs))) # Output that the number of evaluation iterations exceeds the number of sentence pairs populated for the chatbot model\r\n",
        "        number_of_iterations = len(sentence_pairs) # Set the number of evaluation iterations to the length of the sentence pairs array\r\n",
        "        print(\"Now evaluating all [{}] sentence pairs...\\n\".format(number_of_iterations)) # Output the updated number of iterations to be executed for evaluating the chatbot models configuration\r\n",
        "\r\n",
        "    for i in range(0, number_of_iterations, 1): # For the number of iterations configured for the chatbot models response accuracy to be measured within, do the following\r\n",
        "        query_sentence = sentence_pairs[i][0] # Store the query sentence of the currently iterated sentence pairs, populated for training the chatbot model configured\r\n",
        "        target_response_sentence = sentence_pairs[i][1] # Store the response sentence of the currently iterated sentence pairs, populated for training the chatbot model configured\r\n",
        "\r\n",
        "        query_sentence = normalizeString(query_sentence) # Normalise the query sentence (Unicode to ASCII encoding for the chatbot model to handle)\r\n",
        "\r\n",
        "        response_sentence = evaluate(encoder, decoder, searcher, vocabulary, query_sentence) # Evaluate the query sentence, to produce a response sentence that has been approproated to it \r\n",
        "        response_sentence[:] = [word_token for word_token in response_sentence if not (word_token == 'EOS' or word_token == 'PAD')] # Compile the sequence of words in the order compiled, discarding the end-of-sentence and padding (zeros) tokens \r\n",
        "        response_sentence = ' '.join(response_sentence) # Concatenate the elements of the response sentence array, to a string\r\n",
        "\r\n",
        "        characters_to_replace = \"[^0-9a-zA-Z]+\" # Initialise the characters to replace string (everything non-alphanumeric)\r\n",
        "                    \r\n",
        "        query_sentence = re.sub(characters_to_replace, \" \", query_sentence) # Replace all non-alphanumeric characters in the query sentence, to a whitespace character\r\n",
        "        target_response_sentence = re.sub(characters_to_replace, \" \", target_response_sentence) # Replace all non-alphanumeric characters in the target response sentence, to a whitespace character\r\n",
        "        response_sentence = re.sub(characters_to_replace, \" \", response_sentence) # Replace all non-alphanumeric characters in the response sentence, to a whitespace character\r\n",
        "            \r\n",
        "        query_sentence, target_response_sentence, response_sentence = concatenateApostrophisedWords(query_sentence, target_response_sentence, response_sentence) # Function call, concatenate split apostrophised words for all sentences passed\r\n",
        "        \r\n",
        "        #print(\"[Query: {}]  [Target response: {}]  [Response: {}]\".format(query_sentence, target_response_sentence, response_sentence)) # Ouput the query, target response and response sentences for the chatbot model \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        # Calculate the percentage of misclassification (zero-one loss) of the chatbot model configuration compiled\r\n",
        "        # Inspired by the concept delivered in: https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model \r\n",
        "        split_sentence = [] # Reinitialise the split sentence array\r\n",
        "        sentences = [query_sentence, target_response_sentence, response_sentence] # Reinitialise the sentences array\r\n",
        "\r\n",
        "        for j in range(0, 3, 1): # For each type of sentence in the sentence array, do the following\r\n",
        "            split_sentence.append(sentences[j].split()) # Append the currently split iterated sentence to the split sentence array\r\n",
        "\r\n",
        "        for j in range(0, len(split_sentence[2]), 1): # For the length of the response sentence compiled by the chatbot model configuration, do the following\r\n",
        "            if j < len(split_sentence[1]): # If the currently iterated word is not the last word in the target response sentence, do the following\r\n",
        "                if split_sentence[1][j] == split_sentence[2][j]: # If the currently iterated word exists at the same index in both sentences, do the following\r\n",
        "                    words_correct += 1 # Increment the number of words predicted correctly\r\n",
        "                    words_evaluated += 1 # Increment the total number of words evaluated\r\n",
        "            \r\n",
        "                else: # Else if the currently iterated word does not exist at the same index in both sentences, do the following\r\n",
        "                    words_evaluated += 1 # Increment the total number of words evaluated\r\n",
        "            \r\n",
        "            else: # Else if the currently iterated word is the last, or is beyond the last word in the target response sentence, do the following\r\n",
        "                words_evaluated += 1 # Increment the total number of words evaluated\r\n",
        "\r\n",
        "        if words_correct > 0: # If at least one word was correctly predicted in the target sentence by the chatbot model configuration, do the following \r\n",
        "            model_accuracy_sentences.append(words_correct / words_evaluated) # Append the ratio of the number of words predicted correctly, relative to the size of the response that the chatbot model produced, to the model accuracy sentence array\r\n",
        "\r\n",
        "        else: # Else if no word was correctly predicted in the target sentence by the chatbot model configuration, do the following \r\n",
        "            model_accuracy_sentences.append(0) # Append '0' to the model accuracy sentence array (incorrect sentence) \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        # Calculate the percentage of misclassification of the chatbot model configuration compiled, using BLEU scoring (Bilingual Evaluation Understudy)\r\n",
        "        # Discovered at: https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\r\n",
        "        reference = target_response_sentence.split() # Set the reference sentence (comparing sentence) to the target response sentence (n-gram - word for word scoring)\r\n",
        "        candidate = response_sentence.split() # Set the candidate sentence (generated sentence) to the response sentence (n-gram - word for word scoring)\r\n",
        "        smooth = SmoothingFunction().method0 # Define the smoothing method for BLEU scoring calculation\r\n",
        "        \r\n",
        "        if target_response_sentence is not \"\": # If the target sentence in the sentence pair currently iterated, is not an empty character, do the following\r\n",
        "            bleu_score = sentence_bleu(reference, candidate, smoothing_function = smooth, auto_reweigh = False, emulate_multibleu = False) # Calculate the BLEU score of the currently iterated sentence pair\r\n",
        "\r\n",
        "            if model_accuracy_sentences[i] > bleu_score: # If the sentence accuracy calculated by the order of the words in the currently iterated response and target response sentence pairs (zero-one loss method), is larger than its BLEU score (prevent word for word accurate sentences receiving less than '1.0' score - BLEU inaccurate), do the following \r\n",
        "                bleu_score = model_accuracy_sentences[i] # Update the BLEU score to the score computed by the zero-one loss method (words correct vs words evaluated)\r\n",
        "        else: # Else if the target sentence in the sentence pair currently iterated, is an empty character, do the following\r\n",
        "            bleu_score = 0 # Set the BLEU score to '0' (no match)\r\n",
        "\r\n",
        "        bleu_score_total.append(bleu_score) # Append the BLEU score for the currently iterated sentence pair (all sentence scores combined), to the BLEU score total array\r\n",
        "        \r\n",
        "        #print(\"[Target response: {}]  [Response: {}]  [BLEU score (total): {}%]  [BLEU score (sentence): {}%]  [Sentence accuracy: {}%]\"\r\n",
        "              #.format(reference, candidate, round(sum(bleu_score_total), 2), round(bleu_score, 2), round(model_accuracy_sentences[i], 2))) # Output the BLEU score accuracies of the chatbot models configuration\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        # Calculate the percentage of misclassification of the chatbot model configuration compiled, using Levenshtein distance (the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other)\r\n",
        "        # Discovered at: https://stackoverflow.com/questions/6690739/high-performance-fuzzy-string-comparison-in-python-use-levenshtein-or-difflib\r\n",
        "        levenshtein_accuracy_total.append(Levenshtein.ratio(target_response_sentence, response_sentence)) # Append the Levenshtein similarity calculated for the currently iterated sentence pair, to the Levenshtein accuracy total array \r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        # Calculate the percentage of misclassification of the chatbot model configuration compiled, using sequence matching (applies Ratcliff and Obershelp's “gestalt pattern matching” algorithm)\r\n",
        "        # Discovered at: https://stackoverflow.com/questions/6690739/high-performance-fuzzy-string-comparison-in-python-use-levenshtein-or-difflib\r\n",
        "        sequence_matcher_accuracy_total.append(SequenceMatcher(None, target_response_sentence, response_sentence).ratio()) # Append the sequence matcher accuracy calculated for the currently iterated sentence pair, to the sequence matcher accuracy total array \r\n",
        "        \r\n",
        "        \r\n",
        "\r\n",
        "        # Calculate the percentage of misclassification of the chatbot model configuration compiled, using cosine similarity (cosine of the angle between two vectors projected in a multi-dimensional space (irrespective of different vector sizes); smaller the angle, higher the degree of similarity)\r\n",
        "        # Discovered at: https://www.geeksforgeeks.org/python-measure-similarity-between-two-sentences-using-cosine-similarity/\r\n",
        "        cosine_accuracy_total.append(cosineSimilarity(target_response_sentence, response_sentence))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        #print(\"[Target response: {}]  [Response: {}]  [Words correct total: {}]  [Words incorrect total: {}]  [Words correct sentence: {}]  [Words in sentence accuracy: {}%]  [BLEU score: {}%]\"\r\n",
        "              #.format(target_response_sentence, response_sentence, words_correct_total, words_evaluated_total - words_correct_total, words_correct, \r\n",
        "              #round((words_correct / words_evaluated) * 100, 2), round(bleu_score, 2))) # Output the word and sentence accuracies of the chatbot models configuration\r\n",
        "\r\n",
        "        words_correct_total += words_correct # Accumulate the correctly predicted word count\r\n",
        "        words_evaluated_total += words_evaluated # Accumulate the evaluated word count\r\n",
        "\r\n",
        "        words_correct = 0 # Reinitialise the correctly predicted word count (for future iterations)\r\n",
        "        words_evaluated = 0 # Reinitialise the evaluated word count (for future iterations)\r\n",
        "\r\n",
        "    model_accuracy_words = round((words_correct_total / words_evaluated_total) * 100, 2) # Calculate the accuracy of the words predicted (predicted vs actual) by the chatbot models configuration\r\n",
        "    \r\n",
        "    return number_of_iterations, words_correct_total, words_evaluated_total - words_correct_total, words_evaluated_total, model_accuracy_words, bleu_score_total, levenshtein_accuracy_total, sequence_matcher_accuracy_total, cosine_accuracy_total # Return the correct and incorrect words counts predicted by the chatbot model and the word and sentence accuracies calculated"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL5hA9FCsmAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94bb0f6-efae-4347-a929-2ea49f1d36f4"
      },
      "source": [
        "# Set the dropout layers to evaluation mode\r\n",
        "encoder.eval() # Function call, evaluate the encoder model (RNN)\r\n",
        "decoder.eval() # Function call, evaluate the decoder model (RNN)\r\n",
        "\r\n",
        "searcher = GreedySearchDecoder(encoder, decoder) # Initialise the search module using the greedy decoder (decoding method of the chatbot model)\r\n",
        "\r\n",
        "number_of_evaluation_iterations = 1000 # Initialise the number of evaluation iterations that are going to be performed on the chatbot models current configuration\r\n",
        "\r\n",
        "number_of_evaluation_iterations, words_correct, words_incorrect, words_evaluated, model_accuracy, bleu_accuracy, levenshtein_accuracy, sequence_matcher_accuracy, cosine_accuracy_total = ResponseAccuracy(vocabulary, evaluation_pairs, encoder, decoder, searcher, number_of_evaluation_iterations) # Return the accuracy related variables of the chatbot model configuration\r\n",
        "\r\n",
        "average_cosine_similarity_accuracy = round((sum(cosine_accuracy_total) / len(cosine_accuracy_total)) * 100, 2) # Calculate the cosine similarity accuracy\r\n",
        "average_sequence_matcher_accuracy = round((sum(sequence_matcher_accuracy) / len(sequence_matcher_accuracy)) * 100, 2) # Calculate the sequence matcher accuracy\r\n",
        "average_levenshtein_accuracy = round((sum(levenshtein_accuracy) / len(levenshtein_accuracy)) * 100, 2) # Calculate the averaged Levenshtein similarity\r\n",
        "average_bleu_score_accuracy = round((sum(bleu_accuracy) / len(bleu_accuracy)) * 100, 2) # Calculate the averaged BLEU score accuracy\r\n",
        "\r\n",
        "print(\"\\n[Levenshtein accuracy: {}%]\\n[BLEU score accuracy: {}%]\\n[Sequence matcher accuracy: {}%]\\n[Cosine similarity accuracy: {}%]\\n[Ordered token-by-token accuracy: {}%]  [Sentences: {}/{}]  [Words: {}/{}/{}]\\n\" \r\n",
        "      .format(average_levenshtein_accuracy, average_bleu_score_accuracy, average_sequence_matcher_accuracy, average_cosine_similarity_accuracy, model_accuracy, \r\n",
        "              bleu_accuracy.count(1), number_of_evaluation_iterations, words_correct, words_incorrect, words_correct + words_incorrect)) # Output the accuracy of the chatbot model, for the configuration compiled"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning:\n",
            "\n",
            "\n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Levenshtein accuracy: 28.46%]\n",
            "[BLEU score accuracy: 15.98%]\n",
            "[Sequence matcher accuracy: 25.55%]\n",
            "[Cosine similarity accuracy: 3.8%]\n",
            "[Ordered token-by-token accuracy: 3.6%]  [Sentences: 37/1000]  [Words: 108/2890/2998]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4xhhsxzYcbS"
      },
      "source": [
        "### **Model Evaluation Accuracy Summary Table**\r\n",
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK2W02vbWl9E"
      },
      "source": [
        "Present the series of evaluation accuracy data compiled for each of the corpuses supported by the chatbot model, in a summary table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYfclwFkYXEx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "40d39529-7c74-4d75-a43c-7bc21cd204ba"
      },
      "source": [
        "data_file = '' # Initialise the performance data files array\r\n",
        "data_file_path = '' # Initialise the performance data file paths array\r\n",
        "\r\n",
        "read_accuracy_data = [] # Initialise the read data array (the accuracy data of corpuses already populated by previous evaluation processes)\r\n",
        "\r\n",
        "file_name = \"corpora_accuracy_data.txt\" # Define the name of the corpora accuracy data\r\n",
        "data_file = os.path.join(corpus_data_directory, file_name) # Configure and combine the absolute directory of the notebook and the files name\r\n",
        "data_file_path = Path(data_file) # Append the path variable to the data file paths array\r\n",
        "\r\n",
        "for i, corpus in enumerate(corpus_name): # For each corpus recognised in the corpora dictionary, do the following\r\n",
        "    read_accuracy_data.append(corpus) # Initialise the current index of the read accuracy data array ( ['', '', ''] )\r\n",
        "\r\n",
        "# Corpus name, ordered token-by-token accuracy, correct words, inccorect words, evaluated words, BLEU score accuracy, Levenshtein accuracy, sequence matcher accuracy, cosine similarity accuracy, number of training iterations, number of evaluation iterations\r\n",
        "accuracy_data = [corpus_choice,\r\n",
        "                 str(model_accuracy), str(words_correct), str(words_incorrect), str(words_correct + words_incorrect), \r\n",
        "                 str(average_bleu_score_accuracy), \r\n",
        "                 str(average_levenshtein_accuracy), \r\n",
        "                 str(average_sequence_matcher_accuracy),\r\n",
        "                 str(average_cosine_similarity_accuracy),\r\n",
        "                 str(number_of_training_iterations),  \r\n",
        "                 str(number_of_evaluation_iterations)] # Initialise the accuracy data array\r\n",
        "\r\n",
        "updateData(corpus_name, corpus_choice, data_file_path, data_file, read_accuracy_data, accuracy_data, \"evaluate\") # Function call, update the accuracy data for each corpus enrolled by the chatbot model\r\n",
        "\r\n",
        "accuracy_data_parsed = [] # Initialise the accuracy data parsed array\r\n",
        "\r\n",
        "accuracy_data_parsed = normaliseData(read_accuracy_data, \"evaluate\") # Function call, normalise the accuracy data for each corpus enrolled by the chatbot model\r\n",
        "\r\n",
        "summary_table_fields = ['Corpus', 'Token-by-token Accuracy', 'BLEU Score Accuracy', 'Levenshtein Accuarcy', 'Sequence Matcher Accuracy', 'Cosine Similarity Accuracy', 'Cumulative Accuracy', 'Training Iterations', 'Evaluation Iterations'] # Initialise the summary table fields array (store table headers)\r\n",
        "summary_table_values = [] # Initialise the summary table value array (store the values for the corresponding table header fields)\r\n",
        "\r\n",
        "model_accuracies = [] # Initialise the model accuracies array\r\n",
        "bleau_accuracies = [] # Initialise the BLEU score accuracies array\r\n",
        "levenshtein_accuracies = [] # Initialise the Levenshtein accuracies array\r\n",
        "sequence_matcher_accuracies = [] # Initialise the sequence matcher accuracies array\r\n",
        "cosine_similarity_accuracies = [] # Initialise the cosine similarity accuracies array\r\n",
        "training_iterations = [] # Initialise the training iterations array\r\n",
        "evaluation_iterations = [] # Initialise the evaluation iterations array\r\n",
        "cumulative_accuracies = [] # Initialise the cumulative accuracies array\r\n",
        "\r\n",
        "for i in range(0, len(corpora), 1): # For each corpus in the chatbot models supported corpora, do the following\r\n",
        "    table_values = {\"accuracy model\": '', \"correct words\": '', \"incorrect words\": '', \"evaluated words\": '', \"accuracy bleu\": '', \r\n",
        "                    \"accuracy levenshtein\": '', \"accuracy sequence matcher\": '', \"accuracy cosine similarity\": '', \"iterations training\": '', \"iterations evaluation\": ''} # Initialise the table values dictionary\r\n",
        "\r\n",
        "    table_value_keys = list(table_values.keys()) # Store the keys of the table value keys dictionary\r\n",
        "\r\n",
        "    for j in range(0, len(accuracy_data_parsed[i]), 1): # For each data field in the accuracy data parsed array, do the following\r\n",
        "        table_values[table_value_keys[j]] = accuracy_data_parsed[i][j] # Store the currently iterated data in the accuracy parsed data array, in the corresponding data field within the table values dictionary\r\n",
        "\r\n",
        "    model_accuracies.append(\"{}% [{}/{}/{}]\".format(table_values[\"accuracy model\"], table_values[\"correct words\"], table_values[\"incorrect words\"], table_values[\"evaluated words\"])) # Append the ordered token-by-token accuracy for the currently iterated corpus, to the model accuracies array\r\n",
        "    bleau_accuracies.append(\"{}%\".format(table_values[\"accuracy bleu\"])) # Append the BLEU accuracy for the currently iterated corpus, to the BLEU accuracies array\r\n",
        "    levenshtein_accuracies.append(\"{}%\".format(table_values[\"accuracy levenshtein\"])) # Append the Levenshtein accuracy for the currently iterated corpus, to the Levenshtein accuracies array\r\n",
        "    sequence_matcher_accuracies.append(\"{}%\".format(table_values[\"accuracy sequence matcher\"])) # Append the sequence matcher accuracy for the currently iterated corpus, to the sequence matcher accuracies array\r\n",
        "    cosine_similarity_accuracies.append(\"{}%\".format(table_values[\"accuracy cosine similarity\"])) # Append the cosine similarity accuracy for the currently iterated corpus, to the cosine similarity accuracies array\r\n",
        "    cumulative_accuracies.append(\"{}%\".format(round((table_values[\"accuracy model\"] + table_values[\"accuracy bleu\"] + table_values[\"accuracy levenshtein\"] + table_values[\"accuracy sequence matcher\"] + table_values[\"accuracy cosine similarity\"]) / 5, 2))) # Append the cumulative accuracy for the currently iterated corpus, to the cumulative accuracies array\r\n",
        "    training_iterations.append(\"{}\".format(table_values[\"iterations training\"])) # Append the number of training iterations for the currently iterated corpus, to the training iterations array\r\n",
        "    evaluation_iterations.append(\"{}\".format(table_values[\"iterations evaluation\"])) # Append the number of evaluation iterations for the currently iterated corpus, to the evaluation iterations array\r\n",
        "\r\n",
        "summary_table_values = [corpus_names, model_accuracies, bleau_accuracies, levenshtein_accuracies, sequence_matcher_accuracies, cosine_similarity_accuracies, cumulative_accuracies, training_iterations, evaluation_iterations] # Store each array as a seperate field in the summary table values array (columnised)\r\n",
        "\r\n",
        "summary_table = go.Figure(data = [go.Table(\r\n",
        "     header = dict(values = summary_table_fields,\r\n",
        "               line_color = 'black',\r\n",
        "               fill_color = 'black',\r\n",
        "                    align = 'center',\r\n",
        "        font = dict(color = 'white', size = 12)),\r\n",
        "      cells = dict(values = summary_table_values,\r\n",
        "               line_color = 'black',\r\n",
        "               fill_color = [['lightgrey', 'white'] * len(corpora)],\r\n",
        "                    align = 'center',\r\n",
        "        font = dict(color = 'black', size = 12)))\r\n",
        "]) # Create a summary table object instance, passing the evaluation data compiled and calculated for each corpus supported by the chatbot model\r\n",
        "\r\n",
        "summary_table.update_layout(width = None, height = None) # Update the layout of the summary table instance\r\n",
        "summary_table.show() # Generate and display the summary table object instance (after updating its layout) "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"62b871cd-7ae4-4d84-a3c7-7fd654184651\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"62b871cd-7ae4-4d84-a3c7-7fd654184651\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '62b871cd-7ae4-4d84-a3c7-7fd654184651',\n",
              "                        [{\"cells\": {\"align\": \"center\", \"fill\": {\"color\": [[\"lightgrey\", \"white\", \"lightgrey\", \"white\", \"lightgrey\", \"white\"]]}, \"font\": {\"color\": \"black\", \"size\": 12}, \"line\": {\"color\": \"black\"}, \"values\": [[\"CMD\", \"CMQ\", \"WIKI\"], [\"1.57% [46/2893/2939]\", \"3.6% [108/2890/2998]\", \"3.73% [5/129/134]\"], [\"22.14%\", \"15.98%\", \"32.61%\"], [\"28.11%\", \"28.46%\", \"34.51%\"], [\"23.83%\", \"25.55%\", \"28.69%\"], [\"2.12%\", \"3.8%\", \"9.55%\"], [\"15.55%\", \"15.48%\", \"21.82%\"], [\"1000\", \"10000\", \"1000\"], [\"1000\", \"1000\", \"27\"]]}, \"header\": {\"align\": \"center\", \"fill\": {\"color\": \"black\"}, \"font\": {\"color\": \"white\", \"size\": 12}, \"line\": {\"color\": \"black\"}, \"values\": [\"Corpus\", \"Token-by-token Accuracy\", \"BLEU Score Accuracy\", \"Levenshtein Accuarcy\", \"Sequence Matcher Accuracy\", \"Cosine Similarity Accuracy\", \"Cumulative Accuracy\", \"Training Iterations\", \"Evaluation Iterations\"]}, \"type\": \"table\"}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('62b871cd-7ae4-4d84-a3c7-7fd654184651');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqlw2g6TiDju"
      },
      "source": [
        "## **Run Evaluation**\n",
        "---------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdYEV003QCgx"
      },
      "source": [
        "Intervene with the chatbot model (conversate)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4Rful9UiDju"
      },
      "source": [
        "scripted_input = False # Determine whether the chatbot model is to evaulate live input or a series of scripted input\n",
        "\n",
        "# Set the dropout layers to evaluation mode\n",
        "#encoder.eval() # Function call, evaluate the encoder model (RNN)\n",
        "#decoder.eval() # Function call, evaluate the decoder model (RNN)\n",
        "\n",
        "# Initialise the search module using the greedy decoder (decoding method of the chatbot model)\n",
        "#searcher = GreedySearchDecoder(encoder, decoder)\n",
        "\n",
        "# Initiate the chatbot (live conversation)\n",
        "evaluateInput(encoder, decoder, searcher, vocabulary, scripted_input)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}